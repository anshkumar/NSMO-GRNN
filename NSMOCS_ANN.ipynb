{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSMOCS_ANN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshkumar/elf/blob/master/NSMOCS_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4lR1KKo2k3Zf",
        "colab_type": "code",
        "outputId": "66f611f1-c115-4aa2-cf40-722d3843e3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vao-plwRk5kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp \"./drive/My Drive/data.zip\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "epsB6XgMk7nW",
        "colab_type": "code",
        "outputId": "ef3f76c7-8511-481e-d8bb-efe6f40a6681",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3595
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip ./data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./data.zip\n",
            "   creating: data/\n",
            "   creating: data/VIC/\n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201501_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201711_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201710_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201612_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201706_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201707_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201604_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201605_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201510_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201511_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201701_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201609_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201608_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201603_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201602_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201507_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201506_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201607_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201606_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201705_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201704_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201509_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201508_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201610_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201611_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201503_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201502_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201712_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201504_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201505_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201601_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201708_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201709_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201512_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201702_VIC1.csv  \n",
            "  inflating: data/VIC/PRICE_AND_DEMAND_201703_VIC1.csv  \n",
            "   creating: data/vars/\n",
            "  inflating: data/vars/.DS_Store     \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/data/\n",
            "   creating: __MACOSX/data/vars/\n",
            "  inflating: __MACOSX/data/vars/._.DS_Store  \n",
            "  inflating: data/vars/feeder_meta.pkl  \n",
            "  inflating: data/vars/feeder.cpt.index  \n",
            "  inflating: data/vars/feeder.cpt.data-00000-of-00001  \n",
            "  inflating: data/.DS_Store          \n",
            "   creating: data/SA/\n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201705_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201502_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201512_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201606_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201503_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201607_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201704_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201605_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201501_SA1.csv  \n",
            "   creating: __MACOSX/data/SA/\n",
            "  inflating: __MACOSX/data/SA/._PRICE_AND_DEMAND_201501_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201511_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201706_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201508_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201707_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201509_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201604_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201510_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201601_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201611_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201505_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201702_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201712_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201608_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201703_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201609_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201610_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201504_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201701_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201711_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201708_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201506_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201602_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201612_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201709_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201507_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201603_SA1.csv  \n",
            "  inflating: data/SA/PRICE_AND_DEMAND_201710_SA1.csv  \n",
            "   creating: data/QLD/\n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201504_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201505_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201708_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201709_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201601_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201512_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201702_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201703_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201607_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201606_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201705_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201704_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201509_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201508_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201610_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201611_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201503_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201502_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201712_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201510_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201511_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201609_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201608_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201701_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201603_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201602_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201507_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201506_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201501_QLD1.csv  \n",
            "   creating: __MACOSX/data/QLD/\n",
            "  inflating: __MACOSX/data/QLD/._PRICE_AND_DEMAND_201501_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201711_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201710_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201612_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201706_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201707_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201604_QLD1.csv  \n",
            "  inflating: data/QLD/PRICE_AND_DEMAND_201605_QLD1.csv  \n",
            "   creating: data/NSW/\n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201506_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201507_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201608_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201609_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201701_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201511_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201510_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201602_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201603_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201707_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201706_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201605_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201604_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201710_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201711_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201501_NSW1.csv  \n",
            "   creating: __MACOSX/data/NSW/\n",
            "  inflating: __MACOSX/data/NSW/._PRICE_AND_DEMAND_201501_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201612_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201709_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201708_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201601_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201703_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201702_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201512_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201505_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201504_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201611_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201610_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201508_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201509_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201712_NSW1.csv  \n",
            "  inflating: __MACOSX/data/NSW/._PRICE_AND_DEMAND_201712_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201502_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201503_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201606_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201607_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201704_NSW1.csv  \n",
            "  inflating: data/NSW/PRICE_AND_DEMAND_201705_NSW1.csv  \n",
            "   creating: data/TAS/\n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201602_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201603_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201701_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201608_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201609_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201511_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201510_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201506_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201507_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201612_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201710_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201711_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201501_TAS1.csv  \n",
            "   creating: __MACOSX/data/TAS/\n",
            "  inflating: __MACOSX/data/TAS/._PRICE_AND_DEMAND_201501_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201605_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201604_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201707_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201706_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201505_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201504_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201703_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201702_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201512_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201601_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201709_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201708_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201704_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201705_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201606_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201607_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201712_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201502_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201503_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201611_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201610_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201508_TAS1.csv  \n",
            "  inflating: data/TAS/PRICE_AND_DEMAND_201509_TAS1.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUEu1W3AkYhC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class sw(object):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.__Positions = []\n",
        "        self.__Gbest = []\n",
        "\n",
        "    def _set_Gbest(self, Gbest):\n",
        "        self.__Gbest = Gbest\n",
        "\n",
        "    def _points(self, agents):\n",
        "        self.__Positions.append([list(i) for i in agents])\n",
        "\n",
        "    def get_agents(self):\n",
        "        \"\"\"Returns a history of all agents of the algorithm (return type:\n",
        "        list)\"\"\"\n",
        "\n",
        "        return self.__Positions\n",
        "\n",
        "    def get_Gbest(self):\n",
        "        \"\"\"Return the best position of algorithm (return type: list)\"\"\"\n",
        "\n",
        "        return list(self.__Gbest)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sQjgmwxHkOPl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Feb 25 15:16:25 2018\n",
        "\n",
        "@author: vedanshu\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from math import gamma, pi, sin, sqrt\n",
        "from random import normalvariate, randint, random\n",
        "\n",
        "class QuadraticCost(object):\n",
        "    @staticmethod\n",
        "    def fn(a,y):\n",
        "        return 0.5*np.linalg.norm(a-y)**2\n",
        "        \n",
        "    @staticmethod\n",
        "    def delta(activation, z, a, y):\n",
        "        if(activation == Activation.sigmoid):\n",
        "            return (a-y)*Activation.sigmoid_prime(z)\n",
        "        elif(activation == Activation.tanh):\n",
        "            return (a-y)*Activation.tanh_prime(z)\n",
        "        elif(activation == Activation.relu):\n",
        "            return (a-y)*(z > 0)\n",
        "        \n",
        "class Accuracy(object):\n",
        "    @staticmethod\n",
        "    def mape(y_true, y_pred):\n",
        "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    \n",
        "    @staticmethod\n",
        "    def rmse(y_true, y_pred):\n",
        "        return np.sqrt(np.mean(np.square(y_true - y_pred))) \n",
        " \n",
        "    @staticmethod\n",
        "    def mae(y_true, y_pred):\n",
        "        return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "class CrossEntropyCost(object):\n",
        "    @staticmethod\n",
        "    def fn(a, y):\n",
        "        a[a == 0] = 1e-10\n",
        "        return np.sum(np.nan_to_num(-y*np.log(a) - (1-y)*np.log(1-a)))\n",
        "    \n",
        "    @staticmethod\n",
        "    def delta(activation, z, a, y):\n",
        "        if(activation == Activation.sigmoid):\n",
        "            return a-y\n",
        "        else:\n",
        "            return (a - y + 1 - y/a)\n",
        "        \n",
        "class Activation(object):\n",
        "    @staticmethod\n",
        "    def sigmoid(z):\n",
        "        return 1.0/(1.0 + np.exp(-z))\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid_prime(z):\n",
        "        return Activation.sigmoid(z)*(1 - Activation.sigmoid(z))\n",
        "\n",
        "    @staticmethod        \n",
        "    def tanh(z):\n",
        "        return 2*Activation.sigmoid(2*z) - 1\n",
        "    \n",
        "    @staticmethod        \n",
        "    def tanh_prime(z):\n",
        "        return 1 - (Activation.tanh(z))**2\n",
        "        \n",
        "    @staticmethod\n",
        "    def relu(z):\n",
        "        return z * (z > 0)\n",
        "\n",
        "class Network(sw):\n",
        "    def __init__(self, sizes, activate, cost = CrossEntropyCost):\n",
        "        self.num_layers = len(sizes)\n",
        "        self.sizes = sizes\n",
        "        self.default_weight_initializer()\n",
        "        self.cost = cost\n",
        "        self.activate = activate\n",
        "        self.dim = sum(x*(y+1) for x,y in zip(self.sizes[1:], self.sizes[:-1]))\n",
        "               \n",
        "    def default_weight_initializer(self):\n",
        "        self.biases = [np.random.randn(x,1) for x in self.sizes[1:]]\n",
        "        self.weights = [np.random.randn(x,y)/np.sqrt(x) \n",
        "                        for x,y in zip(self.sizes[1:], self.sizes[:-1])]\n",
        "    \n",
        "    def large_weight_initializer(self):\n",
        "        self.biases = [np.random.randn(x,1) for x in self.sizes[1:]]\n",
        "        self.weights = [np.random.randn(x,y) \n",
        "                        for x,y in zip(self.sizes[1:], self.sizes[:-1])]\n",
        "    \n",
        "    def feedforward(self,a):\n",
        "        for b,w in zip(self.biases, self.weights):\n",
        "            a  = (self.activate)(np.matmul(w,a) + b)\n",
        "        return a\n",
        "                \n",
        "    def set_weight_bias(self, a):\n",
        "        lIt = 0\n",
        "        rIt = 0\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        for x,y in zip(self.sizes[1:], self.sizes[:-1]):\n",
        "            rIt += x*y\n",
        "            self.weights.append(a[lIt:rIt].reshape((x,y)))\n",
        "            lIt = rIt\n",
        "        for x in self.sizes[1:]:\n",
        "            rIt += x\n",
        "            self.biases.append(a[lIt:rIt].reshape((x,1)))\n",
        "            lIt = rIt\n",
        "           \n",
        "    def SGD(self, train_x, train_y, epochs, mini_batch_size, eta,\n",
        "            evaluation_x = None, evaluation_y = None, lmbda = 0.0,\n",
        "            monitor_evaluation_cost = False,\n",
        "            monitor_evaluation_accuracy = False,\n",
        "            monitor_training_cost = False,\n",
        "            monitor_training_accuracy = False,\n",
        "            output2D = False):\n",
        "   \n",
        "        evaluation_cost, eval_mape, eval_rmse, eval_mae = [], [] , [] , []\n",
        "        training_cost, training_mape, training_rmse, training_mae = [], [] , [] , []\n",
        "        n_train = train_x.shape[1]\n",
        "        for i in range(epochs): \n",
        "            for j in range(0, int(n_train/mini_batch_size)):\n",
        "                #taking transpose below in very much important\n",
        "                X = train_x[:,j*mini_batch_size:(j+1)*mini_batch_size]\n",
        "                if output2D:\n",
        "                    y = train_y[:, j*mini_batch_size:(j+1)*mini_batch_size]\n",
        "                else:\n",
        "                    y = train_y[j*mini_batch_size:(j+1)*mini_batch_size]\n",
        "                self.update_mini_batch(X, y, mini_batch_size, eta, lmbda, train_x.shape[1])\n",
        "                               \n",
        "            if i % 100 == 0:\n",
        "                print(\"Epochs {0}\".format(i))\n",
        "            if monitor_training_cost:\n",
        "                cost = self.total_cost(train_x, train_y, lmbda, output2D)\n",
        "                training_cost.append(cost)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"Cost on training data: {1}\".format(i, cost))\n",
        "            if monitor_training_accuracy:\n",
        "                accuracy = self.accuracy(train_x, train_y, output2D, Accuracy.mape)\n",
        "                training_mape.append(accuracy)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"MAPE on training data: {0}\".format(accuracy))\n",
        "                    \n",
        "                accuracy = self.accuracy(train_x, train_y, output2D, Accuracy.rmse)\n",
        "                training_rmse.append(accuracy)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"RMSE on training data: {0}\".format(accuracy))\n",
        "                    \n",
        "                accuracy = self.accuracy(train_x, train_y, output2D, Accuracy.mae)\n",
        "                training_mae.append(accuracy)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"MAE on training data: {0}\".format(accuracy))\n",
        "            if monitor_evaluation_cost:\n",
        "                cost = self.total_cost(evaluation_x, evaluation_y, lmbda, output2D)\n",
        "                evaluation_cost.append(cost)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"Cost on evaluation data: {1}\".format(i, cost))\n",
        "            if monitor_evaluation_accuracy:\n",
        "                accuracy = self.accuracy(evaluation_x, evaluation_y, output2D, Accuracy.mape)\n",
        "                eval_mape.append(accuracy)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"MAPE on evaluation data: {0}\".format(accuracy)) \n",
        "                    \n",
        "                accuracy = self.accuracy(evaluation_x, evaluation_y, output2D, Accuracy.rmse)\n",
        "                eval_rmse.append(accuracy)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"RMSE on evaluation data: {0}\".format(accuracy)) \n",
        "                    \n",
        "                accuracy = self.accuracy(evaluation_x, evaluation_y, output2D, Accuracy.mae)\n",
        "                eval_mae.append(accuracy)\n",
        "                if i % 100 == 0:\n",
        "                    print(\"MAE on evaluation data: {0}\".format(accuracy)) \n",
        "        return evaluation_cost, eval_mape, eval_rmse, eval_mae, training_cost, training_mape, training_rmse, training_mae\n",
        "    \n",
        "    def update_mini_batch(self, X, y, mini_batch_size, eta, lmbda, n):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        \n",
        "        delta_nabla_b, delta_nabla_w = self.backprop(X, y, mini_batch_size)\n",
        "        nabla_b = [nb+dnb for nb,dnb in zip(nabla_b, delta_nabla_b)]\n",
        "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
        "            \n",
        "        self.biases = [b - (eta/mini_batch_size)*nb \n",
        "                            for b,nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "\n",
        "#       L2 regulrization        \n",
        "#        self.weights = [(1 - eta*(lmbda/n))*w - (eta/mini_batch_size)*nw \n",
        "#                            for w,nw in zip(self.weights, nabla_w)]\n",
        "\n",
        "#       L1 regulrization\n",
        "        self.weights = [(w - eta*(lmbda/n)*np.sign(w)) - (eta/mini_batch_size)*nw \n",
        "                            for w,nw in zip(self.weights, nabla_w)]\n",
        "                            \n",
        "    def backprop(self, X, y, mini_batch_size):\n",
        "        activations = [X]\n",
        "        z = []\n",
        "        delta = [np.zeros((x, mini_batch_size)) \n",
        "                        for x in self.sizes[1:]]\n",
        "        delta_nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        \n",
        "        for b,w in zip(self.biases, self.weights):\n",
        "            z.append(np.matmul(w,activations[-1]) + b)\n",
        "            activations.append((self.activate)(z[-1]))\n",
        "           \n",
        "        delta[-1] = (self.cost).delta(self.activate, z[-1], activations[-1], y)\n",
        "        delta_nabla_w[-1] = np.dot(delta[-1], activations[-2].transpose())\n",
        "                        \n",
        "        for l in range(2,self.num_layers):\n",
        "            delta[-l] = np.dot(self.weights[-l + 1].transpose(), \n",
        "                                        delta[-l+1])*\\\n",
        "                                        (self.activate)(z[-l])\n",
        "            delta_nabla_w[-l] = np.dot(delta[-l], \n",
        "                                        activations[-l-1].transpose())\n",
        "        \n",
        "        delta_nabla_b = [b.sum(axis = 1).reshape((b.shape[0], 1)) \n",
        "                        for b in delta]\n",
        "        return (delta_nabla_b, delta_nabla_w)\n",
        "        \n",
        "    def accuracy(self, X, Y, output2D = False, AccFunc = Accuracy.mape):\n",
        "        if not output2D:\n",
        "            results = np.zeros(X.shape[1])\n",
        "            for i in range(0, X.shape[1]):\n",
        "                x = X[:, i]\n",
        "                x = x.reshape((x.shape[0], 1))    #Very much important           \n",
        "                results[i] = self.feedforward(x).item(0)\n",
        "            return AccFunc(Y, results)\n",
        "        else:\n",
        "            results = []\n",
        "            for i in range(0, X.shape[1]):\n",
        "                x = X[:, i]\n",
        "                x = x.reshape((x.shape[0], 1))    #Very much important           \n",
        "                results.append(self.feedforward(x))\n",
        "            return AccFunc(Y, np.hstack(results))\n",
        "        \n",
        "    def total_cost(self, X, Y, lmbda, output2D = False):\n",
        "        cost = 0.0\n",
        "        for j in range(0, int(X.shape[1])):\n",
        "            x = X[:, j]\n",
        "            if output2D:\n",
        "                y = Y[:,j]\n",
        "            else:\n",
        "                y = Y[j]\n",
        "            x = x.reshape((x.shape[0], 1))    #Very much important   \n",
        "            a = self.feedforward(x)\n",
        "            cost += self.cost.fn(a,y)/Y.shape[0]\n",
        "        cost += 0.5*(lmbda/Y.shape[0])*sum(np.linalg.norm(w)**2 for w in self.weights)\n",
        "        return cost     \n",
        "        \n",
        "    \"\"\"\n",
        "    Cuckoo Search Optimization\n",
        "    \"\"\"\n",
        "\n",
        "    def multiObjectiveFunction(self,x):\n",
        "        self.set_weight_bias(x)\n",
        "        y_prime = self.feedforward(self.input)\n",
        "        ob1 = sum(abs(u-v) for u,v in zip(y_prime, self.output))/x.shape[0]\n",
        "        ob2 = sqrt(sum((u-v)**2 for u,v in zip(y_prime, self.output))/x.shape[0])\n",
        "        ob3 = sum(abs((u-v)/v) for u,v in zip(y_prime, self.output))/x.shape[0]\n",
        "        ob4 = sqrt(sum((abs((u-v)/v) - ob3)**2 for u,v in zip(y_prime, self.output))/x.shape[0])\n",
        "        return min([ob1,ob2,ob3,ob4])\n",
        "    \n",
        "    def cso(self, n, x, y, function, lb, ub, dimension, iteration, pa=0.25,\n",
        "                 nest=100):\n",
        "        \"\"\"\n",
        "        :param n: number of agents\n",
        "        :param function: test function\n",
        "        :param lb: lower limits for plot axes\n",
        "        :param ub: upper limits for plot axes\n",
        "        :param dimension: space dimension\n",
        "        :param iteration: number of iterations\n",
        "        :param pa: probability of cuckoo's egg detection (default value is 0.25)\n",
        "        :param nest: number of nests (default value is 100)\n",
        "        \"\"\"\n",
        "\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.__Nests = []\n",
        "        \n",
        "        self.input = x\n",
        "        self.output = y\n",
        "\n",
        "        beta = 3 / 2\n",
        "        sigma = (gamma(1 + beta) * sin(pi * beta / 2) / (\n",
        "            gamma((1 + beta) / 2) * beta *\n",
        "            2 ** ((beta - 1) / 2))) ** (1 / beta)\n",
        "        u = np.array([normalvariate(0, 1) for k in range(dimension)]) * sigma\n",
        "        v = np.array([normalvariate(0, 1) for k in range(dimension)])\n",
        "        step = u / abs(v) ** (1 / beta)\n",
        "\n",
        "        self.__agents = np.random.uniform(lb, ub, (n, dimension))\n",
        "        self.__nests = np.random.uniform(lb, ub, (nest, dimension))\n",
        "        Pbest = self.__nests[np.array([function(x)\n",
        "                                       for x in self.__nests]).argmin()]\n",
        "        Gbest = Pbest\n",
        "        self._points(self.__agents)\n",
        "\n",
        "        for t in range(iteration):\n",
        "\n",
        "            for i in self.__agents:\n",
        "                val = randint(0, nest - 1)\n",
        "                if function(i) < function(self.__nests[val]):\n",
        "                    self.__nests[val] = i\n",
        "\n",
        "            fnests = [(function(self.__nests[i]), i) for i in range(nest)]\n",
        "            fnests.sort()\n",
        "            fcuckoos = [(function(self.__agents[i]), i) for i in range(n)]\n",
        "            fcuckoos.sort(reverse=True)\n",
        "\n",
        "            nworst = nest // 2\n",
        "            worst_nests = [fnests[-i - 1][1] for i in range(nworst)]\n",
        "\n",
        "            for i in worst_nests:\n",
        "                if random() < pa:\n",
        "                    self.__nests[i] = np.random.uniform(lb, ub, (1, dimension))\n",
        "\n",
        "            if nest > n:\n",
        "                mworst = n\n",
        "            else:\n",
        "                mworst = nest\n",
        "\n",
        "            for i in range(mworst):\n",
        "\n",
        "                if fnests[i][0] < fcuckoos[i][0]:\n",
        "                    self.__agents[fcuckoos[i][1]] = self.__nests[fnests[i][1]]\n",
        "\n",
        "            self.__nests = np.clip(self.__nests, lb, ub)\n",
        "            self.__Levyfly(step, Pbest, n, dimension)\n",
        "            self.__agents = np.clip(self.__agents, lb, ub)\n",
        "            self._points(self.__agents)\n",
        "            self.__nest()\n",
        "\n",
        "            Pbest = self.__nests[np.array([function(x)\n",
        "                                        for x in self.__nests]).argmin()]\n",
        "\n",
        "            if function(Pbest) < function(Gbest):\n",
        "                Gbest = Pbest\n",
        "\n",
        "        self._set_Gbest(Gbest)\n",
        "\n",
        "    def __nest(self):\n",
        "        self.__Nests.append([list(i) for i in self.__nests])\n",
        "\n",
        "    def __Levyfly(self, step, Pbest, n, dimension):\n",
        "\n",
        "        for i in range(n):\n",
        "            stepsize = 0.2 * step * (self.__agents[i] - Pbest)\n",
        "            self.__agents[i] += stepsize * np.array([normalvariate(0, 1)\n",
        "                                                    for k in range(dimension)])\n",
        "\n",
        "    def get_nests(self):\n",
        "        \"\"\"Return a history of cuckoos nests (return type: list)\"\"\"\n",
        "\n",
        "        return self.__Nests\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gRv1vJKHki_h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Sun Jun 17 21:30:36 2018\n",
        "\n",
        "@author: vedanshu\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "overfitting\n",
        "~~~~~~~~~~~\n",
        "Plot graphs to illustrate the problem of overfitting.  \n",
        "\"\"\"\n",
        "\n",
        "# Standard library\n",
        "import json\n",
        "\n",
        "# Third-party libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from os import path\n",
        "\n",
        "def make_plots(filename, num_epochs, \n",
        "               training_cost_xmin=200, \n",
        "               test_accuracy_xmin=200, \n",
        "               test_cost_xmin=0, \n",
        "               training_accuracy_xmin=0,\n",
        "               plt_training_cost = False,\n",
        "               plt_training_accuracy = False,\n",
        "               plt_test_cost = False,\n",
        "               plt_test_accuracy = True,\n",
        "               plt_overlay = False):\n",
        "    \"\"\"Load the results from ``filename``, and generate the corresponding\n",
        "    plots. \"\"\"\n",
        "    f = open(filename, \"r\")\n",
        "    test_cost, test_mape, test_rmse, test_mae, training_cost, training_mape, \\\n",
        "        training_rmse, training_mae = json.load(f)\n",
        "    f.close()\n",
        "    if plt_training_cost:\n",
        "        plot_training_cost(training_cost, num_epochs, training_cost_xmin)\n",
        "    if plt_test_accuracy:\n",
        "        plot_test_accuracy(test_mape, num_epochs, test_accuracy_xmin)\n",
        "    if plt_test_cost:\n",
        "        plot_test_cost(test_cost, num_epochs, test_cost_xmin)\n",
        "    if plt_training_accuracy:\n",
        "        plot_training_accuracy(training_mape, num_epochs, \n",
        "                               training_accuracy_xmin)\n",
        "    if plt_overlay:\n",
        "        plot_overlay(test_mape, training_mape, num_epochs,\n",
        "                 min(test_accuracy_xmin, training_accuracy_xmin))\n",
        "\n",
        "def plot_training_cost(training_cost, num_epochs, training_cost_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(training_cost_xmin, num_epochs), \n",
        "            training_cost[training_cost_xmin:num_epochs],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([training_cost_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Cost on the training data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_accuracy(test_accuracy, num_epochs, test_accuracy_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(test_accuracy_xmin, num_epochs), \n",
        "            [accuracy\n",
        "             for accuracy in test_accuracy[test_accuracy_xmin:num_epochs]],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([test_accuracy_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Error on the test data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_test_cost(test_cost, num_epochs, test_cost_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(test_cost_xmin, num_epochs), \n",
        "            test_cost[test_cost_xmin:num_epochs],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([test_cost_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Cost on the test data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_training_accuracy(training_accuracy, num_epochs, \n",
        "                           training_accuracy_xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(training_accuracy_xmin, num_epochs), \n",
        "            [accuracy \n",
        "             for accuracy in training_accuracy[training_accuracy_xmin:num_epochs]],\n",
        "            color='#2A6EA6')\n",
        "    ax.set_xlim([training_accuracy_xmin, num_epochs])\n",
        "    ax.grid(True)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_title('Error on the training data')\n",
        "    plt.show()\n",
        "\n",
        "def plot_overlay(test_accuracy, training_accuracy, num_epochs, xmin):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.plot(np.arange(xmin, num_epochs), \n",
        "            [accuracy for accuracy in test_accuracy], \n",
        "            color='#2A6EA6',\n",
        "            label=\"Error on the test data\")\n",
        "    ax.plot(np.arange(xmin, num_epochs), \n",
        "            [accuracy \n",
        "             for accuracy in training_accuracy], \n",
        "            color='#FFA933',\n",
        "            label=\"Error on the training data\")\n",
        "    ax.grid(True)\n",
        "    ax.set_xlim([xmin, num_epochs])\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylim([0, 20])\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "def timeSeriesSplit(cso = False):\n",
        "    state = {0: 'NSW', 1: 'QLD', 2: 'SA', 3: 'TAS', 4: 'VIC'}\n",
        "    year = {0: '2015', 1: '2016', 2: '2017'}\n",
        "    \n",
        "    df_nsw = pd.DataFrame()\n",
        "    df_qld = pd.DataFrame()\n",
        "    df_sa = pd.DataFrame()\n",
        "    df_tas = pd.DataFrame()\n",
        "    df_vic = pd.DataFrame()\n",
        "    \n",
        "    df = {'NSW': df_nsw, 'QLD': df_qld, 'SA': df_sa, 'TAS': df_tas, 'VIC': df_vic}\n",
        "    \n",
        "    df_nsw_test = pd.DataFrame()\n",
        "    df_qld_test = pd.DataFrame()\n",
        "    df_sa_test = pd.DataFrame()\n",
        "    df_tas_test = pd.DataFrame()\n",
        "    df_vic_test = pd.DataFrame()\n",
        "    \n",
        "    df_test = {'NSW': df_nsw_test, 'QLD': df_qld_test, 'SA': df_sa_test, 'TAS': df_tas_test, 'VIC': df_vic_test}\n",
        "    \n",
        "    for st in state.values():\n",
        "        for ye in year.values():\n",
        "            for mn in range(1,13):\n",
        "                if mn < 10:            \n",
        "                    dataset = pd.read_csv('./datasets/train/' + st + '/PRICE_AND_DEMAND_' + ye + '0' + str(mn) +'_' + st + '1.csv')\n",
        "                else:\n",
        "                    dataset = pd.read_csv('./datasets/train/' + st + '/PRICE_AND_DEMAND_' + ye + str(mn) +'_' + st + '1.csv')\n",
        "                df[st] = df[st].append(dataset.iloc[:,1:3])\n",
        "        df[st] = df[st].set_index('SETTLEMENTDATE')\n",
        "       \n",
        "    for st in state.values():\n",
        "        dataset = pd.read_csv('./datasets/test/' + st + '/PRICE_AND_DEMAND_201801_' + st + '1.csv')\n",
        "        df_test[st] = df_test[st].append(dataset.iloc[:,1:3])\n",
        "        df_test[st] = df_test[st].set_index('SETTLEMENTDATE')\n",
        "       \n",
        "    # numpy array\n",
        "    list_hourly_load_NSW = np.array(df['NSW'])\n",
        "    list_hourly_load_QLD = np.array(df['QLD'])\n",
        "    list_hourly_load_SA = np.array(df['SA'])\n",
        "    list_hourly_load_TAS = np.array(df['TAS'])\n",
        "    list_hourly_load_VIC = np.array(df['VIC'])\n",
        "       \n",
        "    # the length of the sequnce for predicting the future value\n",
        "    sequence_length = 84\n",
        "    x_size = 36\n",
        "    hidden = 10\n",
        "    y_size = 48\n",
        "    \n",
        "    # normalizing\n",
        "    matrix_load_NSW = list_hourly_load_NSW / np.linalg.norm(list_hourly_load_NSW)\n",
        "    matrix_load_QLD = list_hourly_load_QLD / np.linalg.norm(list_hourly_load_QLD)\n",
        "    matrix_load_SA = list_hourly_load_SA / np.linalg.norm(list_hourly_load_SA)\n",
        "    matrix_load_TAS = list_hourly_load_TAS / np.linalg.norm(list_hourly_load_TAS)\n",
        "    matrix_load_VIC = list_hourly_load_VIC / np.linalg.norm(list_hourly_load_VIC)\n",
        "    \n",
        "    matrix_load_NSW = matrix_load_NSW[:-(len(matrix_load_NSW) % sequence_length)]\n",
        "    matrix_load_QLD = matrix_load_QLD[:-(len(matrix_load_QLD) % sequence_length)]\n",
        "    matrix_load_SA = matrix_load_SA[:-(len(matrix_load_SA) % sequence_length)]\n",
        "    matrix_load_TAS = matrix_load_TAS[:-(len(matrix_load_TAS) % sequence_length)]\n",
        "    matrix_load_VIC = matrix_load_VIC[:-(len(matrix_load_VIC) % sequence_length)]\n",
        "    \n",
        "    matrix_load_NSW = matrix_load_NSW.reshape(-1, sequence_length)\n",
        "    matrix_load_QLD = matrix_load_QLD.reshape(-1, sequence_length)\n",
        "    matrix_load_SA = matrix_load_SA.reshape(-1, sequence_length)\n",
        "    matrix_load_TAS = matrix_load_TAS.reshape(-1, sequence_length)\n",
        "    matrix_load_VIC = matrix_load_VIC.reshape(-1, sequence_length)\n",
        "    \n",
        "    # shuffle the training set (but do not shuffle the test set)\n",
        "    np.random.shuffle(matrix_load_NSW)\n",
        "    np.random.shuffle(matrix_load_QLD)\n",
        "    np.random.shuffle(matrix_load_SA)\n",
        "    np.random.shuffle(matrix_load_TAS)\n",
        "    np.random.shuffle(matrix_load_VIC)\n",
        "    \n",
        "    # the training set\n",
        "    X_NSW = matrix_load_NSW[:, :x_size]\n",
        "    X_QLD = matrix_load_QLD[:, :x_size]\n",
        "    X_SA = matrix_load_SA[:, :x_size]\n",
        "    X_TAS = matrix_load_TAS[:, :x_size]\n",
        "    X_VIC = matrix_load_VIC[:, :x_size]\n",
        "    \n",
        "    # the last column is the true value to compute the mean-squared-error loss\n",
        "    y_NSW = matrix_load_NSW[:, x_size:]\n",
        "    y_QLD = matrix_load_QLD[:, x_size:]\n",
        "    y_SA = matrix_load_SA[:, x_size:]\n",
        "    y_TAS = matrix_load_TAS[:, x_size:]\n",
        "    y_VIC = matrix_load_VIC[:, x_size:]\n",
        "    \n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    \n",
        "    X = {'NSW': X_NSW, 'QLD': X_QLD, 'SA': X_SA, 'TAS': X_TAS, 'VIC': X_VIC}\n",
        "    y = {'NSW': y_NSW, 'QLD': y_QLD, 'SA': y_SA, 'TAS': y_TAS, 'VIC': y_VIC}\n",
        "    \n",
        "    for st in state.values():\n",
        "        print(\"State: \", st)\n",
        "        i = 1\n",
        "        for train_index, test_index in tscv.split(X[st]):\n",
        "            X_train, X_test = X[st][train_index], X[st][test_index]\n",
        "            y_train, y_test = y[st][train_index], y[st][test_index]\n",
        "            \n",
        "            print(\"Train and validation from state \", st, \" split \", i)\n",
        "            net = nt.Network([x_size, hidden, y_size], nt.Activation.tanh, nt.QuadraticCost)\n",
        "            if cso:\n",
        "                fname = \"kernelBiasTimeSeries\" + st + \".npy\"\n",
        "                if not path.exists(fname):\n",
        "                    print(\"Weights and biases initialization for state \",st, \" in progress...\")\n",
        "                    randInt = np.random.randint(X_train.shape[0])\n",
        "                    net.cso(100,X_train[randInt].reshape(x_size,1),y_train[randInt].reshape(y_size,1),\n",
        "                                net.multiObjectiveFunction,-0.6,0.6,net.dim ,100)\n",
        "                    net.set_weight_bias(np.array(net.get_Gbest()))\n",
        "                    np.save(fname, np.array(net.get_Gbest()))\n",
        "                net.set_weight_bias(np.load(fname))\n",
        "\n",
        "            if cso:\n",
        "                fname = \"results_\" + st + \"_TS_\" + str(i) + \"CSO\"\n",
        "            else:\n",
        "                fname = \"results_\" + st + \"_TS_\" + str(i) + \"GD\"\n",
        "            num_epochs = 1500\n",
        "            lmbda = 2\n",
        "            \n",
        "            evaluation_cost, eval_mape, eval_rmse, eval_mae, training_cost, training_mape, training_rmse, training_mae = net.SGD(\n",
        "                    X_train.transpose(),y_train.transpose(), num_epochs, \n",
        "                    10, 0.01, \n",
        "                    X_test.transpose(), y_test.transpose(), \n",
        "                    lmbda, monitor_evaluation_cost = True,\n",
        "                    monitor_evaluation_accuracy = True,\n",
        "                    monitor_training_cost = True,\n",
        "                    monitor_training_accuracy = True,\n",
        "                    output2D = True)\n",
        "            \n",
        "            f = open(fname, \"w\")\n",
        "            json.dump([evaluation_cost, eval_mape, eval_rmse, eval_mae, training_cost, training_mape, training_rmse, training_mae], f)\n",
        "            f.close()\n",
        "                \n",
        "#            make_plots(fname, num_epochs,\n",
        "#                       training_cost_xmin = 0,\n",
        "#                       test_accuracy_xmin = 0,\n",
        "#                       test_cost_xmin = 0, \n",
        "#                       training_accuracy_xmin = 0)\n",
        "            i = i+1\n",
        "\n",
        "def fiveFoldCrossValidation(cso = False):\n",
        "    #State and year to use for training and testing\n",
        "    state = {0: 'NSW', 1: 'QLD', 2: 'SA', 3: 'TAS', 4: 'VIC'}\n",
        "#    state = {0: 'NSW'}\n",
        "    year = {0: '2015', 1: '2016', 2: '2017'}\n",
        "#    year = {0: '2015'}\n",
        "    \n",
        "    hidden = 10\n",
        "    \n",
        "    #Training and testing batches\n",
        "    x_batches = {}\n",
        "    y_batches = {} \n",
        "    \n",
        "    #parameters for 5 fold validation \n",
        "    set_size = 84 \n",
        "    x_size = 36\n",
        "    y_size = 48\n",
        "    x_batches_validation_fold ={}\n",
        "    y_batches_validation_fold ={}\n",
        "    x_batches_train_fold = {}\n",
        "    y_batches_train_fold = {}\n",
        "\n",
        "    df_nsw = pd.DataFrame()\n",
        "    df_qld = pd.DataFrame()\n",
        "    df_sa = pd.DataFrame()\n",
        "    df_tas = pd.DataFrame()\n",
        "    df_vic = pd.DataFrame()\n",
        "    \n",
        "    df = {'NSW': df_nsw, 'QLD': df_qld, 'SA': df_sa, 'TAS': df_tas, 'VIC': df_vic}\n",
        "    \n",
        "    for st in state.values():\n",
        "        for ye in year.values():\n",
        "            for mn in range(1,13):\n",
        "                if mn < 10:            \n",
        "                    dataset = pd.read_csv('./data/' + st + '/PRICE_AND_DEMAND_' + ye + '0' + str(mn) +'_' + st + '1.csv')\n",
        "                else:\n",
        "                    dataset = pd.read_csv('./data/' + st + '/PRICE_AND_DEMAND_' + ye + str(mn) +'_' + st + '1.csv')\n",
        "                df[st] = df[st].append(dataset.iloc[:,1:3])\n",
        "        df[st] = df[st].set_index('SETTLEMENTDATE')\n",
        "    \n",
        "    TS_NSW = np.array(df['NSW'])\n",
        "    TS_QLD = np.array(df['QLD'])\n",
        "    TS_SA = np.array(df['SA'])\n",
        "    TS_TAS = np.array(df['TAS'])\n",
        "    TS_VIC = np.array(df['VIC'])\n",
        "      \n",
        "    #Normalizing the dataset\n",
        "    TS_NSW = TS_NSW / np.linalg.norm(TS_NSW)\n",
        "    TS_QLD = TS_QLD / np.linalg.norm(TS_QLD)\n",
        "    TS_SA = TS_SA / np.linalg.norm(TS_SA)\n",
        "    TS_TAS = TS_TAS / np.linalg.norm(TS_TAS)\n",
        "    TS_VIC = TS_VIC / np.linalg.norm(TS_VIC)\n",
        "\n",
        "    \"\"\" Making the dataset size divisible by num_period \"\"\"\n",
        "    TS_NSW = TS_NSW[:(len(TS_NSW) -(len(TS_NSW) % set_size))] \n",
        "    TS_QLD = TS_QLD[:(len(TS_QLD)- (len(TS_QLD) % set_size))]\n",
        "    TS_SA = TS_SA[:(len(TS_SA) -(len(TS_SA) % set_size))]\n",
        "    TS_TAS = TS_TAS[:(len(TS_TAS) -(len(TS_TAS) % set_size))]\n",
        "    TS_VIC = TS_VIC[:(len(TS_VIC) - (len(TS_VIC) % set_size))] \n",
        "    \n",
        "    \"\"\" Making our training dataset with batch size of num_period \"\"\"\n",
        "    TS_batches = {'NSW': TS_NSW.reshape(-1, set_size).transpose(),\n",
        "                 'QLD': TS_QLD.reshape(-1, set_size).transpose(),\n",
        "                 'SA': TS_SA.reshape(-1, set_size).transpose(),\n",
        "                 'TAS': TS_TAS.reshape(-1, set_size).transpose(),\n",
        "                 'VIC': TS_VIC.reshape(-1, set_size).transpose()}\n",
        "    \n",
        "    x_batches = {'NSW': TS_batches['NSW'][:x_size,:(TS_batches['NSW'].shape[1]-TS_batches['NSW'].shape[1]%5)],\n",
        "                 'QLD': TS_batches['QLD'][:x_size,:(TS_batches['QLD'].shape[1]-TS_batches['QLD'].shape[1]%5)],\n",
        "                 'SA': TS_batches['SA'][:x_size,:(TS_batches['SA'].shape[1]-TS_batches['SA'].shape[1]%5)],\n",
        "                 'TAS': TS_batches['TAS'][:x_size,:(TS_batches['TAS'].shape[1]-TS_batches['TAS'].shape[1]%5)],\n",
        "                 'VIC': TS_batches['VIC'][:x_size,:(TS_batches['VIC'].shape[1]-TS_batches['VIC'].shape[1]%5)]}\n",
        "    \n",
        "    y_batches = {'NSW': TS_batches['NSW'][x_size:,:(TS_batches['NSW'].shape[1]-TS_batches['NSW'].shape[1]%5)],\n",
        "                 'QLD': TS_batches['QLD'][x_size:,:(TS_batches['QLD'].shape[1]-TS_batches['QLD'].shape[1]%5)],\n",
        "                 'SA': TS_batches['SA'][x_size:,:(TS_batches['SA'].shape[1]-TS_batches['SA'].shape[1]%5)],\n",
        "                 'TAS': TS_batches['TAS'][x_size:,:(TS_batches['TAS'].shape[1]-TS_batches['TAS'].shape[1]%5)],\n",
        "                 'VIC': TS_batches['VIC'][x_size:,:(TS_batches['VIC'].shape[1]-TS_batches['VIC'].shape[1]%5)]}\n",
        "\n",
        "\n",
        "    #Making validation set\n",
        "    x_batches_validation_fold[1] = {'NSW': x_batches['NSW'][:, np.arange(0,x_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': x_batches['QLD'][:, np.arange(0,x_batches['QLD'].shape[1],5)],\n",
        "                             'SA': x_batches['SA'][:, np.arange(0,x_batches['SA'].shape[1],5)],\n",
        "                             'TAS': x_batches['TAS'][:, np.arange(0,x_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': x_batches['VIC'][:, np.arange(0,x_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    x_batches_validation_fold[2] = {'NSW': x_batches['NSW'][:, np.arange(1,x_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': x_batches['QLD'][:, np.arange(1,x_batches['QLD'].shape[1],5)],\n",
        "                             'SA': x_batches['SA'][:, np.arange(1,x_batches['SA'].shape[1],5)],\n",
        "                             'TAS': x_batches['TAS'][:, np.arange(1,x_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': x_batches['VIC'][:, np.arange(1,x_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    x_batches_validation_fold[3] = {'NSW': x_batches['NSW'][:, np.arange(2,x_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': x_batches['QLD'][:, np.arange(2,x_batches['QLD'].shape[1],5)],\n",
        "                             'SA': x_batches['SA'][:, np.arange(2,x_batches['SA'].shape[1],5)],\n",
        "                             'TAS': x_batches['TAS'][:, np.arange(2,x_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': x_batches['VIC'][:, np.arange(2,x_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    x_batches_validation_fold[4] = {'NSW': x_batches['NSW'][:,np.arange(3,x_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': x_batches['QLD'][:, np.arange(3,x_batches['QLD'].shape[1],5)],\n",
        "                             'SA': x_batches['SA'][:, np.arange(3,x_batches['SA'].shape[1],5)],\n",
        "                             'TAS': x_batches['TAS'][:, np.arange(3,x_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': x_batches['VIC'][:, np.arange(3,x_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    x_batches_validation_fold[5] = {'NSW': x_batches['NSW'][:, np.arange(4,x_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': x_batches['QLD'][:, np.arange(4,x_batches['QLD'].shape[1],5)],\n",
        "                             'SA': x_batches['SA'][:, np.arange(4,x_batches['SA'].shape[1],5)],\n",
        "                             'TAS': x_batches['TAS'][:, np.arange(4,x_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': x_batches['VIC'][:, np.arange(4,x_batches['VIC'].shape[1],5)]}\n",
        "     \n",
        "    y_batches_validation_fold[1] = {'NSW': y_batches['NSW'][:, np.arange(0,y_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': y_batches['QLD'][:, np.arange(0,y_batches['QLD'].shape[1],5)],\n",
        "                             'SA': y_batches['SA'][:, np.arange(0,y_batches['SA'].shape[1],5)],\n",
        "                             'TAS': y_batches['TAS'][:, np.arange(0,y_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': y_batches['VIC'][:, np.arange(0,y_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    y_batches_validation_fold[2] = {'NSW': y_batches['NSW'][:, np.arange(1,y_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': y_batches['QLD'][:, np.arange(1,y_batches['QLD'].shape[1],5)],\n",
        "                             'SA': y_batches['SA'][:, np.arange(1,y_batches['SA'].shape[1],5)],\n",
        "                             'TAS': y_batches['TAS'][:, np.arange(1,y_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': y_batches['VIC'][:, np.arange(1,y_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    y_batches_validation_fold[3] = {'NSW': y_batches['NSW'][:, np.arange(2,y_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': y_batches['QLD'][:, np.arange(2,y_batches['QLD'].shape[1],5)],\n",
        "                             'SA': y_batches['SA'][:, np.arange(2,y_batches['SA'].shape[1],5)],\n",
        "                             'TAS': y_batches['TAS'][:, np.arange(2,y_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': y_batches['VIC'][:, np.arange(2,y_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    y_batches_validation_fold[4] = {'NSW': y_batches['NSW'][:, np.arange(3,y_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': y_batches['QLD'][:, np.arange(3,y_batches['QLD'].shape[1],5)],\n",
        "                             'SA': y_batches['SA'][:, np.arange(3,y_batches['SA'].shape[1],5)],\n",
        "                             'TAS': y_batches['TAS'][:, np.arange(3,y_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': y_batches['VIC'][:, np.arange(3,y_batches['VIC'].shape[1],5)]}\n",
        "    \n",
        "    y_batches_validation_fold[5] = {'NSW': y_batches['NSW'][:, np.arange(4,y_batches['NSW'].shape[1],5)],\n",
        "                             'QLD': y_batches['QLD'][:, np.arange(4,y_batches['QLD'].shape[1],5)],\n",
        "                             'SA': y_batches['SA'][:, np.arange(4,y_batches['SA'].shape[1],5)],\n",
        "                             'TAS': y_batches['TAS'][:, np.arange(4,y_batches['TAS'].shape[1],5)],\n",
        "                             'VIC': y_batches['VIC'][:, np.arange(4,y_batches['VIC'].shape[1],5)]}\n",
        " \n",
        "    \n",
        "    #Making training sets\n",
        "    x_batches_train_fold[1] = {'NSW': x_batches['NSW'][:, [x for x in np.arange(0,x_batches['NSW'].shape[1]) if x not in np.arange(0,x_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': x_batches['QLD'][:, [x for x in np.arange(0,x_batches['QLD'].shape[1]) if x not in np.arange(0,x_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': x_batches['SA'][:, [x for x in np.arange(0,x_batches['SA'].shape[1]) if x not in np.arange(0,x_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': x_batches['TAS'][:, [x for x in np.arange(0,x_batches['TAS'].shape[1]) if x not in np.arange(0,x_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': x_batches['VIC'][:, [x for x in np.arange(0,x_batches['VIC'].shape[1]) if x not in np.arange(0,x_batches['VIC'].shape[1],5)] ]}\n",
        "    \n",
        "    x_batches_train_fold[2] = {'NSW': x_batches['NSW'][:, [x for x in np.arange(1,x_batches['NSW'].shape[1]) if x not in np.arange(1,x_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': x_batches['QLD'][:, [x for x in np.arange(1,x_batches['QLD'].shape[1]) if x not in np.arange(1,x_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': x_batches['SA'][:, [x for x in np.arange(1,x_batches['SA'].shape[1]) if x not in np.arange(1,x_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': x_batches['TAS'][:, [x for x in np.arange(1,x_batches['TAS'].shape[1]) if x not in np.arange(1,x_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': x_batches['VIC'][:, [x for x in np.arange(1,x_batches['VIC'].shape[1]) if x not in np.arange(1,x_batches['VIC'].shape[1],5)] ]}\n",
        "    \n",
        "    x_batches_train_fold[3] = {'NSW': x_batches['NSW'][:, [x for x in np.arange(2,x_batches['NSW'].shape[1]) if x not in np.arange(2,x_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': x_batches['QLD'][:, [x for x in np.arange(2,x_batches['QLD'].shape[1]) if x not in np.arange(2,x_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': x_batches['SA'][:, [x for x in np.arange(2,x_batches['SA'].shape[1]) if x not in np.arange(2,x_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': x_batches['TAS'][:, [x for x in np.arange(2,x_batches['TAS'].shape[1]) if x not in np.arange(2,x_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': x_batches['VIC'][:, [x for x in np.arange(2,x_batches['VIC'].shape[1]) if x not in np.arange(2,x_batches['VIC'].shape[1],5)] ]}\n",
        "    \n",
        "    x_batches_train_fold[4] = {'NSW': x_batches['NSW'][:, [x for x in np.arange(3,x_batches['NSW'].shape[1]) if x not in np.arange(3,x_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': x_batches['QLD'][:, [x for x in np.arange(3,x_batches['QLD'].shape[1]) if x not in np.arange(3,x_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': x_batches['SA'][:, [x for x in np.arange(3,x_batches['SA'].shape[1]) if x not in np.arange(3,x_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': x_batches['TAS'][:, [x for x in np.arange(3,x_batches['TAS'].shape[1]) if x not in np.arange(3,x_batches['TAS'].shape[1],5)]],\n",
        "                             'VIC': x_batches['VIC'][:, [x for x in np.arange(3,x_batches['VIC'].shape[1]) if x not in np.arange(3,x_batches['VIC'].shape[1],5)]]}\n",
        "    \n",
        "    x_batches_train_fold[5] = {'NSW': x_batches['NSW'][:, [x for x in np.arange(4,x_batches['NSW'].shape[1]) if x not in np.arange(4,x_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': x_batches['QLD'][:, [x for x in np.arange(4,x_batches['QLD'].shape[1]) if x not in np.arange(4,x_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': x_batches['SA'][:, [x for x in np.arange(4,x_batches['SA'].shape[1]) if x not in np.arange(4,x_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': x_batches['TAS'][:, [x for x in np.arange(4,x_batches['TAS'].shape[1]) if x not in np.arange(4,x_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': x_batches['VIC'][:, [x for x in np.arange(4,x_batches['VIC'].shape[1]) if x not in np.arange(4,x_batches['VIC'].shape[1],5)] ]}\n",
        "\n",
        "    y_batches_train_fold[1] = {'NSW': y_batches['NSW'][:, [x for x in np.arange(0,y_batches['NSW'].shape[1]) if x not in np.arange(0,y_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': y_batches['QLD'][:, [x for x in np.arange(0,y_batches['QLD'].shape[1]) if x not in np.arange(0,y_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': y_batches['SA'][:, [x for x in np.arange(0,y_batches['SA'].shape[1]) if x not in np.arange(0,y_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': y_batches['TAS'][:, [x for x in np.arange(0,y_batches['TAS'].shape[1]) if x not in np.arange(0,y_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': y_batches['VIC'][:, [x for x in np.arange(0,y_batches['VIC'].shape[1]) if x not in np.arange(0,y_batches['VIC'].shape[1],5)] ]}\n",
        "    \n",
        "    y_batches_train_fold[2] = {'NSW': y_batches['NSW'][:, [x for x in np.arange(1,y_batches['NSW'].shape[1]) if x not in np.arange(1,y_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': y_batches['QLD'][:, [x for x in np.arange(1,y_batches['QLD'].shape[1]) if x not in np.arange(1,y_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': y_batches['SA'][:, [x for x in np.arange(1,y_batches['SA'].shape[1]) if x not in np.arange(1,y_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': y_batches['TAS'][:, [x for x in np.arange(1,y_batches['TAS'].shape[1]) if x not in np.arange(1,y_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': y_batches['VIC'][:, [x for x in np.arange(1,y_batches['VIC'].shape[1]) if x not in np.arange(1,y_batches['VIC'].shape[1],5)] ]}\n",
        "    \n",
        "    y_batches_train_fold[3] = {'NSW': y_batches['NSW'][:, [x for x in np.arange(2,y_batches['NSW'].shape[1]) if x not in np.arange(2,y_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': y_batches['QLD'][:, [x for x in np.arange(2,y_batches['QLD'].shape[1]) if x not in np.arange(2,y_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': y_batches['SA'][:, [x for x in np.arange(2,y_batches['SA'].shape[1]) if x not in np.arange(2,y_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': y_batches['TAS'][:, [x for x in np.arange(2,y_batches['TAS'].shape[1]) if x not in np.arange(2,y_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': y_batches['VIC'][:, [x for x in np.arange(2,y_batches['VIC'].shape[1]) if x not in np.arange(2,y_batches['VIC'].shape[1],5)] ]}\n",
        "    \n",
        "    y_batches_train_fold[4] = {'NSW': y_batches['NSW'][:, [x for x in np.arange(3,y_batches['NSW'].shape[1]) if x not in np.arange(3,y_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': y_batches['QLD'][:, [x for x in np.arange(3,y_batches['QLD'].shape[1]) if x not in np.arange(3,y_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': y_batches['SA'][:, [x for x in np.arange(3,y_batches['SA'].shape[1]) if x not in np.arange(3,y_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': y_batches['TAS'][:, [x for x in np.arange(3,y_batches['TAS'].shape[1]) if x not in np.arange(3,y_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': y_batches['VIC'][:, [x for x in np.arange(3,y_batches['VIC'].shape[1]) if x not in np.arange(3,y_batches['VIC'].shape[1],5)] ]}\n",
        "\n",
        "    y_batches_train_fold[5] = {'NSW': y_batches['NSW'][:, [x for x in np.arange(4,y_batches['NSW'].shape[1]) if x not in np.arange(4,y_batches['NSW'].shape[1],5)] ],\n",
        "                             'QLD': y_batches['QLD'][:, [x for x in np.arange(4,y_batches['QLD'].shape[1]) if x not in np.arange(4,y_batches['QLD'].shape[1],5)] ],\n",
        "                             'SA': y_batches['SA'][:, [x for x in np.arange(4,y_batches['SA'].shape[1]) if x not in np.arange(4,y_batches['SA'].shape[1],5)] ],\n",
        "                             'TAS': y_batches['TAS'][:, [x for x in np.arange(4,y_batches['TAS'].shape[1]) if x not in np.arange(4,y_batches['TAS'].shape[1],5)] ],\n",
        "                             'VIC': y_batches['VIC'][:, [x for x in np.arange(4,y_batches['VIC'].shape[1]) if x not in np.arange(4,y_batches['VIC'].shape[1],5)] ]}\n",
        "\n",
        "\n",
        "    for st in state.values():\n",
        "        for fold in np.arange(1,6):\n",
        "            print(\"Train and validation from state \", st, \" fold \", fold)\n",
        "            net = Network([x_size, hidden, y_size], Activation.tanh, QuadraticCost)\n",
        "            if cso:\n",
        "                fname = \"kernelBias5Fold\" + st + \".npy\"\n",
        "                if not path.exists(fname):\n",
        "                    print(\"Weights and biases initialization for state \",st ,\" in progress...\")\n",
        "                    randInt = np.random.randint(x_batches[st].shape[1])\n",
        "                    net.cso(100,x_batches[st][:, randInt].reshape(x_size,1),\n",
        "                                    y_batches[st][:, randInt].reshape(y_size,1),\n",
        "                                    net.multiObjectiveFunction,-0.6,0.6,net.dim ,100)\n",
        "                    \n",
        "                    net.set_weight_bias(np.array(net.get_Gbest()))\n",
        "                    np.save(fname, np.array(net.get_Gbest()))\n",
        "            \n",
        "                net.set_weight_bias(np.load(fname))\n",
        "            \n",
        "            num_epochs = 1500\n",
        "            lmbda = 2\n",
        "            \n",
        "            if cso:\n",
        "                fname = \"results_\"+ st + \"_5Fold_\" + str(fold) + \"CSO\"\n",
        "            else:\n",
        "                fname = \"results_\"+ st + \"_5Fold_\" + str(fold) + \"GD\" #GD: Gaussian Distribution\n",
        "            \n",
        "            evaluation_cost, eval_mape, eval_rmse, eval_mae, training_cost, training_mape, training_rmse, training_mae = net.SGD(\n",
        "                    x_batches_train_fold[fold][st],y_batches_train_fold[fold][st],\n",
        "                    num_epochs, 10, 0.01, x_batches_validation_fold[fold][st],\n",
        "                    y_batches_validation_fold[fold][st],\n",
        "                    lmbda, monitor_evaluation_cost = True,\n",
        "                    monitor_evaluation_accuracy = True,\n",
        "                    monitor_training_cost = True,\n",
        "                    monitor_training_accuracy = True,\n",
        "                    output2D = True)\n",
        "            \n",
        "            f = open(fname, \"w\")\n",
        "            json.dump([evaluation_cost, eval_mape, eval_rmse, eval_mae, training_cost, training_mape, training_rmse, training_mae], f)\n",
        "            f.close()\n",
        "            \n",
        "#            make_plots(fname, num_epochs,\n",
        "#                       training_cost_xmin = 0,\n",
        "#                       test_accuracy_xmin = 0,\n",
        "#                       test_cost_xmin = 0, \n",
        "#                       training_accuracy_xmin = 0)\n",
        "            \n",
        "       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2n6XfNislYHl",
        "colab_type": "code",
        "outputId": "b52a3294-5358-496a-89ad-a38e6bebade4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59151
        }
      },
      "cell_type": "code",
      "source": [
        "fiveFoldCrossValidation(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train and validation from state  NSW  fold  1\n",
            "Weights and biases initialization for state  NSW  in progress...\n",
            "Epochs 0\n",
            "Cost on training data: 84.56728676191925\n",
            "MAPE on training data: 1238.9423253976988\n",
            "RMSE on training data: 0.08280931997577853\n",
            "MAE on training data: 0.05207685484165203\n",
            "Cost on evaluation data: 22.846918870071352\n",
            "MAPE on evaluation data: 1238.7962154815139\n",
            "RMSE on evaluation data: 0.08281270503130818\n",
            "MAE on evaluation data: 0.052082220455264935\n",
            "Epochs 100\n",
            "Cost on training data: 0.796087722219899\n",
            "MAPE on training data: 35.11321160737781\n",
            "RMSE on training data: 0.001828935671895454\n",
            "MAE on training data: 0.0014792201175132806\n",
            "Cost on evaluation data: 0.7648869558980752\n",
            "MAPE on evaluation data: 35.05531317020373\n",
            "RMSE on evaluation data: 0.001825284401958013\n",
            "MAE on evaluation data: 0.0014767462514660619\n",
            "Epochs 200\n",
            "Cost on training data: 0.16960644080471907\n",
            "MAPE on training data: 33.10886030234938\n",
            "RMSE on training data: 0.001645468451957382\n",
            "MAE on training data: 0.0013943019790993631\n",
            "Cost on evaluation data: 0.14453297172738924\n",
            "MAPE on evaluation data: 33.02521032974765\n",
            "RMSE on evaluation data: 0.0016378602608479631\n",
            "MAE on evaluation data: 0.0013905020159587504\n",
            "Epochs 300\n",
            "Cost on training data: 0.02992916333667514\n",
            "MAPE on training data: 25.733240405938908\n",
            "RMSE on training data: 0.0014136715933534066\n",
            "MAE on training data: 0.0010991518886309855\n",
            "Cost on evaluation data: 0.011243249746115722\n",
            "MAPE on evaluation data: 25.51640149889529\n",
            "RMSE on evaluation data: 0.0014051539923222015\n",
            "MAE on evaluation data: 0.0010884618669990862\n",
            "Epochs 400\n",
            "Cost on training data: 0.012126065987913492\n",
            "MAPE on training data: 17.00865803627006\n",
            "RMSE on training data: 0.0009825589014128978\n",
            "MAE on training data: 0.0007194232059953599\n",
            "Cost on evaluation data: 0.00314672020686427\n",
            "MAPE on evaluation data: 16.639877824877047\n",
            "RMSE on evaluation data: 0.000969024814658937\n",
            "MAE on evaluation data: 0.000701909791156977\n",
            "Epochs 500\n",
            "Cost on training data: 0.005803910951697444\n",
            "MAPE on training data: 12.804974390648315\n",
            "RMSE on training data: 0.0006859574412547997\n",
            "MAE on training data: 0.0005407316459186401\n",
            "Cost on evaluation data: 0.0013703140199673918\n",
            "MAPE on evaluation data: 12.381400571153245\n",
            "RMSE on evaluation data: 0.0006665112974186679\n",
            "MAE on evaluation data: 0.0005207854773314563\n",
            "Epochs 600\n",
            "Cost on training data: 0.005803904323765876\n",
            "MAPE on training data: 12.80496795099418\n",
            "RMSE on training data: 0.0006859574246043569\n",
            "MAE on training data: 0.0005407315472086598\n",
            "Cost on evaluation data: 0.001370312303497394\n",
            "MAPE on evaluation data: 12.381391337958544\n",
            "RMSE on evaluation data: 0.0006665112438469826\n",
            "MAE on evaluation data: 0.0005207852435149941\n",
            "Epochs 700\n",
            "Cost on training data: 0.005803904317288009\n",
            "MAPE on training data: 12.804967945081842\n",
            "RMSE on training data: 0.0006859574243964801\n",
            "MAE on training data: 0.0005407315467788336\n",
            "Cost on evaluation data: 0.0013703123019233852\n",
            "MAPE on evaluation data: 12.381391332678076\n",
            "RMSE on evaluation data: 0.0006665112436309316\n",
            "MAE on evaluation data: 0.0005207852431138678\n",
            "Epochs 800\n",
            "Cost on training data: 0.005803904310810206\n",
            "MAPE on training data: 12.80496793916948\n",
            "RMSE on training data: 0.0006859574241886014\n",
            "MAE on training data: 0.0005407315463490056\n",
            "Cost on evaluation data: 0.0013703123003494591\n",
            "MAPE on evaluation data: 12.381391327397651\n",
            "RMSE on evaluation data: 0.000666511243414884\n",
            "MAE on evaluation data: 0.0005207852427127427\n",
            "Epochs 900\n",
            "Cost on training data: 0.0058039075861521785\n",
            "MAPE on training data: 12.80497017572985\n",
            "RMSE on training data: 0.0006859573785962573\n",
            "MAE on training data: 0.0005407313686599375\n",
            "Cost on evaluation data: 0.0013703131907748325\n",
            "MAPE on evaluation data: 12.381394941289772\n",
            "RMSE on evaluation data: 0.0006665112221159123\n",
            "MAE on evaluation data: 0.0005207851389104113\n",
            "Epochs 1000\n",
            "Cost on training data: 0.005803907579669741\n",
            "MAPE on training data: 12.804970169809197\n",
            "RMSE on training data: 0.0006859573783883022\n",
            "MAE on training data: 0.0005407313682298648\n",
            "Cost on evaluation data: 0.0013703131891998257\n",
            "MAPE on evaluation data: 12.381394936004122\n",
            "RMSE on evaluation data: 0.0006665112218997498\n",
            "MAE on evaluation data: 0.0005207851385091637\n",
            "Epochs 1100\n",
            "Cost on training data: 0.005803907573187377\n",
            "MAPE on training data: 12.80497016388856\n",
            "RMSE on training data: 0.0006859573781803474\n",
            "MAE on training data: 0.0005407313677997926\n",
            "Cost on evaluation data: 0.0013703131876248943\n",
            "MAPE on evaluation data: 12.381394930718509\n",
            "RMSE on evaluation data: 0.0006665112216835886\n",
            "MAE on evaluation data: 0.0005207851381079171\n",
            "Epochs 1200\n",
            "Cost on training data: 0.005803907566705083\n",
            "MAPE on training data: 12.804970157967919\n",
            "RMSE on training data: 0.0006859573779723928\n",
            "MAE on training data: 0.0005407313673697201\n",
            "Cost on evaluation data: 0.0013703131860500503\n",
            "MAPE on evaluation data: 12.381394925432854\n",
            "RMSE on evaluation data: 0.0006665112214674263\n",
            "MAE on evaluation data: 0.0005207851377066686\n",
            "Epochs 1300\n",
            "Cost on training data: 0.005803906775974538\n",
            "MAPE on training data: 12.80497632190979\n",
            "RMSE on training data: 0.0006859573410220209\n",
            "MAE on training data: 0.0005407313500438968\n",
            "Cost on evaluation data: 0.0013703130702786214\n",
            "MAPE on evaluation data: 12.381399959922176\n",
            "RMSE on evaluation data: 0.0006665112419562863\n",
            "MAE on evaluation data: 0.0005207850866180627\n",
            "Epochs 1400\n",
            "Cost on training data: 0.00580390776420243\n",
            "MAPE on training data: 12.804971333063344\n",
            "RMSE on training data: 0.0006859573712515767\n",
            "MAE on training data: 0.0005407313816227705\n",
            "Cost on evaluation data: 0.001370313255330239\n",
            "MAPE on evaluation data: 12.381396444154893\n",
            "RMSE on evaluation data: 0.0006665113038154663\n",
            "MAE on evaluation data: 0.0005207851758416985\n",
            "Train and validation from state  NSW  fold  2\n",
            "Epochs 0\n",
            "Cost on training data: 86.6224936148393\n",
            "MAPE on training data: 1252.3867203474697\n",
            "RMSE on training data: 0.08392247308333792\n",
            "MAE on training data: 0.05265024007680734\n",
            "Cost on evaluation data: 23.3994621171805\n",
            "MAPE on evaluation data: 1254.0631747709274\n",
            "RMSE on evaluation data: 0.08391040001373978\n",
            "MAE on evaluation data: 0.05264591494498361\n",
            "Epochs 100\n",
            "Cost on training data: 0.8151240992409521\n",
            "MAPE on training data: 35.56049701786059\n",
            "RMSE on training data: 0.001848989204108476\n",
            "MAE on training data: 0.001498893688079488\n",
            "Cost on evaluation data: 0.7832726790298737\n",
            "MAPE on evaluation data: 35.45784895450934\n",
            "RMSE on evaluation data: 0.0018314492504372208\n",
            "MAE on evaluation data: 0.0014875117311209376\n",
            "Epochs 200\n",
            "Cost on training data: 0.1816963192111846\n",
            "MAPE on training data: 33.4597243924535\n",
            "RMSE on training data: 0.0016601790842157142\n",
            "MAE on training data: 0.001409891980323971\n",
            "Cost on evaluation data: 0.1561905441083862\n",
            "MAPE on evaluation data: 33.405173606797185\n",
            "RMSE on evaluation data: 0.001648529581753429\n",
            "MAE on evaluation data: 0.0014015095724523637\n",
            "Epochs 300\n",
            "Cost on training data: 0.031296935293776584\n",
            "MAPE on training data: 26.242328245375212\n",
            "RMSE on training data: 0.0014280232723155436\n",
            "MAE on training data: 0.001120984358949362\n",
            "Cost on evaluation data: 0.012199090586220573\n",
            "MAPE on evaluation data: 26.03036943931264\n",
            "RMSE on evaluation data: 0.0014106225613042557\n",
            "MAE on evaluation data: 0.0011051251054781009\n",
            "Epochs 400\n",
            "Cost on training data: 0.013185750574929076\n",
            "MAPE on training data: 17.722456337634153\n",
            "RMSE on training data: 0.001023918839073452\n",
            "MAE on training data: 0.0007474801626330355\n",
            "Cost on evaluation data: 0.003438115969559151\n",
            "MAPE on evaluation data: 17.43058323971143\n",
            "RMSE on evaluation data: 0.0010068896106886877\n",
            "MAE on evaluation data: 0.0007295633899759203\n",
            "Epochs 500\n",
            "Cost on training data: 0.005824953593216321\n",
            "MAPE on training data: 12.79674204427465\n",
            "RMSE on training data: 0.0006880366832061947\n",
            "MAE on training data: 0.0005406107135319787\n",
            "Cost on evaluation data: 0.001332320688480832\n",
            "MAPE on evaluation data: 12.399679389783397\n",
            "RMSE on evaluation data: 0.0006578290863831081\n",
            "MAE on evaluation data: 0.0005179273404622275\n",
            "Epochs 600\n",
            "Cost on training data: 0.005824953590858104\n",
            "MAPE on training data: 12.796742040017053\n",
            "RMSE on training data: 0.0006880366830672766\n",
            "MAE on training data: 0.0005406107133643639\n",
            "Cost on evaluation data: 0.0013323206879009503\n",
            "MAPE on evaluation data: 12.39967938505614\n",
            "RMSE on evaluation data: 0.0006578290862282898\n",
            "MAE on evaluation data: 0.0005179273402763222\n",
            "Epochs 700\n",
            "Cost on training data: 0.00582495358850421\n",
            "MAPE on training data: 12.796742035707979\n",
            "RMSE on training data: 0.000688036682928202\n",
            "MAE on training data: 0.0005406107131957303\n",
            "Cost on evaluation data: 0.0013323206873211437\n",
            "MAPE on evaluation data: 12.399679380274279\n",
            "RMSE on evaluation data: 0.0006578290860726739\n",
            "MAE on evaluation data: 0.0005179273400892058\n",
            "Epochs 800\n",
            "Cost on training data: 0.0058249535861503625\n",
            "MAPE on training data: 12.796742031398917\n",
            "RMSE on training data: 0.000688036682789128\n",
            "MAE on training data: 0.0005406107130270973\n",
            "Cost on evaluation data: 0.0013323206867413935\n",
            "MAPE on evaluation data: 12.399679375492406\n",
            "RMSE on evaluation data: 0.0006578290859170579\n",
            "MAE on evaluation data: 0.0005179273399020893\n",
            "Epochs 900\n",
            "Cost on training data: 0.005824951134598835\n",
            "MAPE on training data: 12.796766588312334\n",
            "RMSE on training data: 0.0006880368153053324\n",
            "MAE on training data: 0.0005406112078244756\n",
            "Cost on evaluation data: 0.001332320581231888\n",
            "MAPE on evaluation data: 12.399706993444026\n",
            "RMSE on evaluation data: 0.0006578294913013732\n",
            "MAE on evaluation data: 0.0005179279983495847\n",
            "Epochs 1000\n",
            "Cost on training data: 0.005824947486588823\n",
            "MAPE on training data: 12.796755454763872\n",
            "RMSE on training data: 0.0006880368215442632\n",
            "MAE on training data: 0.0005406109930805334\n",
            "Cost on evaluation data: 0.001332319388174109\n",
            "MAPE on evaluation data: 12.399699543578647\n",
            "RMSE on evaluation data: 0.0006578295439731156\n",
            "MAE on evaluation data: 0.0005179279410574335\n",
            "Epochs 1100\n",
            "Cost on training data: 0.005824947484264108\n",
            "MAPE on training data: 12.79675545047392\n",
            "RMSE on training data: 0.0006880368214055345\n",
            "MAE on training data: 0.0005406109929127854\n",
            "Cost on evaluation data: 0.0013323193876018631\n",
            "MAPE on evaluation data: 12.399699538815904\n",
            "RMSE on evaluation data: 0.0006578295438179608\n",
            "MAE on evaluation data: 0.0005179279408711941\n",
            "Epochs 1200\n",
            "Cost on training data: 0.005824947481939444\n",
            "MAPE on training data: 12.796755446183921\n",
            "RMSE on training data: 0.0006880368212668037\n",
            "MAE on training data: 0.0005406109927450358\n",
            "Cost on evaluation data: 0.0013323193870296759\n",
            "MAPE on evaluation data: 12.399699534053141\n",
            "RMSE on evaluation data: 0.0006578295436628065\n",
            "MAE on evaluation data: 0.0005179279406849541\n",
            "Epochs 1300\n",
            "Cost on training data: 0.005824947479614827\n",
            "MAPE on training data: 12.796755441893954\n",
            "RMSE on training data: 0.0006880368211280738\n",
            "MAE on training data: 0.0005406109925772876\n",
            "Cost on evaluation data: 0.0013323193864575276\n",
            "MAPE on evaluation data: 12.39969952929027\n",
            "RMSE on evaluation data: 0.0006578295435076484\n",
            "MAE on evaluation data: 0.0005179279404987098\n",
            "Epochs 1400\n",
            "Cost on training data: 0.005824947477290252\n",
            "MAPE on training data: 12.796755437603963\n",
            "RMSE on training data: 0.0006880368209893436\n",
            "MAE on training data: 0.0005406109924095388\n",
            "Cost on evaluation data: 0.0013323193858854382\n",
            "MAPE on evaluation data: 12.399699524527543\n",
            "RMSE on evaluation data: 0.0006578295433524931\n",
            "MAE on evaluation data: 0.0005179279403124718\n",
            "Train and validation from state  NSW  fold  3\n",
            "Epochs 0\n",
            "Cost on training data: 86.45025558445218\n",
            "MAPE on training data: 1252.597496853649\n",
            "RMSE on training data: 0.08391957101547429\n",
            "MAE on training data: 0.05264832461853214\n",
            "Cost on evaluation data: 23.403101865085034\n",
            "MAPE on evaluation data: 1253.0605026832677\n",
            "RMSE on evaluation data: 0.08392398219115246\n",
            "MAE on evaluation data: 0.052644138760905644\n",
            "Epochs 100\n",
            "Cost on training data: 0.8130368999333083\n",
            "MAPE on training data: 35.55558666311578\n",
            "RMSE on training data: 0.0018474821412489066\n",
            "MAE on training data: 0.001497082421401448\n",
            "Cost on evaluation data: 0.7814278310412337\n",
            "MAPE on evaluation data: 35.53643194348452\n",
            "RMSE on evaluation data: 0.001852864160357763\n",
            "MAE on evaluation data: 0.0014991365799292256\n",
            "Epochs 200\n",
            "Cost on training data: 0.18033922415481113\n",
            "MAPE on training data: 33.517753587038094\n",
            "RMSE on training data: 0.001660540867143108\n",
            "MAE on training data: 0.0014107950241459934\n",
            "Cost on evaluation data: 0.15508174416744597\n",
            "MAPE on evaluation data: 33.5250565311059\n",
            "RMSE on evaluation data: 0.0016651608830794379\n",
            "MAE on evaluation data: 0.00141324791552983\n",
            "Epochs 300\n",
            "Cost on training data: 0.030877337884426422\n",
            "MAPE on training data: 26.074044378027256\n",
            "RMSE on training data: 0.001421684882924523\n",
            "MAE on training data: 0.0011127871248843835\n",
            "Cost on evaluation data: 0.012255647445475137\n",
            "MAPE on evaluation data: 26.223903156166777\n",
            "RMSE on evaluation data: 0.0014283300342068383\n",
            "MAE on evaluation data: 0.001121776081443016\n",
            "Epochs 400\n",
            "Cost on training data: 0.013024552309687083\n",
            "MAPE on training data: 17.57377998386018\n",
            "RMSE on training data: 0.0010204119554384054\n",
            "MAE on training data: 0.0007409705269085585\n",
            "Cost on evaluation data: 0.0035910131481266603\n",
            "MAPE on evaluation data: 17.90769382364624\n",
            "RMSE on evaluation data: 0.0010284158936674618\n",
            "MAE on evaluation data: 0.0007573022681538966\n",
            "Epochs 500\n",
            "Cost on training data: 0.005658059261760453\n",
            "MAPE on training data: 12.571964909030717\n",
            "RMSE on training data: 0.0006792580916098266\n",
            "MAE on training data: 0.0005315917824278157\n",
            "Cost on evaluation data: 0.0014809141815460107\n",
            "MAPE on evaluation data: 12.973171989988847\n",
            "RMSE on evaluation data: 0.0006933367364766916\n",
            "MAE on evaluation data: 0.0005512016727442788\n",
            "Epochs 600\n",
            "Cost on training data: 0.005658059258463239\n",
            "MAPE on training data: 12.5719649198698\n",
            "RMSE on training data: 0.00067925809136561\n",
            "MAE on training data: 0.0005315917823358451\n",
            "Cost on evaluation data: 0.0014809141804565708\n",
            "MAPE on evaluation data: 12.973172000416708\n",
            "RMSE on evaluation data: 0.0006933367361818463\n",
            "MAE on evaluation data: 0.0005512016726116588\n",
            "Epochs 700\n",
            "Cost on training data: 0.005658059255197834\n",
            "MAPE on training data: 12.571964930617366\n",
            "RMSE on training data: 0.0006792580911221895\n",
            "MAE on training data: 0.0005315917822428238\n",
            "Cost on evaluation data: 0.001480914179376459\n",
            "MAPE on evaluation data: 12.973172010746456\n",
            "RMSE on evaluation data: 0.0006933367358880112\n",
            "MAE on evaluation data: 0.0005512016724778163\n",
            "Epochs 800\n",
            "Cost on training data: 0.005658059251932491\n",
            "MAPE on training data: 12.571964941364927\n",
            "RMSE on training data: 0.0006792580908787679\n",
            "MAE on training data: 0.0005315917821498013\n",
            "Cost on evaluation data: 0.0014809141782964306\n",
            "MAPE on evaluation data: 12.973172021076271\n",
            "RMSE on evaluation data: 0.0006933367355941779\n",
            "MAE on evaluation data: 0.0005512016723439761\n",
            "Epochs 900\n",
            "Cost on training data: 0.005658059248667252\n",
            "MAPE on training data: 12.571964952112522\n",
            "RMSE on training data: 0.0006792580906353471\n",
            "MAE on training data: 0.0005315917820567799\n",
            "Cost on evaluation data: 0.0014809141772164683\n",
            "MAPE on evaluation data: 12.973172031406033\n",
            "RMSE on evaluation data: 0.0006933367353003416\n",
            "MAE on evaluation data: 0.0005512016722101326\n",
            "Epochs 1000\n",
            "Cost on training data: 0.005658060030608205\n",
            "MAPE on training data: 12.571964154109446\n",
            "RMSE on training data: 0.0006792581060079491\n",
            "MAE on training data: 0.0005315918477057313\n",
            "Cost on evaluation data: 0.001480914412117533\n",
            "MAPE on evaluation data: 12.973170719766088\n",
            "RMSE on evaluation data: 0.0006933367715729409\n",
            "MAE on evaluation data: 0.0005512017192211128\n",
            "Epochs 1100\n",
            "Cost on training data: 0.005658060027342563\n",
            "MAPE on training data: 12.57196416486278\n",
            "RMSE on training data: 0.0006792581057643692\n",
            "MAE on training data: 0.0005315918476127532\n",
            "Cost on evaluation data: 0.0014809144110374988\n",
            "MAPE on evaluation data: 12.97317073009672\n",
            "RMSE on evaluation data: 0.0006933367712789098\n",
            "MAE on evaluation data: 0.0005512017190870844\n",
            "Epochs 1200\n",
            "Cost on training data: 0.005658060990248695\n",
            "MAPE on training data: 12.571963181168929\n",
            "RMSE on training data: 0.0006792581247638934\n",
            "MAE on training data: 0.0005315919283568114\n",
            "Cost on evaluation data: 0.0014809147002913393\n",
            "MAPE on evaluation data: 12.973169114919623\n",
            "RMSE on evaluation data: 0.0006933368159879788\n",
            "MAE on evaluation data: 0.0005512017769227941\n",
            "Epochs 1300\n",
            "Cost on training data: 0.005658061213164923\n",
            "MAPE on training data: 12.571963168841693\n",
            "RMSE on training data: 0.0006792581199125258\n",
            "MAE on training data: 0.0005315920046464756\n",
            "Cost on evaluation data: 0.0014809147857084849\n",
            "MAPE on evaluation data: 12.97316826362564\n",
            "RMSE on evaluation data: 0.0006933368357507465\n",
            "MAE on evaluation data: 0.0005512018208332903\n",
            "Epochs 1400\n",
            "Cost on training data: 0.0056580612098992384\n",
            "MAPE on training data: 12.571963179598223\n",
            "RMSE on training data: 0.0006792581196688468\n",
            "MAE on training data: 0.0005315920045535547\n",
            "Cost on evaluation data: 0.0014809147846285722\n",
            "MAPE on evaluation data: 12.973168273956368\n",
            "RMSE on evaluation data: 0.0006933368354566042\n",
            "MAE on evaluation data: 0.000551201820699177\n",
            "Train and validation from state  NSW  fold  4\n",
            "Epochs 0\n",
            "Cost on training data: 86.28613091539742\n",
            "MAPE on training data: 1252.3155659564684\n",
            "RMSE on training data: 0.08392275187203313\n",
            "MAE on training data: 0.05265156243458661\n",
            "Cost on evaluation data: 23.3977062069134\n",
            "MAPE on evaluation data: 1253.8201941391192\n",
            "RMSE on evaluation data: 0.08391073470208767\n",
            "MAE on evaluation data: 0.05264665690844486\n",
            "Epochs 100\n",
            "Cost on training data: 0.81107554515839\n",
            "MAPE on training data: 35.58058984556448\n",
            "RMSE on training data: 0.001850077224655963\n",
            "MAE on training data: 0.0014990245805430612\n",
            "Cost on evaluation data: 0.7793300181654409\n",
            "MAPE on evaluation data: 35.60432328523146\n",
            "RMSE on evaluation data: 0.0018476246736060583\n",
            "MAE on evaluation data: 0.0014977149005686865\n",
            "Epochs 200\n",
            "Cost on training data: 0.1791496902510613\n",
            "MAPE on training data: 33.593107384402686\n",
            "RMSE on training data: 0.0016640630080564593\n",
            "MAE on training data: 0.001414787519323707\n",
            "Cost on evaluation data: 0.1537599675703358\n",
            "MAPE on evaluation data: 33.69176070708938\n",
            "RMSE on evaluation data: 0.0016633042026934248\n",
            "MAE on evaluation data: 0.0014166126990679958\n",
            "Epochs 300\n",
            "Cost on training data: 0.03088796388294009\n",
            "MAPE on training data: 26.121945321559686\n",
            "RMSE on training data: 0.0014264290486375266\n",
            "MAE on training data: 0.0011153586138254624\n",
            "Cost on evaluation data: 0.012091910246001652\n",
            "MAPE on evaluation data: 26.20958940987715\n",
            "RMSE on evaluation data: 0.0014233489176931652\n",
            "MAE on evaluation data: 0.0011162942928509719\n",
            "Epochs 400\n",
            "Cost on training data: 0.013031756063639507\n",
            "MAPE on training data: 17.65034331514012\n",
            "RMSE on training data: 0.0010220145318462423\n",
            "MAE on training data: 0.000744124888579393\n",
            "Cost on evaluation data: 0.0035143213100422436\n",
            "MAPE on evaluation data: 17.728541318321458\n",
            "RMSE on evaluation data: 0.0010185685936006871\n",
            "MAE on evaluation data: 0.0007449951350943709\n",
            "Epochs 500\n",
            "Cost on training data: 0.005702838080355327\n",
            "MAPE on training data: 12.685860789239186\n",
            "RMSE on training data: 0.0006827924259496645\n",
            "MAE on training data: 0.0005356909451857234\n",
            "Cost on evaluation data: 0.0014217574782081012\n",
            "MAPE on evaluation data: 12.783271232104521\n",
            "RMSE on evaluation data: 0.0006794262798686104\n",
            "MAE on evaluation data: 0.0005377097968667912\n",
            "Epochs 600\n",
            "Cost on training data: 0.0057028382485741136\n",
            "MAPE on training data: 12.685853370662715\n",
            "RMSE on training data: 0.0006827923999738417\n",
            "MAE on training data: 0.0005356908346618412\n",
            "Cost on evaluation data: 0.0014217574740774713\n",
            "MAPE on evaluation data: 12.783262310892546\n",
            "RMSE on evaluation data: 0.0006794262353245498\n",
            "MAE on evaluation data: 0.0005377096187712927\n",
            "Epochs 700\n",
            "Cost on training data: 0.005702838249637626\n",
            "MAPE on training data: 12.685853367322885\n",
            "RMSE on training data: 0.0006827923998269118\n",
            "MAE on training data: 0.0005356908344748535\n",
            "Cost on evaluation data: 0.0014217574743687826\n",
            "MAPE on evaluation data: 12.783262306257399\n",
            "RMSE on evaluation data: 0.0006794262351228056\n",
            "MAE on evaluation data: 0.0005377096185269298\n",
            "Epochs 800\n",
            "Cost on training data: 0.005702838250701193\n",
            "MAPE on training data: 12.685853363983018\n",
            "RMSE on training data: 0.0006827923996799793\n",
            "MAE on training data: 0.0005356908342878642\n",
            "Cost on evaluation data: 0.0014217574746601671\n",
            "MAPE on evaluation data: 12.783262301622091\n",
            "RMSE on evaluation data: 0.0006794262349210564\n",
            "MAE on evaluation data: 0.0005377096182825605\n",
            "Epochs 900\n",
            "Cost on training data: 0.005702838251764858\n",
            "MAPE on training data: 12.685853360643195\n",
            "RMSE on training data: 0.0006827923995330492\n",
            "MAE on training data: 0.0005356908341008767\n",
            "Cost on evaluation data: 0.0014217574749516252\n",
            "MAPE on evaluation data: 12.783262296986944\n",
            "RMSE on evaluation data: 0.0006794262347193116\n",
            "MAE on evaluation data: 0.0005377096180381968\n",
            "Epochs 1000\n",
            "Cost on training data: 0.005702838252828592\n",
            "MAPE on training data: 12.68585335730332\n",
            "RMSE on training data: 0.0006827923993861172\n",
            "MAE on training data: 0.0005356908339138866\n",
            "Cost on evaluation data: 0.0014217574752431596\n",
            "MAPE on evaluation data: 12.783262292351658\n",
            "RMSE on evaluation data: 0.000679426234517562\n",
            "MAE on evaluation data: 0.0005377096177938277\n",
            "Epochs 1100\n",
            "Cost on training data: 0.005702838253892394\n",
            "MAPE on training data: 12.685853353963441\n",
            "RMSE on training data: 0.0006827923992391852\n",
            "MAE on training data: 0.0005356908337268967\n",
            "Cost on evaluation data: 0.001421757475534777\n",
            "MAPE on evaluation data: 12.783262287716415\n",
            "RMSE on evaluation data: 0.0006794262343158147\n",
            "MAE on evaluation data: 0.0005377096175494603\n",
            "Epochs 1200\n",
            "Cost on training data: 0.005702874894637651\n",
            "MAPE on training data: 12.686011889505519\n",
            "RMSE on training data: 0.0006827931370381136\n",
            "MAE on training data: 0.0005356955722501768\n",
            "Cost on evaluation data: 0.0014217674608773604\n",
            "MAPE on evaluation data: 12.783539205057684\n",
            "RMSE on evaluation data: 0.0006794278379915484\n",
            "MAE on evaluation data: 0.000537719347726459\n",
            "Epochs 1300\n",
            "Cost on training data: 0.005702884574332077\n",
            "MAPE on training data: 12.68599971320697\n",
            "RMSE on training data: 0.0006827932826985532\n",
            "MAE on training data: 0.0005356954930631279\n",
            "Cost on evaluation data: 0.0014217697832310545\n",
            "MAPE on evaluation data: 12.783527284832966\n",
            "RMSE on evaluation data: 0.0006794278178213643\n",
            "MAE on evaluation data: 0.0005377192907464543\n",
            "Epochs 1400\n",
            "Cost on training data: 0.0057028845753675644\n",
            "MAPE on training data: 12.685999709978239\n",
            "RMSE on training data: 0.0006827932825502032\n",
            "MAE on training data: 0.0005356954928760134\n",
            "Cost on evaluation data: 0.001421769783517068\n",
            "MAPE on evaluation data: 12.783527280336651\n",
            "RMSE on evaluation data: 0.0006794278176188135\n",
            "MAE on evaluation data: 0.0005377192905031574\n",
            "Train and validation from state  NSW  fold  5\n",
            "Epochs 0\n",
            "Cost on training data: 86.10667853964245\n",
            "MAPE on training data: 1253.4454392222574\n",
            "RMSE on training data: 0.08391658786400188\n",
            "MAE on training data: 0.05264823641172818\n",
            "Cost on evaluation data: 23.40602293893973\n",
            "MAPE on evaluation data: 1249.5311167037107\n",
            "RMSE on evaluation data: 0.08393061478336748\n",
            "MAE on evaluation data: 0.05265728187427931\n",
            "Epochs 100\n",
            "Cost on training data: 0.8087161703858695\n",
            "MAPE on training data: 35.51841143297837\n",
            "RMSE on training data: 0.0018452595144655987\n",
            "MAE on training data: 0.0014945825895446233\n",
            "Cost on evaluation data: 0.7775344383964865\n",
            "MAPE on evaluation data: 35.67169969478086\n",
            "RMSE on evaluation data: 0.0018626639832608487\n",
            "MAE on evaluation data: 0.0015071488565756982\n",
            "Epochs 200\n",
            "Cost on training data: 0.17773981108076164\n",
            "MAPE on training data: 33.66739792606203\n",
            "RMSE on training data: 0.0016631326031676561\n",
            "MAE on training data: 0.0014160631038520103\n",
            "Cost on evaluation data: 0.1526452700995577\n",
            "MAPE on evaluation data: 33.72626243014095\n",
            "RMSE on evaluation data: 0.0016789917509652825\n",
            "MAE on evaluation data: 0.0014244760094099661\n",
            "Epochs 300\n",
            "Cost on training data: 0.030586698063567196\n",
            "MAPE on training data: 26.070609261648226\n",
            "RMSE on training data: 0.0014221190298187587\n",
            "MAE on training data: 0.001111088626130578\n",
            "Cost on evaluation data: 0.012164320833203613\n",
            "MAPE on evaluation data: 26.285432574411168\n",
            "RMSE on evaluation data: 0.0014451241971934056\n",
            "MAE on evaluation data: 0.0011280806499696554\n",
            "Epochs 400\n",
            "Cost on training data: 0.012635209748798872\n",
            "MAPE on training data: 17.442339424220073\n",
            "RMSE on training data: 0.001006410781953852\n",
            "MAE on training data: 0.0007342397831256889\n",
            "Cost on evaluation data: 0.0035945906705190066\n",
            "MAPE on evaluation data: 17.757881646619538\n",
            "RMSE on evaluation data: 0.0010331102787681345\n",
            "MAE on evaluation data: 0.0007548602108336988\n",
            "Epochs 500\n",
            "Cost on training data: 0.005567683258870376\n",
            "MAPE on training data: 12.579268185246912\n",
            "RMSE on training data: 0.0006740137875105312\n",
            "MAE on training data: 0.0005305048232800892\n",
            "Cost on evaluation data: 0.0015650219921455003\n",
            "MAPE on evaluation data: 12.97021617546769\n",
            "RMSE on evaluation data: 0.0007131554963617075\n",
            "MAE on evaluation data: 0.0005538852541394135\n",
            "Epochs 600\n",
            "Cost on training data: 0.005567683253140014\n",
            "MAPE on training data: 12.579268192849216\n",
            "RMSE on training data: 0.0006740137873549264\n",
            "MAE on training data: 0.0005305048231632489\n",
            "Cost on evaluation data: 0.0015650219902751674\n",
            "MAPE on evaluation data: 12.970216183149965\n",
            "RMSE on evaluation data: 0.0007131554961126643\n",
            "MAE on evaluation data: 0.0005538852540147567\n",
            "Epochs 700\n",
            "Cost on training data: 0.0055676832474097476\n",
            "MAPE on training data: 12.579268200451505\n",
            "RMSE on training data: 0.0006740137871993212\n",
            "MAE on training data: 0.0005305048230464076\n",
            "Cost on evaluation data: 0.001565021988404931\n",
            "MAPE on evaluation data: 12.970216190832323\n",
            "RMSE on evaluation data: 0.0007131554958636252\n",
            "MAE on evaluation data: 0.0005538852538901021\n",
            "Epochs 800\n",
            "Cost on training data: 0.005567683241679581\n",
            "MAPE on training data: 12.579268208053834\n",
            "RMSE on training data: 0.000674013787043716\n",
            "MAE on training data: 0.0005305048229295675\n",
            "Cost on evaluation data: 0.001565021986534785\n",
            "MAPE on evaluation data: 12.970216198514612\n",
            "RMSE on evaluation data: 0.000713155495614581\n",
            "MAE on evaluation data: 0.0005538852537654444\n",
            "Epochs 900\n",
            "Cost on training data: 0.005567683235949498\n",
            "MAPE on training data: 12.579268215656164\n",
            "RMSE on training data: 0.0006740137868881109\n",
            "MAE on training data: 0.0005305048228127266\n",
            "Cost on evaluation data: 0.0015650219846647501\n",
            "MAPE on evaluation data: 12.97021620619691\n",
            "RMSE on evaluation data: 0.0007131554953655392\n",
            "MAE on evaluation data: 0.0005538852536407861\n",
            "Epochs 1000\n",
            "Cost on training data: 0.005567683230219502\n",
            "MAPE on training data: 12.579268223258508\n",
            "RMSE on training data: 0.0006740137867325041\n",
            "MAE on training data: 0.0005305048226958856\n",
            "Cost on evaluation data: 0.0015650219827948026\n",
            "MAPE on evaluation data: 12.970216213879226\n",
            "RMSE on evaluation data: 0.0007131554951164944\n",
            "MAE on evaluation data: 0.0005538852535161282\n",
            "Epochs 1100\n",
            "Cost on training data: 0.005567683224489622\n",
            "MAPE on training data: 12.579268230860851\n",
            "RMSE on training data: 0.0006740137865768989\n",
            "MAE on training data: 0.0005305048225790439\n",
            "Cost on evaluation data: 0.0015650219809249639\n",
            "MAPE on evaluation data: 12.9702162215616\n",
            "RMSE on evaluation data: 0.0007131554948674532\n",
            "MAE on evaluation data: 0.000553885253391472\n",
            "Epochs 1200\n",
            "Cost on training data: 0.005567683218759821\n",
            "MAPE on training data: 12.57926823846324\n",
            "RMSE on training data: 0.000674013786421293\n",
            "MAE on training data: 0.0005305048224622034\n",
            "Cost on evaluation data: 0.0015650219790552071\n",
            "MAPE on evaluation data: 12.970216229243947\n",
            "RMSE on evaluation data: 0.000713155494618407\n",
            "MAE on evaluation data: 0.0005538852532668131\n",
            "Epochs 1300\n",
            "Cost on training data: 0.005567683213030116\n",
            "MAPE on training data: 12.57926824606562\n",
            "RMSE on training data: 0.0006740137862656865\n",
            "MAE on training data: 0.0005305048223453614\n",
            "Cost on evaluation data: 0.0015650219771855599\n",
            "MAPE on evaluation data: 12.970216236926287\n",
            "RMSE on evaluation data: 0.0007131554943693643\n",
            "MAE on evaluation data: 0.0005538852531421539\n",
            "Epochs 1400\n",
            "Cost on training data: 0.005567683207300495\n",
            "MAPE on training data: 12.57926825366803\n",
            "RMSE on training data: 0.0006740137861100801\n",
            "MAE on training data: 0.0005305048222285202\n",
            "Cost on evaluation data: 0.0015650219753160063\n",
            "MAPE on evaluation data: 12.97021624460867\n",
            "RMSE on evaluation data: 0.0007131554941203178\n",
            "MAE on evaluation data: 0.0005538852530174954\n",
            "Train and validation from state  QLD  fold  1\n",
            "Weights and biases initialization for state  QLD  in progress...\n",
            "Epochs 0\n",
            "Cost on training data: 55.60639749516925\n",
            "MAPE on training data: 1101.9764770347767\n",
            "RMSE on training data: 0.06671267348687492\n",
            "MAE on training data: 0.04686357972796246\n",
            "Cost on evaluation data: 15.562342632990097\n",
            "MAPE on evaluation data: 1100.0989432535516\n",
            "RMSE on evaluation data: 0.06670776012262322\n",
            "MAE on evaluation data: 0.0468620122914778\n",
            "Epochs 100\n",
            "Cost on training data: 0.7411809660559155\n",
            "MAPE on training data: 30.343160233236784\n",
            "RMSE on training data: 0.0016296496677465698\n",
            "MAE on training data: 0.001288413420896276\n",
            "Cost on evaluation data: 0.7167737850239521\n",
            "MAPE on evaluation data: 30.231931678460462\n",
            "RMSE on evaluation data: 0.0016253459153147503\n",
            "MAE on evaluation data: 0.0012849630633064242\n",
            "Epochs 200\n",
            "Cost on training data: 0.17534913762489263\n",
            "MAPE on training data: 39.43853404528072\n",
            "RMSE on training data: 0.001968089598511571\n",
            "MAE on training data: 0.001672204608389586\n",
            "Cost on evaluation data: 0.14004152751330134\n",
            "MAPE on evaluation data: 39.31301770498031\n",
            "RMSE on evaluation data: 0.0019646905463170244\n",
            "MAE on evaluation data: 0.0016695777164148714\n",
            "Epochs 300\n",
            "Cost on training data: 0.054407920180133386\n",
            "MAPE on training data: 38.01815046910324\n",
            "RMSE on training data: 0.0019228695112078564\n",
            "MAE on training data: 0.0016167659303293197\n",
            "Cost on evaluation data: 0.02111545001563749\n",
            "MAPE on evaluation data: 37.903800273019804\n",
            "RMSE on evaluation data: 0.00192076588553108\n",
            "MAE on evaluation data: 0.001614055572633149\n",
            "Epochs 400\n",
            "Cost on training data: 0.016593582892644922\n",
            "MAPE on training data: 20.163676007597694\n",
            "RMSE on training data: 0.0011468770745743672\n",
            "MAE on training data: 0.0008524495463680371\n",
            "Cost on evaluation data: 0.0047412105802997675\n",
            "MAPE on evaluation data: 20.14242867784849\n",
            "RMSE on evaluation data: 0.001143064103224247\n",
            "MAE on evaluation data: 0.0008522426857266131\n",
            "Epochs 500\n",
            "Cost on training data: 0.004137634801865471\n",
            "MAPE on training data: 11.171616764838479\n",
            "RMSE on training data: 0.0005815659656335013\n",
            "MAE on training data: 0.0004762703383540263\n",
            "Cost on evaluation data: 0.0010217100207525714\n",
            "MAPE on evaluation data: 11.198213833436192\n",
            "RMSE on evaluation data: 0.0005781620717976339\n",
            "MAE on evaluation data: 0.0004773608123987309\n",
            "Epochs 600\n",
            "Cost on training data: 0.004143375391657632\n",
            "MAPE on training data: 11.177950881713306\n",
            "RMSE on training data: 0.0005809805236287698\n",
            "MAE on training data: 0.0004760480193914206\n",
            "Cost on evaluation data: 0.0010229855440697815\n",
            "MAPE on evaluation data: 11.207239327215632\n",
            "RMSE on evaluation data: 0.000577580745152889\n",
            "MAE on evaluation data: 0.00047728125666893196\n",
            "Epochs 700\n",
            "Cost on training data: 0.004143375387002634\n",
            "MAPE on training data: 11.177950861678337\n",
            "RMSE on training data: 0.0005809805232738579\n",
            "MAE on training data: 0.00047604801893208894\n",
            "Cost on evaluation data: 0.001022985543080403\n",
            "MAPE on evaluation data: 11.207239306853536\n",
            "RMSE on evaluation data: 0.0005775807448149803\n",
            "MAE on evaluation data: 0.00047728125619995364\n",
            "Epochs 800\n",
            "Cost on training data: 0.004143375382347676\n",
            "MAPE on training data: 11.177950841643373\n",
            "RMSE on training data: 0.0005809805229189471\n",
            "MAE on training data: 0.0004760480184727575\n",
            "Cost on evaluation data: 0.00102298554209106\n",
            "MAPE on evaluation data: 11.207239286491472\n",
            "RMSE on evaluation data: 0.0005775807444770732\n",
            "MAE on evaluation data: 0.0004772812557309766\n",
            "Epochs 900\n",
            "Cost on training data: 0.004143375377692741\n",
            "MAPE on training data: 11.177950821608402\n",
            "RMSE on training data: 0.0005809805225640357\n",
            "MAE on training data: 0.00047604801801342546\n",
            "Cost on evaluation data: 0.0010229855411017467\n",
            "MAPE on evaluation data: 11.207239266129443\n",
            "RMSE on evaluation data: 0.0005775807441391666\n",
            "MAE on evaluation data: 0.0004772812552620005\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004143375373037849\n",
            "MAPE on training data: 11.177950801573433\n",
            "RMSE on training data: 0.0005809805222091248\n",
            "MAE on training data: 0.00047604801755409345\n",
            "Cost on evaluation data: 0.0010229855401124716\n",
            "MAPE on evaluation data: 11.207239245767392\n",
            "RMSE on evaluation data: 0.0005775807438012604\n",
            "MAE on evaluation data: 0.0004772812547930235\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004143375368382993\n",
            "MAPE on training data: 11.17795078153849\n",
            "RMSE on training data: 0.0005809805218542148\n",
            "MAE on training data: 0.0004760480170947622\n",
            "Cost on evaluation data: 0.0010229855391232195\n",
            "MAPE on evaluation data: 11.207239225405377\n",
            "RMSE on evaluation data: 0.0005775807434633554\n",
            "MAE on evaluation data: 0.0004772812543240483\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004143375363728181\n",
            "MAPE on training data: 11.177950761503562\n",
            "RMSE on training data: 0.0005809805214993055\n",
            "MAE on training data: 0.0004760480166354313\n",
            "Cost on evaluation data: 0.0010229855381340028\n",
            "MAPE on evaluation data: 11.207239205043344\n",
            "RMSE on evaluation data: 0.0005775807431254505\n",
            "MAE on evaluation data: 0.00047728125385507176\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004143375359073408\n",
            "MAPE on training data: 11.177950741468672\n",
            "RMSE on training data: 0.0005809805211443973\n",
            "MAE on training data: 0.0004760480161761021\n",
            "Cost on evaluation data: 0.0010229855371448199\n",
            "MAPE on evaluation data: 11.207239184681313\n",
            "RMSE on evaluation data: 0.0005775807427875445\n",
            "MAE on evaluation data: 0.0004772812533860953\n",
            "Epochs 1400\n",
            "Cost on training data: 0.0041433753544186745\n",
            "MAPE on training data: 11.177950721433758\n",
            "RMSE on training data: 0.0005809805207894885\n",
            "MAE on training data: 0.0004760480157167719\n",
            "Cost on evaluation data: 0.0010229855361556688\n",
            "MAPE on evaluation data: 11.207239164319374\n",
            "RMSE on evaluation data: 0.0005775807424496424\n",
            "MAE on evaluation data: 0.00047728125291712255\n",
            "Train and validation from state  QLD  fold  2\n",
            "Epochs 0\n",
            "Cost on training data: 57.40126396703071\n",
            "MAPE on training data: 1116.5125972575192\n",
            "RMSE on training data: 0.06789169003540182\n",
            "MAE on training data: 0.04750537302011631\n",
            "Cost on evaluation data: 16.039344009804907\n",
            "MAPE on evaluation data: 1117.635701936511\n",
            "RMSE on evaluation data: 0.06789139821465281\n",
            "MAE on evaluation data: 0.04750366889672447\n",
            "Epochs 100\n",
            "Cost on training data: 0.7592600687681534\n",
            "MAPE on training data: 30.48740947120952\n",
            "RMSE on training data: 0.0016365260870269322\n",
            "MAE on training data: 0.0012932540298533253\n",
            "Cost on evaluation data: 0.7347411387281655\n",
            "MAPE on evaluation data: 30.52462459019612\n",
            "RMSE on evaluation data: 0.0016383263468592172\n",
            "MAE on evaluation data: 0.0012947706983851355\n",
            "Epochs 200\n",
            "Cost on training data: 0.18312920713851139\n",
            "MAPE on training data: 38.50076990749551\n",
            "RMSE on training data: 0.0019160802349548532\n",
            "MAE on training data: 0.0016328833125681173\n",
            "Cost on evaluation data: 0.14975031274214035\n",
            "MAPE on evaluation data: 38.5911465658983\n",
            "RMSE on evaluation data: 0.001920990575727785\n",
            "MAE on evaluation data: 0.0016365283336443597\n",
            "Epochs 300\n",
            "Cost on training data: 0.057767389555994045\n",
            "MAPE on training data: 39.543931248358064\n",
            "RMSE on training data: 0.0019695415182135164\n",
            "MAE on training data: 0.0016831596158968318\n",
            "Cost on evaluation data: 0.022966132936818213\n",
            "MAPE on evaluation data: 39.611635516656676\n",
            "RMSE on evaluation data: 0.001973918230993389\n",
            "MAE on evaluation data: 0.0016858943429738866\n",
            "Epochs 400\n",
            "Cost on training data: 0.01869162946593059\n",
            "MAPE on training data: 21.48945292146913\n",
            "RMSE on training data: 0.0012169872753084155\n",
            "MAE on training data: 0.0009121313530948211\n",
            "Cost on evaluation data: 0.005487691964869735\n",
            "MAPE on evaluation data: 21.573735877188458\n",
            "RMSE on evaluation data: 0.0012220780869261236\n",
            "MAE on evaluation data: 0.0009157401897415893\n",
            "Epochs 500\n",
            "Cost on training data: 0.005011178626965041\n",
            "MAPE on training data: 11.791678417313774\n",
            "RMSE on training data: 0.0006486063526845721\n",
            "MAE on training data: 0.0005062491372800551\n",
            "Cost on evaluation data: 0.0012893635812209958\n",
            "MAPE on evaluation data: 11.896331268436885\n",
            "RMSE on evaluation data: 0.0006568760425688567\n",
            "MAE on evaluation data: 0.0005117462299654354\n",
            "Epochs 600\n",
            "Cost on training data: 0.004099476766416165\n",
            "MAPE on training data: 11.083490880431963\n",
            "RMSE on training data: 0.0005779684870676528\n",
            "MAE on training data: 0.0004738172186675681\n",
            "Cost on evaluation data: 0.0010605363343167212\n",
            "MAPE on evaluation data: 11.193727510018334\n",
            "RMSE on evaluation data: 0.0005879063676410349\n",
            "MAE on evaluation data: 0.0004795794178486541\n",
            "Epochs 700\n",
            "Cost on training data: 0.004099476763063055\n",
            "MAPE on training data: 11.083490880808156\n",
            "RMSE on training data: 0.0005779684868997211\n",
            "MAE on training data: 0.00047381721860693623\n",
            "Cost on evaluation data: 0.001060536333478722\n",
            "MAPE on evaluation data: 11.19372750982496\n",
            "RMSE on evaluation data: 0.0005879063674614899\n",
            "MAE on evaluation data: 0.0004795794177611781\n",
            "Epochs 800\n",
            "Cost on training data: 0.004099476759709964\n",
            "MAPE on training data: 11.08349088118436\n",
            "RMSE on training data: 0.0005779684867317894\n",
            "MAE on training data: 0.00047381721854630477\n",
            "Cost on evaluation data: 0.0010605363326407465\n",
            "MAPE on evaluation data: 11.193727509631627\n",
            "RMSE on evaluation data: 0.0005879063672819465\n",
            "MAE on evaluation data: 0.0004795794176737035\n",
            "Epochs 900\n",
            "Cost on training data: 0.004099476756356897\n",
            "MAPE on training data: 11.083490881560557\n",
            "RMSE on training data: 0.0005779684865638585\n",
            "MAE on training data: 0.00047381721848567315\n",
            "Cost on evaluation data: 0.001060536331802785\n",
            "MAPE on evaluation data: 11.193727509438194\n",
            "RMSE on evaluation data: 0.0005879063671024021\n",
            "MAE on evaluation data: 0.00047957941758622493\n",
            "Epochs 1000\n",
            "Cost on training data: 0.00409947675300385\n",
            "MAPE on training data: 11.083490881936758\n",
            "RMSE on training data: 0.0005779684863959266\n",
            "MAE on training data: 0.00047381721842504164\n",
            "Cost on evaluation data: 0.0010605363309648583\n",
            "MAPE on evaluation data: 11.193727509244852\n",
            "RMSE on evaluation data: 0.0005879063669228606\n",
            "MAE on evaluation data: 0.0004795794174987502\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004099476749650835\n",
            "MAPE on training data: 11.083490882312947\n",
            "RMSE on training data: 0.0005779684862279956\n",
            "MAE on training data: 0.0004738172183644102\n",
            "Cost on evaluation data: 0.001060536330126939\n",
            "MAPE on evaluation data: 11.193727509051444\n",
            "RMSE on evaluation data: 0.0005879063667433163\n",
            "MAE on evaluation data: 0.0004795794174112731\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004099476746297838\n",
            "MAPE on training data: 11.083490882689158\n",
            "RMSE on training data: 0.000577968486060065\n",
            "MAE on training data: 0.00047381721830377953\n",
            "Cost on evaluation data: 0.0010605363292890467\n",
            "MAPE on evaluation data: 11.1937275088581\n",
            "RMSE on evaluation data: 0.0005879063665637731\n",
            "MAE on evaluation data: 0.00047957941732379824\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004099476742944865\n",
            "MAPE on training data: 11.083490883065323\n",
            "RMSE on training data: 0.0005779684858921332\n",
            "MAE on training data: 0.000473817218243147\n",
            "Cost on evaluation data: 0.001060536328451176\n",
            "MAPE on evaluation data: 11.193727508664706\n",
            "RMSE on evaluation data: 0.0005879063663842306\n",
            "MAE on evaluation data: 0.00047957941723632204\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004099476739591906\n",
            "MAPE on training data: 11.083490883441518\n",
            "RMSE on training data: 0.000577968485724203\n",
            "MAE on training data: 0.0004738172181825161\n",
            "Cost on evaluation data: 0.0010605363276133257\n",
            "MAPE on evaluation data: 11.193727508471268\n",
            "RMSE on evaluation data: 0.000587906366204685\n",
            "MAE on evaluation data: 0.00047957941714884384\n",
            "Train and validation from state  QLD  fold  3\n",
            "Epochs 0\n",
            "Cost on training data: 57.287851598568\n",
            "MAPE on training data: 1116.9120153280355\n",
            "RMSE on training data: 0.06789011870191998\n",
            "MAE on training data: 0.04750487949089317\n",
            "Cost on evaluation data: 16.037578936524064\n",
            "MAPE on evaluation data: 1115.0488530171788\n",
            "RMSE on evaluation data: 0.06788605026309322\n",
            "MAE on evaluation data: 0.04749858080915949\n",
            "Epochs 100\n",
            "Cost on training data: 0.757593244586526\n",
            "MAPE on training data: 30.660893055756468\n",
            "RMSE on training data: 0.0016459289826035485\n",
            "MAE on training data: 0.0013006771264207748\n",
            "Cost on evaluation data: 0.7328886323302648\n",
            "MAPE on evaluation data: 30.611988859238455\n",
            "RMSE on evaluation data: 0.0016488556218360493\n",
            "MAE on evaluation data: 0.0013023269904592033\n",
            "Epochs 200\n",
            "Cost on training data: 0.18208702263294693\n",
            "MAPE on training data: 38.55232156976203\n",
            "RMSE on training data: 0.0019206401978723497\n",
            "MAE on training data: 0.0016345618012372598\n",
            "Cost on evaluation data: 0.1486286702174542\n",
            "MAPE on evaluation data: 38.54767846526937\n",
            "RMSE on evaluation data: 0.0019227587173194372\n",
            "MAE on evaluation data: 0.0016374114956764177\n",
            "Epochs 300\n",
            "Cost on training data: 0.05785933927508106\n",
            "MAPE on training data: 39.649807506981645\n",
            "RMSE on training data: 0.0019768480084251367\n",
            "MAE on training data: 0.0016864959071175444\n",
            "Cost on evaluation data: 0.022892657299410958\n",
            "MAPE on evaluation data: 39.63608026955365\n",
            "RMSE on evaluation data: 0.001980996033476308\n",
            "MAE on evaluation data: 0.001690360010721222\n",
            "Epochs 400\n",
            "Cost on training data: 0.018508164234047095\n",
            "MAPE on training data: 21.422751285758352\n",
            "RMSE on training data: 0.0012133503708780249\n",
            "MAE on training data: 0.0009090392316240811\n",
            "Cost on evaluation data: 0.005417484805595386\n",
            "MAPE on evaluation data: 21.37981604447554\n",
            "RMSE on evaluation data: 0.0012154238319342868\n",
            "MAE on evaluation data: 0.0009097362316774185\n",
            "Epochs 500\n",
            "Cost on training data: 0.004926652150758912\n",
            "MAPE on training data: 11.771878381783928\n",
            "RMSE on training data: 0.0006443246473873658\n",
            "MAE on training data: 0.0005049146808667455\n",
            "Cost on evaluation data: 0.0012626646260435778\n",
            "MAPE on evaluation data: 11.77879576538946\n",
            "RMSE on evaluation data: 0.0006503259928987901\n",
            "MAE on evaluation data: 0.0005068300321515308\n",
            "Epochs 600\n",
            "Cost on training data: 0.004094004953244225\n",
            "MAPE on training data: 11.102944963789144\n",
            "RMSE on training data: 0.0005788262047983408\n",
            "MAE on training data: 0.0004740011053319417\n",
            "Cost on evaluation data: 0.0010509315352062293\n",
            "MAPE on evaluation data: 11.120602502421738\n",
            "RMSE on evaluation data: 0.0005848397953520018\n",
            "MAE on evaluation data: 0.00047627757067841066\n",
            "Epochs 700\n",
            "Cost on training data: 0.004094004950975573\n",
            "MAPE on training data: 11.102944962204731\n",
            "RMSE on training data: 0.000578826204572576\n",
            "MAE on training data: 0.00047400110525081516\n",
            "Cost on evaluation data: 0.0010509315346512223\n",
            "MAPE on evaluation data: 11.120602501519894\n",
            "RMSE on evaluation data: 0.0005848397950913972\n",
            "MAE on evaluation data: 0.0004762775706278047\n",
            "Epochs 800\n",
            "Cost on training data: 0.0040940049487069256\n",
            "MAPE on training data: 11.102944960620281\n",
            "RMSE on training data: 0.00057882620434681\n",
            "MAE on training data: 0.0004740011051696867\n",
            "Cost on evaluation data: 0.0010509315340962273\n",
            "MAPE on evaluation data: 11.120602500618029\n",
            "RMSE on evaluation data: 0.0005848397948307917\n",
            "MAE on evaluation data: 0.00047627757057719817\n",
            "Epochs 900\n",
            "Cost on training data: 0.00409400494643828\n",
            "MAPE on training data: 11.102944959035828\n",
            "RMSE on training data: 0.0005788262041210434\n",
            "MAE on training data: 0.0004740011050885584\n",
            "Cost on evaluation data: 0.0010509315335412487\n",
            "MAPE on evaluation data: 11.120602499716263\n",
            "RMSE on evaluation data: 0.0005848397945701889\n",
            "MAE on evaluation data: 0.00047627757052659563\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004094002706375519\n",
            "MAPE on training data: 11.102955113157439\n",
            "RMSE on training data: 0.0005788262303074791\n",
            "MAE on training data: 0.00047400139586625134\n",
            "Cost on evaluation data: 0.0010509308907414312\n",
            "MAPE on evaluation data: 11.120610681245536\n",
            "RMSE on evaluation data: 0.0005848398654299392\n",
            "MAE on evaluation data: 0.0004762777781821136\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004094002704104904\n",
            "MAPE on training data: 11.102955111590159\n",
            "RMSE on training data: 0.0005788262300817238\n",
            "MAE on training data: 0.0004740013957856434\n",
            "Cost on evaluation data: 0.0010509308901858554\n",
            "MAPE on evaluation data: 11.12061068035806\n",
            "RMSE on evaluation data: 0.0005848398651693424\n",
            "MAE on evaluation data: 0.0004762777781319014\n",
            "Epochs 1200\n",
            "Cost on training data: 0.0040940027018345655\n",
            "MAPE on training data: 11.102955110021636\n",
            "RMSE on training data: 0.0005788262298559637\n",
            "MAE on training data: 0.0004740013957049996\n",
            "Cost on evaluation data: 0.0010509308896303692\n",
            "MAPE on evaluation data: 11.12061067946967\n",
            "RMSE on evaluation data: 0.00058483986490874\n",
            "MAE on evaluation data: 0.00047627777808166664\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004094002699564249\n",
            "MAPE on training data: 11.102955108453141\n",
            "RMSE on training data: 0.0005788262296302056\n",
            "MAE on training data: 0.000474001395624357\n",
            "Cost on evaluation data: 0.0010509308890749025\n",
            "MAPE on evaluation data: 11.120610678581325\n",
            "RMSE on evaluation data: 0.0005848398646481379\n",
            "MAE on evaluation data: 0.00047627777803143403\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004094002697293937\n",
            "MAPE on training data: 11.102955106884629\n",
            "RMSE on training data: 0.0005788262294044471\n",
            "MAE on training data: 0.00047400139554371377\n",
            "Cost on evaluation data: 0.0010509308885194536\n",
            "MAPE on evaluation data: 11.120610677692897\n",
            "RMSE on evaluation data: 0.000584839864387535\n",
            "MAE on evaluation data: 0.0004762777779811982\n",
            "Train and validation from state  QLD  fold  4\n",
            "Epochs 0\n",
            "Cost on training data: 57.17867283993158\n",
            "MAPE on training data: 1116.0671726547998\n",
            "RMSE on training data: 0.06789133146637706\n",
            "MAE on training data: 0.04750464194131928\n",
            "Cost on evaluation data: 16.04026101181497\n",
            "MAPE on evaluation data: 1118.586416711064\n",
            "RMSE on evaluation data: 0.06789097896892593\n",
            "MAE on evaluation data: 0.04750408549733618\n",
            "Epochs 100\n",
            "Cost on training data: 0.7550894796608871\n",
            "MAPE on training data: 30.44740836253192\n",
            "RMSE on training data: 0.0016338229727833964\n",
            "MAE on training data: 0.001293425043844451\n",
            "Cost on evaluation data: 0.7307530985865973\n",
            "MAPE on evaluation data: 30.565985953087566\n",
            "RMSE on evaluation data: 0.0016334470413853373\n",
            "MAE on evaluation data: 0.00129350827506503\n",
            "Epochs 200\n",
            "Cost on training data: 0.1816464324929314\n",
            "MAPE on training data: 38.884544922139874\n",
            "RMSE on training data: 0.0019382134105421166\n",
            "MAE on training data: 0.0016501194227426415\n",
            "Cost on evaluation data: 0.14766051767216934\n",
            "MAPE on evaluation data: 38.98737102616799\n",
            "RMSE on evaluation data: 0.0019367365906755028\n",
            "MAE on evaluation data: 0.0016491432800007236\n",
            "Epochs 300\n",
            "Cost on training data: 0.057639366373114835\n",
            "MAPE on training data: 39.633124614069814\n",
            "RMSE on training data: 0.0019777237908085205\n",
            "MAE on training data: 0.0016878135662533426\n",
            "Cost on evaluation data: 0.02268953359794554\n",
            "MAPE on evaluation data: 39.67900786589092\n",
            "RMSE on evaluation data: 0.001973060907968404\n",
            "MAE on evaluation data: 0.00168413379789963\n",
            "Epochs 400\n",
            "Cost on training data: 0.018291559412155264\n",
            "MAPE on training data: 21.28946578019727\n",
            "RMSE on training data: 0.0012065652719464627\n",
            "MAE on training data: 0.0009046939943686084\n",
            "Cost on evaluation data: 0.005307173107328676\n",
            "MAPE on evaluation data: 21.312248529268306\n",
            "RMSE on evaluation data: 0.0012032723657262531\n",
            "MAE on evaluation data: 0.0009022134265762679\n",
            "Epochs 500\n",
            "Cost on training data: 0.005017797070638285\n",
            "MAPE on training data: 11.84203514536036\n",
            "RMSE on training data: 0.0006503351077087454\n",
            "MAE on training data: 0.0005087687294460213\n",
            "Cost on evaluation data: 0.0012279711854446893\n",
            "MAPE on evaluation data: 11.79050936155646\n",
            "RMSE on evaluation data: 0.0006421509262159113\n",
            "MAE on evaluation data: 0.000503639849976321\n",
            "Epochs 600\n",
            "Cost on training data: 0.004130228206823048\n",
            "MAPE on training data: 11.146625600197634\n",
            "RMSE on training data: 0.0005817246241744295\n",
            "MAE on training data: 0.0004769474988825701\n",
            "Cost on evaluation data: 0.0010079415008846084\n",
            "MAPE on evaluation data: 11.098742811258875\n",
            "RMSE on evaluation data: 0.0005731258702390419\n",
            "MAE on evaluation data: 0.0004720023581818779\n",
            "Epochs 700\n",
            "Cost on training data: 0.004130228208334567\n",
            "MAPE on training data: 11.146625599428383\n",
            "RMSE on training data: 0.0005817246241043669\n",
            "MAE on training data: 0.00047694749882056366\n",
            "Cost on evaluation data: 0.0010079415012987426\n",
            "MAPE on evaluation data: 11.098742810035866\n",
            "RMSE on evaluation data: 0.0005731258701935849\n",
            "MAE on evaluation data: 0.0004720023580996564\n",
            "Epochs 800\n",
            "Cost on training data: 0.004130228209846114\n",
            "MAPE on training data: 11.146625598659153\n",
            "RMSE on training data: 0.0005817246240343045\n",
            "MAE on training data: 0.0004769474987585584\n",
            "Cost on evaluation data: 0.0010079415017128911\n",
            "MAPE on evaluation data: 11.09874280881286\n",
            "RMSE on evaluation data: 0.000573125870148127\n",
            "MAE on evaluation data: 0.0004720023580174352\n",
            "Epochs 900\n",
            "Cost on training data: 0.004130228211357668\n",
            "MAPE on training data: 11.146625597889944\n",
            "RMSE on training data: 0.0005817246239642432\n",
            "MAE on training data: 0.0004769474986965538\n",
            "Cost on evaluation data: 0.0010079415021270585\n",
            "MAPE on evaluation data: 11.098742807589856\n",
            "RMSE on evaluation data: 0.0005731258701026695\n",
            "MAE on evaluation data: 0.0004720023579352143\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004130228218086119\n",
            "MAPE on training data: 11.14662714411955\n",
            "RMSE on training data: 0.0005817245915792741\n",
            "MAE on training data: 0.00047694741773155673\n",
            "Cost on evaluation data: 0.001007941599692485\n",
            "MAPE on evaluation data: 11.09874608220689\n",
            "RMSE on evaluation data: 0.0005731258817914017\n",
            "MAE on evaluation data: 0.0004720023486622201\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004130228219606017\n",
            "MAPE on training data: 11.146627143340341\n",
            "RMSE on training data: 0.0005817245915093417\n",
            "MAE on training data: 0.0004769474176692396\n",
            "Cost on evaluation data: 0.0010079416001086737\n",
            "MAPE on evaluation data: 11.098746080975856\n",
            "RMSE on evaluation data: 0.0005731258817460588\n",
            "MAE on evaluation data: 0.00047200234857976603\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004130228221125927\n",
            "MAPE on training data: 11.146627142561146\n",
            "RMSE on training data: 0.0005817245914394103\n",
            "MAE on training data: 0.0004769474176069231\n",
            "Cost on evaluation data: 0.0010079416005248823\n",
            "MAPE on evaluation data: 11.098746079744782\n",
            "RMSE on evaluation data: 0.0005731258817007171\n",
            "MAE on evaluation data: 0.00047200234849731083\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004130228222645847\n",
            "MAPE on training data: 11.146627141781913\n",
            "RMSE on training data: 0.0005817245913694778\n",
            "MAE on training data: 0.0004769474175446051\n",
            "Cost on evaluation data: 0.0010079416009411066\n",
            "MAPE on evaluation data: 11.09874607851373\n",
            "RMSE on evaluation data: 0.0005731258816553748\n",
            "MAE on evaluation data: 0.0004720023484148566\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004130228224165783\n",
            "MAPE on training data: 11.1466271410027\n",
            "RMSE on training data: 0.0005817245912995463\n",
            "MAE on training data: 0.0004769474174822881\n",
            "Cost on evaluation data: 0.001007941601357337\n",
            "MAPE on evaluation data: 11.098746077282554\n",
            "RMSE on evaluation data: 0.0005731258816100281\n",
            "MAE on evaluation data: 0.00047200234833239717\n",
            "Train and validation from state  QLD  fold  5\n",
            "Epochs 0\n",
            "Cost on training data: 57.06687814235444\n",
            "MAPE on training data: 1116.4717042888417\n",
            "RMSE on training data: 0.06789039976631676\n",
            "MAE on training data: 0.047502506002857284\n",
            "Cost on evaluation data: 16.044177677193872\n",
            "MAPE on evaluation data: 1116.9835334017262\n",
            "RMSE on evaluation data: 0.06790221092304036\n",
            "MAE on evaluation data: 0.04751390559553371\n",
            "Epochs 100\n",
            "Cost on training data: 0.7533893668111883\n",
            "MAPE on training data: 30.574120173910714\n",
            "RMSE on training data: 0.0016426714666923396\n",
            "MAE on training data: 0.0012978959125904146\n",
            "Cost on evaluation data: 0.7288665575478954\n",
            "MAPE on evaluation data: 30.562424945388457\n",
            "RMSE on evaluation data: 0.0016413365366366214\n",
            "MAE on evaluation data: 0.0012971415856985642\n",
            "Epochs 200\n",
            "Cost on training data: 0.18109385082198803\n",
            "MAPE on training data: 39.175723261370806\n",
            "RMSE on training data: 0.0019533637425960234\n",
            "MAE on training data: 0.0016615900290569434\n",
            "Cost on evaluation data: 0.14668371371444658\n",
            "MAPE on evaluation data: 39.11934066137404\n",
            "RMSE on evaluation data: 0.0019511319835449799\n",
            "MAE on evaluation data: 0.0016587941243047049\n",
            "Epochs 300\n",
            "Cost on training data: 0.05718120424213411\n",
            "MAPE on training data: 39.518048598883325\n",
            "RMSE on training data: 0.00197287287854016\n",
            "MAE on training data: 0.0016823057726354173\n",
            "Cost on evaluation data: 0.022503052638821634\n",
            "MAPE on evaluation data: 39.531641057670036\n",
            "RMSE on evaluation data: 0.001971222452338211\n",
            "MAE on evaluation data: 0.0016817958239266839\n",
            "Epochs 400\n",
            "Cost on training data: 0.018106942102249633\n",
            "MAPE on training data: 21.17342470571737\n",
            "RMSE on training data: 0.0012017080328425454\n",
            "MAE on training data: 0.0008988058856271614\n",
            "Cost on evaluation data: 0.005258240554953247\n",
            "MAPE on evaluation data: 21.106821274626462\n",
            "RMSE on evaluation data: 0.0012003344481343711\n",
            "MAE on evaluation data: 0.0008957831682426899\n",
            "Epochs 500\n",
            "Cost on training data: 0.004948822260970753\n",
            "MAPE on training data: 11.802412622534405\n",
            "RMSE on training data: 0.0006470501132561894\n",
            "MAE on training data: 0.0005071154159666779\n",
            "Cost on evaluation data: 0.0012274569350078195\n",
            "MAPE on evaluation data: 11.690736498487245\n",
            "RMSE on evaluation data: 0.0006425417684856116\n",
            "MAE on evaluation data: 0.0005023403887906542\n",
            "Epochs 600\n",
            "Cost on training data: 0.0041063463713277345\n",
            "MAPE on training data: 11.130293245519448\n",
            "RMSE on training data: 0.0005813182549910294\n",
            "MAE on training data: 0.0004762297935203855\n",
            "Cost on evaluation data: 0.0010157312507787454\n",
            "MAPE on evaluation data: 11.011003209663391\n",
            "RMSE on evaluation data: 0.0005760338178329191\n",
            "MAE on evaluation data: 0.00047112230613477544\n",
            "Epochs 700\n",
            "Cost on training data: 0.004106342164474483\n",
            "MAPE on training data: 11.130280616326212\n",
            "RMSE on training data: 0.0005813182611045473\n",
            "MAE on training data: 0.000476229460592059\n",
            "Cost on evaluation data: 0.00101573015643116\n",
            "MAPE on evaluation data: 11.010992558572157\n",
            "RMSE on evaluation data: 0.0005760338290814289\n",
            "MAE on evaluation data: 0.0004711220520749529\n",
            "Epochs 800\n",
            "Cost on training data: 0.00410634215680763\n",
            "MAPE on training data: 11.130280595144416\n",
            "RMSE on training data: 0.0005813182610342928\n",
            "MAE on training data: 0.00047622946000442544\n",
            "Cost on evaluation data: 0.0010157301544374622\n",
            "MAPE on evaluation data: 11.01099254061829\n",
            "RMSE on evaluation data: 0.0005760338290201717\n",
            "MAE on evaluation data: 0.0004711220516166363\n",
            "Epochs 900\n",
            "Cost on training data: 0.004106342156309387\n",
            "MAPE on training data: 11.1302805954994\n",
            "RMSE on training data: 0.0005813182609531607\n",
            "MAE on training data: 0.00047622945998449125\n",
            "Cost on evaluation data: 0.0010157301543086068\n",
            "MAPE on evaluation data: 11.010992540827804\n",
            "RMSE on evaluation data: 0.0005760338289392766\n",
            "MAE on evaluation data: 0.0004711220515915196\n",
            "Epochs 1000\n",
            "Cost on training data: 0.0041063421558111485\n",
            "MAPE on training data: 11.130280595854378\n",
            "RMSE on training data: 0.000581318260872027\n",
            "MAE on training data: 0.0004762294599645565\n",
            "Cost on evaluation data: 0.0010157301541797584\n",
            "MAPE on evaluation data: 11.01099254103728\n",
            "RMSE on evaluation data: 0.0005760338288583813\n",
            "MAE on evaluation data: 0.0004711220515664012\n",
            "Epochs 1100\n",
            "Cost on training data: 0.0041063421553129255\n",
            "MAPE on training data: 11.130280596209374\n",
            "RMSE on training data: 0.0005813182607908955\n",
            "MAE on training data: 0.0004762294599446225\n",
            "Cost on evaluation data: 0.00101573015405092\n",
            "MAPE on evaluation data: 11.0109925412468\n",
            "RMSE on evaluation data: 0.0005760338287774874\n",
            "MAE on evaluation data: 0.0004711220515412847\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004106342154814693\n",
            "MAPE on training data: 11.13028059656437\n",
            "RMSE on training data: 0.0005813182607097633\n",
            "MAE on training data: 0.00047622945992468845\n",
            "Cost on evaluation data: 0.0010157301539220859\n",
            "MAPE on evaluation data: 11.010992541456343\n",
            "RMSE on evaluation data: 0.0005760338286965934\n",
            "MAE on evaluation data: 0.0004711220515161689\n",
            "Epochs 1300\n",
            "Cost on training data: 0.00410634215431649\n",
            "MAPE on training data: 11.130280596919333\n",
            "RMSE on training data: 0.0005813182606286298\n",
            "MAE on training data: 0.00047622945990475306\n",
            "Cost on evaluation data: 0.0010157301537932594\n",
            "MAPE on evaluation data: 11.010992541665814\n",
            "RMSE on evaluation data: 0.0005760338286156983\n",
            "MAE on evaluation data: 0.00047112205149105034\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004106342153818268\n",
            "MAPE on training data: 11.130280597274309\n",
            "RMSE on training data: 0.0005813182605474966\n",
            "MAE on training data: 0.0004762294598848184\n",
            "Cost on evaluation data: 0.0010157301536644408\n",
            "MAPE on evaluation data: 11.010992541875302\n",
            "RMSE on evaluation data: 0.0005760338285348028\n",
            "MAE on evaluation data: 0.0004711220514659325\n",
            "Train and validation from state  SA  fold  1\n",
            "Weights and biases initialization for state  SA  in progress...\n",
            "Epochs 0\n",
            "Cost on training data: 147.2736085647592\n",
            "MAPE on training data: 1694.2760096777074\n",
            "RMSE on training data: 0.10983868131498588\n",
            "MAE on training data: 0.06693450474576405\n",
            "Cost on evaluation data: 38.639225487630185\n",
            "MAPE on evaluation data: 1666.0293536652975\n",
            "RMSE on evaluation data: 0.10986098736729809\n",
            "MAE on evaluation data: 0.06694327281124277\n",
            "Epochs 100\n",
            "Cost on training data: 0.9469289593177245\n",
            "MAPE on training data: 59.22540372138047\n",
            "RMSE on training data: 0.0028877461022733166\n",
            "MAE on training data: 0.002351394030114796\n",
            "Cost on evaluation data: 0.8713832583640447\n",
            "MAPE on evaluation data: 58.44349439377486\n",
            "RMSE on evaluation data: 0.002924622030935409\n",
            "MAE on evaluation data: 0.0023789777849280696\n",
            "Epochs 200\n",
            "Cost on training data: 0.20481819420341998\n",
            "MAPE on training data: 38.626836600743\n",
            "RMSE on training data: 0.0018819013958427694\n",
            "MAE on training data: 0.0015290805883393143\n",
            "Cost on evaluation data: 0.1725787523554102\n",
            "MAPE on evaluation data: 37.56958264848601\n",
            "RMSE on evaluation data: 0.0019102416691739556\n",
            "MAE on evaluation data: 0.0015432895723216174\n",
            "Epochs 300\n",
            "Cost on training data: 0.04470858177754749\n",
            "MAPE on training data: 34.72240299513661\n",
            "RMSE on training data: 0.001718922539180199\n",
            "MAE on training data: 0.0013603037327989307\n",
            "Cost on evaluation data: 0.017519956569732063\n",
            "MAPE on evaluation data: 33.72952637255283\n",
            "RMSE on evaluation data: 0.0017473500198999367\n",
            "MAE on evaluation data: 0.0013768488567465068\n",
            "Epochs 400\n",
            "Cost on training data: 0.016262340599138066\n",
            "MAPE on training data: 21.869929591838513\n",
            "RMSE on training data: 0.001123917524061422\n",
            "MAE on training data: 0.0008575385047246417\n",
            "Cost on evaluation data: 0.004601004306246267\n",
            "MAPE on evaluation data: 21.33270355225039\n",
            "RMSE on evaluation data: 0.0011711257232544308\n",
            "MAE on evaluation data: 0.0008877317348451456\n",
            "Epochs 500\n",
            "Cost on training data: 0.011186890422539486\n",
            "MAPE on training data: 18.392407148217597\n",
            "RMSE on training data: 0.0009391747529786798\n",
            "MAE on training data: 0.0007198797700636923\n",
            "Cost on evaluation data: 0.0030977525445212606\n",
            "MAPE on evaluation data: 17.946838158857762\n",
            "RMSE on evaluation data: 0.0009969630097245237\n",
            "MAE on evaluation data: 0.0007543709012414178\n",
            "Epochs 600\n",
            "Cost on training data: 0.011186890424692416\n",
            "MAPE on training data: 18.392407158937356\n",
            "RMSE on training data: 0.0009391747528905714\n",
            "MAE on training data: 0.0007198797702122405\n",
            "Cost on evaluation data: 0.0030977525447974472\n",
            "MAPE on evaluation data: 17.94683816682092\n",
            "RMSE on evaluation data: 0.0009969630096142092\n",
            "MAE on evaluation data: 0.0007543709012830486\n",
            "Epochs 700\n",
            "Cost on training data: 0.011186890426845392\n",
            "MAPE on training data: 18.39240716965707\n",
            "RMSE on training data: 0.0009391747528024625\n",
            "MAE on training data: 0.0007198797703607873\n",
            "Cost on evaluation data: 0.003097752545073663\n",
            "MAPE on evaluation data: 17.94683817478402\n",
            "RMSE on evaluation data: 0.0009969630095038936\n",
            "MAE on evaluation data: 0.000754370901324678\n",
            "Epochs 800\n",
            "Cost on training data: 0.011186890428998437\n",
            "MAPE on training data: 18.392407180376754\n",
            "RMSE on training data: 0.0009391747527143562\n",
            "MAE on training data: 0.0007198797705093354\n",
            "Cost on evaluation data: 0.0030977525453499176\n",
            "MAPE on evaluation data: 17.94683818274709\n",
            "RMSE on evaluation data: 0.0009969630093935788\n",
            "MAE on evaluation data: 0.0007543709013663078\n",
            "Epochs 900\n",
            "Cost on training data: 0.011186903510303941\n",
            "MAPE on training data: 18.39236745360107\n",
            "RMSE on training data: 0.000939174865705825\n",
            "MAE on training data: 0.0007198789533065285\n",
            "Cost on evaluation data: 0.0030977564742894976\n",
            "MAPE on evaluation data: 17.946805947690883\n",
            "RMSE on evaluation data: 0.0009969635503601704\n",
            "MAE on evaluation data: 0.0007543703905633315\n",
            "Epochs 1000\n",
            "Cost on training data: 0.011186898870193382\n",
            "MAPE on training data: 18.392398629436972\n",
            "RMSE on training data: 0.0009391748964340694\n",
            "MAE on training data: 0.0007198796085605247\n",
            "Cost on evaluation data: 0.0030977546641764216\n",
            "MAPE on evaluation data: 17.946834960714686\n",
            "RMSE on evaluation data: 0.00099696371023915\n",
            "MAE on evaluation data: 0.0007543709617227396\n",
            "Epochs 1100\n",
            "Cost on training data: 0.01118689887237893\n",
            "MAPE on training data: 18.39239864007897\n",
            "RMSE on training data: 0.000939174896346497\n",
            "MAE on training data: 0.0007198796087081674\n",
            "Cost on evaluation data: 0.0030977546644625005\n",
            "MAPE on evaluation data: 17.94683496861291\n",
            "RMSE on evaluation data: 0.000996963710129867\n",
            "MAE on evaluation data: 0.0007543709617637715\n",
            "Epochs 1200\n",
            "Cost on training data: 0.011186898874564517\n",
            "MAPE on training data: 18.392398650721\n",
            "RMSE on training data: 0.0009391748962589276\n",
            "MAE on training data: 0.0007198796088558115\n",
            "Cost on evaluation data: 0.0030977546647486197\n",
            "MAPE on evaluation data: 17.946834976511173\n",
            "RMSE on evaluation data: 0.0009969637100205864\n",
            "MAE on evaluation data: 0.0007543709618048054\n",
            "Epochs 1300\n",
            "Cost on training data: 0.011186898876750133\n",
            "MAPE on training data: 18.392398661362904\n",
            "RMSE on training data: 0.0009391748961713553\n",
            "MAE on training data: 0.0007198796090034527\n",
            "Cost on evaluation data: 0.0030977546650347884\n",
            "MAPE on evaluation data: 17.946834984409378\n",
            "RMSE on evaluation data: 0.0009969637099113073\n",
            "MAE on evaluation data: 0.0007543709618458388\n",
            "Epochs 1400\n",
            "Cost on training data: 0.011186898878935836\n",
            "MAPE on training data: 18.392398672004763\n",
            "RMSE on training data: 0.0009391748960837853\n",
            "MAE on training data: 0.0007198796091510935\n",
            "Cost on evaluation data: 0.003097754665320989\n",
            "MAPE on evaluation data: 17.946834992307465\n",
            "RMSE on evaluation data: 0.0009969637098020266\n",
            "MAE on evaluation data: 0.0007543709618868692\n",
            "Train and validation from state  SA  fold  2\n",
            "Epochs 0\n",
            "Cost on training data: 151.59283221659248\n",
            "MAPE on training data: 1710.8402742600485\n",
            "RMSE on training data: 0.11158427774932472\n",
            "MAE on training data: 0.06756876578403845\n",
            "Cost on evaluation data: 39.79010472657061\n",
            "MAPE on evaluation data: 1686.0906190302344\n",
            "RMSE on evaluation data: 0.1115566108208711\n",
            "MAE on evaluation data: 0.06756566046620502\n",
            "Epochs 100\n",
            "Cost on training data: 0.9728319536342639\n",
            "MAPE on training data: 61.24220444866156\n",
            "RMSE on training data: 0.0029775097816835665\n",
            "MAE on training data: 0.002426816707157971\n",
            "Cost on evaluation data: 0.8913899535152805\n",
            "MAPE on evaluation data: 59.21702072009023\n",
            "RMSE on evaluation data: 0.002958745731229711\n",
            "MAE on evaluation data: 0.002408534691861626\n",
            "Epochs 200\n",
            "Cost on training data: 0.21968534913078586\n",
            "MAPE on training data: 39.23785311867455\n",
            "RMSE on training data: 0.0019170091588773966\n",
            "MAE on training data: 0.0015507390320630549\n",
            "Cost on evaluation data: 0.18562023300980138\n",
            "MAPE on evaluation data: 37.51562160769826\n",
            "RMSE on evaluation data: 0.001892017297164213\n",
            "MAE on evaluation data: 0.001534882087748405\n",
            "Epochs 300\n",
            "Cost on training data: 0.048258914426334155\n",
            "MAPE on training data: 35.9951061211317\n",
            "RMSE on training data: 0.0017736551958049964\n",
            "MAE on training data: 0.0014159234339128233\n",
            "Cost on evaluation data: 0.01889777570179433\n",
            "MAPE on evaluation data: 34.27862818176012\n",
            "RMSE on evaluation data: 0.0017510167585814897\n",
            "MAE on evaluation data: 0.0013972950483062557\n",
            "Epochs 400\n",
            "Cost on training data: 0.016854801919702768\n",
            "MAPE on training data: 22.336565121894083\n",
            "RMSE on training data: 0.0011420391451177339\n",
            "MAE on training data: 0.0008724244226754193\n",
            "Cost on evaluation data: 0.004196197564219228\n",
            "MAPE on evaluation data: 20.182557278177228\n",
            "RMSE on evaluation data: 0.0010959262538505522\n",
            "MAE on evaluation data: 0.000835654722254091\n",
            "Epochs 500\n",
            "Cost on training data: 0.011629075218170193\n",
            "MAPE on training data: 18.899797769330927\n",
            "RMSE on training data: 0.0009611681794610363\n",
            "MAE on training data: 0.0007366396731644879\n",
            "Cost on evaluation data: 0.002566662548626277\n",
            "MAPE on evaluation data: 16.562153917337476\n",
            "RMSE on evaluation data: 0.0008968369466722632\n",
            "MAE on evaluation data: 0.0006911538223558091\n",
            "Epochs 600\n",
            "Cost on training data: 0.011629075216923117\n",
            "MAPE on training data: 18.899797777440078\n",
            "RMSE on training data: 0.0009611681794185623\n",
            "MAE on training data: 0.0007366396733003141\n",
            "Cost on evaluation data: 0.0025666625484125107\n",
            "MAPE on evaluation data: 16.562153924787392\n",
            "RMSE on evaluation data: 0.0008968369466441229\n",
            "MAE on evaluation data: 0.0006911538224959439\n",
            "Epochs 700\n",
            "Cost on training data: 0.011629075215675827\n",
            "MAPE on training data: 18.899797785548962\n",
            "RMSE on training data: 0.0009611681793760905\n",
            "MAE on training data: 0.0007366396734361372\n",
            "Cost on evaluation data: 0.0025666625481987468\n",
            "MAPE on evaluation data: 16.562153932237273\n",
            "RMSE on evaluation data: 0.0008968369466159976\n",
            "MAE on evaluation data: 0.0006911538226360824\n",
            "Epochs 800\n",
            "Cost on training data: 0.01162907521442858\n",
            "MAPE on training data: 18.89979779365784\n",
            "RMSE on training data: 0.0009611681793336185\n",
            "MAE on training data: 0.0007366396735719599\n",
            "Cost on evaluation data: 0.002566662547985065\n",
            "MAPE on evaluation data: 16.562153939687157\n",
            "RMSE on evaluation data: 0.0008968369465878707\n",
            "MAE on evaluation data: 0.0006911538227762216\n",
            "Epochs 900\n",
            "Cost on training data: 0.011629075213181466\n",
            "MAPE on training data: 18.89979780176673\n",
            "RMSE on training data: 0.0009611681792911489\n",
            "MAE on training data: 0.0007366396737077841\n",
            "Cost on evaluation data: 0.0025666625477714514\n",
            "MAPE on evaluation data: 16.562153947137006\n",
            "RMSE on evaluation data: 0.0008968369465597467\n",
            "MAE on evaluation data: 0.0006911538229163604\n",
            "Epochs 1000\n",
            "Cost on training data: 0.011629075211934401\n",
            "MAPE on training data: 18.899797809875533\n",
            "RMSE on training data: 0.0009611681792486761\n",
            "MAE on training data: 0.0007366396738436054\n",
            "Cost on evaluation data: 0.002566662547557913\n",
            "MAPE on evaluation data: 16.562153954586837\n",
            "RMSE on evaluation data: 0.0008968369465316217\n",
            "MAE on evaluation data: 0.000691153823056498\n",
            "Epochs 1100\n",
            "Cost on training data: 0.011629089380901611\n",
            "MAPE on training data: 18.89986815597021\n",
            "RMSE on training data: 0.0009611681292841142\n",
            "MAE on training data: 0.0007366405171401413\n",
            "Cost on evaluation data: 0.002566666838328506\n",
            "MAPE on evaluation data: 16.562216812394546\n",
            "RMSE on evaluation data: 0.0008968375492533786\n",
            "MAE on evaluation data: 0.0006911550558378548\n",
            "Epochs 1200\n",
            "Cost on training data: 0.011629089379833531\n",
            "MAPE on training data: 18.89986816449072\n",
            "RMSE on training data: 0.000961168129241818\n",
            "MAE on training data: 0.0007366405172846861\n",
            "Cost on evaluation data: 0.0025666668381657144\n",
            "MAPE on evaluation data: 16.562216820278916\n",
            "RMSE on evaluation data: 0.0008968375492220172\n",
            "MAE on evaluation data: 0.00069115505598818\n",
            "Epochs 1300\n",
            "Cost on training data: 0.011629090892281977\n",
            "MAPE on training data: 18.899881553607226\n",
            "RMSE on training data: 0.0009611681393687059\n",
            "MAE on training data: 0.0007366407153531642\n",
            "Cost on evaluation data: 0.0025666673249849425\n",
            "MAPE on evaluation data: 16.562228565817026\n",
            "RMSE on evaluation data: 0.0008968377162318876\n",
            "MAE on evaluation data: 0.0006911553322050797\n",
            "Epochs 1400\n",
            "Cost on training data: 0.011629090335995431\n",
            "MAPE on training data: 18.899871325838316\n",
            "RMSE on training data: 0.0009611681479066206\n",
            "MAE on training data: 0.000736640601382245\n",
            "Cost on evaluation data: 0.0025666670293600746\n",
            "MAPE on evaluation data: 16.56221715922463\n",
            "RMSE on evaluation data: 0.000896837575666687\n",
            "MAE on evaluation data: 0.000691155152901294\n",
            "Train and validation from state  SA  fold  3\n",
            "Epochs 0\n",
            "Cost on training data: 151.29928096714798\n",
            "MAPE on training data: 1708.157009779494\n",
            "RMSE on training data: 0.1115805205872037\n",
            "MAE on training data: 0.0675751361328934\n",
            "Cost on evaluation data: 39.790502017608055\n",
            "MAPE on evaluation data: 1697.0020623966054\n",
            "RMSE on evaluation data: 0.11158262667290032\n",
            "MAE on evaluation data: 0.06754144060127606\n",
            "Epochs 100\n",
            "Cost on training data: 0.970267389027115\n",
            "MAPE on training data: 61.00742578404598\n",
            "RMSE on training data: 0.0029776055179946584\n",
            "MAE on training data: 0.0024268761574747807\n",
            "Cost on evaluation data: 0.8892512398825504\n",
            "MAPE on evaluation data: 60.065000460102155\n",
            "RMSE on evaluation data: 0.0029466494739799533\n",
            "MAE on evaluation data: 0.0024077136063630606\n",
            "Epochs 200\n",
            "Cost on training data: 0.21843985008929453\n",
            "MAPE on training data: 39.19070591964976\n",
            "RMSE on training data: 0.0019253592675656777\n",
            "MAE on training data: 0.0015567018640600294\n",
            "Cost on evaluation data: 0.18408845559792122\n",
            "MAPE on evaluation data: 37.92752039611364\n",
            "RMSE on evaluation data: 0.0018807685226752946\n",
            "MAE on evaluation data: 0.0015239438828288882\n",
            "Epochs 300\n",
            "Cost on training data: 0.04816336635947445\n",
            "MAPE on training data: 35.882367144123144\n",
            "RMSE on training data: 0.001778323565037964\n",
            "MAE on training data: 0.0014180802895783554\n",
            "Cost on evaluation data: 0.0185856818530767\n",
            "MAPE on evaluation data: 34.60468884317106\n",
            "RMSE on evaluation data: 0.001729871929364697\n",
            "MAE on evaluation data: 0.0013829896014266154\n",
            "Epochs 400\n",
            "Cost on training data: 0.01695463537482881\n",
            "MAPE on training data: 22.224355612864986\n",
            "RMSE on training data: 0.0011484398378191353\n",
            "MAE on training data: 0.0008751665643972135\n",
            "Cost on evaluation data: 0.003988729882769034\n",
            "MAPE on evaluation data: 20.364223154647213\n",
            "RMSE on evaluation data: 0.0010619407991784814\n",
            "MAE on evaluation data: 0.0008169104613976402\n",
            "Epochs 500\n",
            "Cost on training data: 0.011770833022296602\n",
            "MAPE on training data: 18.799818099501774\n",
            "RMSE on training data: 0.0009677438190615864\n",
            "MAE on training data: 0.0007389026894983337\n",
            "Cost on evaluation data: 0.0023795054809112193\n",
            "MAPE on evaluation data: 16.77993281214111\n",
            "RMSE on evaluation data: 0.0008653281767678527\n",
            "MAE on evaluation data: 0.0006771604529007207\n",
            "Epochs 600\n",
            "Cost on training data: 0.011770835311189855\n",
            "MAPE on training data: 18.799807281725876\n",
            "RMSE on training data: 0.000967743872258362\n",
            "MAE on training data: 0.0007389025449025579\n",
            "Cost on evaluation data: 0.0023795054834994255\n",
            "MAPE on evaluation data: 16.77992272034675\n",
            "RMSE on evaluation data: 0.0008653281122256837\n",
            "MAE on evaluation data: 0.0006771603030804719\n",
            "Epochs 700\n",
            "Cost on training data: 0.01177083531176155\n",
            "MAPE on training data: 18.799807277866993\n",
            "RMSE on training data: 0.0009677438723146792\n",
            "MAE on training data: 0.0007389025448656535\n",
            "Cost on evaluation data: 0.0023795054833736402\n",
            "MAPE on evaluation data: 16.779922715982284\n",
            "RMSE on evaluation data: 0.0008653281122291416\n",
            "MAE on evaluation data: 0.0006771603029997581\n",
            "Epochs 800\n",
            "Cost on training data: 0.011770835312333281\n",
            "MAPE on training data: 18.799807274008128\n",
            "RMSE on training data: 0.0009677438723709981\n",
            "MAE on training data: 0.0007389025448287492\n",
            "Cost on evaluation data: 0.0023795054832478958\n",
            "MAPE on evaluation data: 16.779922711617907\n",
            "RMSE on evaluation data: 0.000865328112232603\n",
            "MAE on evaluation data: 0.0006771603029190486\n",
            "Epochs 900\n",
            "Cost on training data: 0.0117708389218675\n",
            "MAPE on training data: 18.79983663117287\n",
            "RMSE on training data: 0.0009677438276421846\n",
            "MAE on training data: 0.0007389027994778052\n",
            "Cost on evaluation data: 0.002379507714271398\n",
            "MAPE on evaluation data: 16.779947271856642\n",
            "RMSE on evaluation data: 0.0008653283229160809\n",
            "MAE on evaluation data: 0.0006771607033656641\n",
            "Epochs 1000\n",
            "Cost on training data: 0.011770844476193065\n",
            "MAPE on training data: 18.799830852860726\n",
            "RMSE on training data: 0.0009677438357083163\n",
            "MAE on training data: 0.0007389027045977948\n",
            "Cost on evaluation data: 0.00237950881512234\n",
            "MAPE on evaluation data: 16.77994027520431\n",
            "RMSE on evaluation data: 0.0008653283072202283\n",
            "MAE on evaluation data: 0.0006771605556855345\n",
            "Epochs 1100\n",
            "Cost on training data: 0.01177085446139509\n",
            "MAPE on training data: 18.799813725262744\n",
            "RMSE on training data: 0.0009677439295301462\n",
            "MAE on training data: 0.0007389024377660383\n",
            "Cost on evaluation data: 0.0023795104160557455\n",
            "MAPE on evaluation data: 16.77992416168045\n",
            "RMSE on evaluation data: 0.0008653282201839146\n",
            "MAE on evaluation data: 0.0006771602734750706\n",
            "Epochs 1200\n",
            "Cost on training data: 0.011770854462054876\n",
            "MAPE on training data: 18.79981372088489\n",
            "RMSE on training data: 0.0009677439295892172\n",
            "MAE on training data: 0.0007389024377226777\n",
            "Cost on evaluation data: 0.0023795104159210767\n",
            "MAPE on evaluation data: 16.77992415673647\n",
            "RMSE on evaluation data: 0.0008653282201848935\n",
            "MAE on evaluation data: 0.000677160273383146\n",
            "Epochs 1300\n",
            "Cost on training data: 0.01177085446271469\n",
            "MAPE on training data: 18.799813716507057\n",
            "RMSE on training data: 0.0009677439296482888\n",
            "MAE on training data: 0.0007389024376793172\n",
            "Cost on evaluation data: 0.0023795104157864335\n",
            "MAPE on evaluation data: 16.779924151792468\n",
            "RMSE on evaluation data: 0.0008653282201858707\n",
            "MAE on evaluation data: 0.0006771602732912193\n",
            "Epochs 1400\n",
            "Cost on training data: 0.011770854463374544\n",
            "MAPE on training data: 18.79981371212926\n",
            "RMSE on training data: 0.0009677439297073612\n",
            "MAE on training data: 0.0007389024376359578\n",
            "Cost on evaluation data: 0.002379510415651807\n",
            "MAPE on evaluation data: 16.77992414684841\n",
            "RMSE on evaluation data: 0.0008653282201868445\n",
            "MAE on evaluation data: 0.0006771602731992908\n",
            "Train and validation from state  SA  fold  4\n",
            "Epochs 0\n",
            "Cost on training data: 150.9932305815526\n",
            "MAPE on training data: 1690.2274944425799\n",
            "RMSE on training data: 0.11157971309297793\n",
            "MAE on training data: 0.06756211092684918\n",
            "Cost on evaluation data: 39.79338671123579\n",
            "MAPE on evaluation data: 1769.1647511192357\n",
            "RMSE on evaluation data: 0.11158037910186627\n",
            "MAE on evaluation data: 0.06757714733215509\n",
            "Epochs 100\n",
            "Cost on training data: 0.9672349849386224\n",
            "MAPE on training data: 59.86004933516269\n",
            "RMSE on training data: 0.002969083004640015\n",
            "MAE on training data: 0.0024194233094877128\n",
            "Cost on evaluation data: 0.8873462687113612\n",
            "MAPE on evaluation data: 64.01907570167818\n",
            "RMSE on evaluation data: 0.0029612750413491816\n",
            "MAE on evaluation data: 0.0024128282369398554\n",
            "Epochs 200\n",
            "Cost on training data: 0.2164450784352141\n",
            "MAPE on training data: 38.08096631647302\n",
            "RMSE on training data: 0.0019176042828699736\n",
            "MAE on training data: 0.0015503021389789494\n",
            "Cost on evaluation data: 0.18304534555134444\n",
            "MAPE on evaluation data: 42.48029674799591\n",
            "RMSE on evaluation data: 0.0019188070583609316\n",
            "MAE on evaluation data: 0.0015574127034631105\n",
            "Epochs 300\n",
            "Cost on training data: 0.04780417321502065\n",
            "MAPE on training data: 34.95638036672925\n",
            "RMSE on training data: 0.0017773196871363947\n",
            "MAE on training data: 0.0014167055375723062\n",
            "Cost on evaluation data: 0.018956920128359873\n",
            "MAPE on evaluation data: 39.13405842557432\n",
            "RMSE on evaluation data: 0.0017773049810068974\n",
            "MAE on evaluation data: 0.0014231944340076547\n",
            "Epochs 400\n",
            "Cost on training data: 0.016365943343435933\n",
            "MAPE on training data: 20.955178791038982\n",
            "RMSE on training data: 0.0011302501376724658\n",
            "MAE on training data: 0.0008598765562032192\n",
            "Cost on evaluation data: 0.004522710438014824\n",
            "MAPE on evaluation data: 25.358197871813502\n",
            "RMSE on evaluation data: 0.0011424329477124884\n",
            "MAE on evaluation data: 0.000877866671660813\n",
            "Epochs 500\n",
            "Cost on training data: 0.011187213798124224\n",
            "MAPE on training data: 17.45864879240991\n",
            "RMSE on training data: 0.0009452307573617404\n",
            "MAE on training data: 0.0007219958465676186\n",
            "Cost on evaluation data: 0.002919672443781367\n",
            "MAPE on evaluation data: 21.942793393965616\n",
            "RMSE on evaluation data: 0.0009610180772780046\n",
            "MAE on evaluation data: 0.0007410194879619733\n",
            "Epochs 600\n",
            "Cost on training data: 0.011187213799404747\n",
            "MAPE on training data: 17.458648813309257\n",
            "RMSE on training data: 0.0009452307572216801\n",
            "MAE on training data: 0.0007219958468758874\n",
            "Cost on evaluation data: 0.002919672443220642\n",
            "MAPE on evaluation data: 21.942793415561248\n",
            "RMSE on evaluation data: 0.0009610180769774797\n",
            "MAE on evaluation data: 0.0007410194881898362\n",
            "Epochs 700\n",
            "Cost on training data: 0.01118721380068528\n",
            "MAPE on training data: 17.45864883420854\n",
            "RMSE on training data: 0.0009452307570816191\n",
            "MAE on training data: 0.0007219958471841547\n",
            "Cost on evaluation data: 0.0029196724426599568\n",
            "MAPE on evaluation data: 21.942793437156872\n",
            "RMSE on evaluation data: 0.0009610180766769575\n",
            "MAE on evaluation data: 0.0007410194884176997\n",
            "Epochs 800\n",
            "Cost on training data: 0.011187213801965879\n",
            "MAPE on training data: 17.458648855107814\n",
            "RMSE on training data: 0.0009452307569415592\n",
            "MAE on training data: 0.0007219958474924221\n",
            "Cost on evaluation data: 0.002919672442099307\n",
            "MAPE on evaluation data: 21.942793458752462\n",
            "RMSE on evaluation data: 0.0009610180763764332\n",
            "MAE on evaluation data: 0.0007410194886455619\n",
            "Epochs 900\n",
            "Cost on training data: 0.011187213803246486\n",
            "MAPE on training data: 17.458648876007064\n",
            "RMSE on training data: 0.0009452307568014991\n",
            "MAE on training data: 0.0007219958478006889\n",
            "Cost on evaluation data: 0.0029196724415387018\n",
            "MAPE on evaluation data: 21.942793480347998\n",
            "RMSE on evaluation data: 0.0009610180760759099\n",
            "MAE on evaluation data: 0.0007410194888734225\n",
            "Epochs 1000\n",
            "Cost on training data: 0.011187213804527163\n",
            "MAPE on training data: 17.458648896906283\n",
            "RMSE on training data: 0.0009452307566614394\n",
            "MAE on training data: 0.0007219958481089554\n",
            "Cost on evaluation data: 0.0029196724409781406\n",
            "MAPE on evaluation data: 21.942793501943537\n",
            "RMSE on evaluation data: 0.0009610180757753882\n",
            "MAE on evaluation data: 0.0007410194891012858\n",
            "Epochs 1100\n",
            "Cost on training data: 0.011187213805807866\n",
            "MAPE on training data: 17.45864891780549\n",
            "RMSE on training data: 0.0009452307565213801\n",
            "MAE on training data: 0.0007219958484172219\n",
            "Cost on evaluation data: 0.0029196724404176155\n",
            "MAPE on evaluation data: 21.94279352353909\n",
            "RMSE on evaluation data: 0.0009610180754748674\n",
            "MAE on evaluation data: 0.0007410194893291487\n",
            "Epochs 1200\n",
            "Cost on training data: 0.011187213807088606\n",
            "MAPE on training data: 17.458648938704716\n",
            "RMSE on training data: 0.0009452307563813221\n",
            "MAE on training data: 0.0007219958487254894\n",
            "Cost on evaluation data: 0.002919672439857129\n",
            "MAPE on evaluation data: 21.942793545134585\n",
            "RMSE on evaluation data: 0.0009610180751743445\n",
            "MAE on evaluation data: 0.0007410194895570086\n",
            "Epochs 1300\n",
            "Cost on training data: 0.011187213808369368\n",
            "MAPE on training data: 17.458648959603828\n",
            "RMSE on training data: 0.0009452307562412614\n",
            "MAE on training data: 0.0007219958490337531\n",
            "Cost on evaluation data: 0.0029196724392966792\n",
            "MAPE on evaluation data: 21.94279356673002\n",
            "RMSE on evaluation data: 0.0009610180748738225\n",
            "MAE on evaluation data: 0.0007410194897848717\n",
            "Epochs 1400\n",
            "Cost on training data: 0.011187213809650171\n",
            "MAPE on training data: 17.45864898050299\n",
            "RMSE on training data: 0.0009452307561012033\n",
            "MAE on training data: 0.0007219958493420194\n",
            "Cost on evaluation data: 0.0029196724387362777\n",
            "MAPE on evaluation data: 21.94279358832548\n",
            "RMSE on evaluation data: 0.000961018074573304\n",
            "MAE on evaluation data: 0.0007410194900127332\n",
            "Train and validation from state  SA  fold  5\n",
            "Epochs 0\n",
            "Cost on training data: 150.6985189490567\n",
            "MAPE on training data: 1710.927591107663\n",
            "RMSE on training data: 0.11157969836881795\n",
            "MAE on training data: 0.06755807067136883\n",
            "Cost on evaluation data: 39.79270594171544\n",
            "MAPE on evaluation data: 1691.2879965328764\n",
            "RMSE on evaluation data: 0.1115854181175267\n",
            "MAE on evaluation data: 0.06757805015799495\n",
            "Epochs 100\n",
            "Cost on training data: 0.9638812212085219\n",
            "MAPE on training data: 60.70778155864467\n",
            "RMSE on training data: 0.0029564689621590125\n",
            "MAE on training data: 0.002409803855010588\n",
            "Cost on evaluation data: 0.8855988902618074\n",
            "MAPE on evaluation data: 60.1958390973625\n",
            "RMSE on evaluation data: 0.0029826886981822033\n",
            "MAE on evaluation data: 0.0024302214200879638\n",
            "Epochs 200\n",
            "Cost on training data: 0.21435751868163783\n",
            "MAPE on training data: 39.0327328006159\n",
            "RMSE on training data: 0.001906151715143996\n",
            "MAE on training data: 0.0015429560986550729\n",
            "Cost on evaluation data: 0.18196513276538798\n",
            "MAPE on evaluation data: 38.605848991519565\n",
            "RMSE on evaluation data: 0.001953425762708926\n",
            "MAE on evaluation data: 0.0015753924192740709\n",
            "Epochs 300\n",
            "Cost on training data: 0.04702243830191027\n",
            "MAPE on training data: 35.7803428644805\n",
            "RMSE on training data: 0.0017639403006969876\n",
            "MAE on training data: 0.0014081979936307468\n",
            "Cost on evaluation data: 0.01917842757811377\n",
            "MAPE on evaluation data: 35.577132142480885\n",
            "RMSE on evaluation data: 0.00181562500259059\n",
            "MAE on evaluation data: 0.001447484658996888\n",
            "Epochs 400\n",
            "Cost on training data: 0.0159285669836349\n",
            "MAPE on training data: 21.787986166397218\n",
            "RMSE on training data: 0.0011147383917082811\n",
            "MAE on training data: 0.0008515681116495641\n",
            "Cost on evaluation data: 0.004918506330624945\n",
            "MAPE on evaluation data: 22.046094517859206\n",
            "RMSE on evaluation data: 0.001200305905886877\n",
            "MAE on evaluation data: 0.0009093834499698184\n",
            "Epochs 500\n",
            "Cost on training data: 0.010655104942493047\n",
            "MAPE on training data: 18.206103443043435\n",
            "RMSE on training data: 0.0009213647093242693\n",
            "MAE on training data: 0.0007098291309765225\n",
            "Cost on evaluation data: 0.0032995789240028903\n",
            "MAPE on evaluation data: 18.65639076609401\n",
            "RMSE on evaluation data: 0.0010266271980432149\n",
            "MAE on evaluation data: 0.0007753856975887927\n",
            "Epochs 600\n",
            "Cost on training data: 0.010655104941920736\n",
            "MAPE on training data: 18.206103449328392\n",
            "RMSE on training data: 0.0009213647092666793\n",
            "MAE on training data: 0.0007098291310741309\n",
            "Cost on evaluation data: 0.0032995789236592676\n",
            "MAPE on evaluation data: 18.656390772341048\n",
            "RMSE on evaluation data: 0.0010266271979870573\n",
            "MAE on evaluation data: 0.000775385697654313\n",
            "Epochs 700\n",
            "Cost on training data: 0.010655104941348444\n",
            "MAPE on training data: 18.206103455613352\n",
            "RMSE on training data: 0.0009213647092090883\n",
            "MAE on training data: 0.000709829131171738\n",
            "Cost on evaluation data: 0.0032995789233156857\n",
            "MAPE on evaluation data: 18.65639077858812\n",
            "RMSE on evaluation data: 0.0010266271979309017\n",
            "MAE on evaluation data: 0.0007753856977198345\n",
            "Epochs 800\n",
            "Cost on training data: 0.01065510358824095\n",
            "MAPE on training data: 18.206108921317817\n",
            "RMSE on training data: 0.0009213646551598178\n",
            "MAE on training data: 0.0007098291411340693\n",
            "Cost on evaluation data: 0.0032995783697486836\n",
            "MAPE on evaluation data: 18.656397459439315\n",
            "RMSE on evaluation data: 0.0010266270571089046\n",
            "MAE on evaluation data: 0.0007753857467148703\n",
            "Epochs 900\n",
            "Cost on training data: 0.010655103587658563\n",
            "MAPE on training data: 18.20610892759592\n",
            "RMSE on training data: 0.000921364655102275\n",
            "MAE on training data: 0.0007098291412315962\n",
            "Cost on evaluation data: 0.00329957836940287\n",
            "MAPE on evaluation data: 18.656397465679746\n",
            "RMSE on evaluation data: 0.0010266270570528106\n",
            "MAE on evaluation data: 0.0007753857467804189\n",
            "Epochs 1000\n",
            "Cost on training data: 0.010655108998420391\n",
            "MAPE on training data: 18.206114778112426\n",
            "RMSE on training data: 0.0009213645902709653\n",
            "MAE on training data: 0.0007098292434628624\n",
            "Cost on evaluation data: 0.0032995795495668104\n",
            "MAPE on evaluation data: 18.656404029639216\n",
            "RMSE on evaluation data: 0.0010266269493874247\n",
            "MAE on evaluation data: 0.0007753858734920017\n",
            "Epochs 1100\n",
            "Cost on training data: 0.01065510899781546\n",
            "MAPE on training data: 18.20611478435566\n",
            "RMSE on training data: 0.0009213645902136752\n",
            "MAE on training data: 0.0007098292435600176\n",
            "Cost on evaluation data: 0.0032995795492165195\n",
            "MAPE on evaluation data: 18.656404035846446\n",
            "RMSE on evaluation data: 0.001026626949331731\n",
            "MAE on evaluation data: 0.0007753858735575235\n",
            "Epochs 1200\n",
            "Cost on training data: 0.01065511202479582\n",
            "MAPE on training data: 18.206063216705846\n",
            "RMSE on training data: 0.0009213644321044475\n",
            "MAE on training data: 0.0007098281693770338\n",
            "Cost on evaluation data: 0.003299581528709623\n",
            "MAPE on evaluation data: 18.656351900823093\n",
            "RMSE on evaluation data: 0.0010266269467506996\n",
            "MAE on evaluation data: 0.0007753848079373321\n",
            "Epochs 1300\n",
            "Cost on training data: 0.010655112024246082\n",
            "MAPE on training data: 18.20606322282763\n",
            "RMSE on training data: 0.0009213644320483415\n",
            "MAE on training data: 0.000709828169473002\n",
            "Cost on evaluation data: 0.0032995815283760788\n",
            "MAPE on evaluation data: 18.656351906946497\n",
            "RMSE on evaluation data: 0.0010266269466969354\n",
            "MAE on evaluation data: 0.0007753848080023658\n",
            "Epochs 1400\n",
            "Cost on training data: 0.01065511202369641\n",
            "MAPE on training data: 18.20606322894935\n",
            "RMSE on training data: 0.0009213644319922353\n",
            "MAE on training data: 0.0007098281695689684\n",
            "Cost on evaluation data: 0.003299581528042606\n",
            "MAPE on evaluation data: 18.656351913069923\n",
            "RMSE on evaluation data: 0.0010266269466431763\n",
            "MAE on evaluation data: 0.0007753848080674007\n",
            "Train and validation from state  TAS  fold  1\n",
            "Weights and biases initialization for state  TAS  in progress...\n",
            "Epochs 0\n",
            "Cost on training data: 203.42521048622424\n",
            "MAPE on training data: 1857.0934700768626\n",
            "RMSE on training data: 0.1294262441462244\n",
            "MAE on training data: 0.07868510804454945\n",
            "Cost on evaluation data: 52.68177923569277\n",
            "MAPE on evaluation data: 1867.21942431016\n",
            "RMSE on evaluation data: 0.12943991802540744\n",
            "MAE on evaluation data: 0.07872622808606285\n",
            "Epochs 100\n",
            "Cost on training data: 0.8761473268382046\n",
            "MAPE on training data: 50.63770314936896\n",
            "RMSE on training data: 0.0024291199271983276\n",
            "MAE on training data: 0.00213330364269585\n",
            "Cost on evaluation data: 0.8225208971561737\n",
            "MAPE on evaluation data: 50.82519150469111\n",
            "RMSE on evaluation data: 0.0024284718995134535\n",
            "MAE on evaluation data: 0.0021311433522299716\n",
            "Epochs 200\n",
            "Cost on training data: 0.19161229323369644\n",
            "MAPE on training data: 35.406835907636406\n",
            "RMSE on training data: 0.0017814065611176187\n",
            "MAE on training data: 0.0014888598288733074\n",
            "Cost on evaluation data: 0.16274351906267118\n",
            "MAPE on evaluation data: 35.63390362778595\n",
            "RMSE on evaluation data: 0.0017829214759181888\n",
            "MAE on evaluation data: 0.0014908662028602624\n",
            "Epochs 300\n",
            "Cost on training data: 0.028293093624930994\n",
            "MAPE on training data: 25.58313525683887\n",
            "RMSE on training data: 0.0013634935791808625\n",
            "MAE on training data: 0.0010739585454538935\n",
            "Cost on evaluation data: 0.011272616936006011\n",
            "MAPE on evaluation data: 25.946217659985948\n",
            "RMSE on evaluation data: 0.0013688461035889637\n",
            "MAE on evaluation data: 0.001082067082177395\n",
            "Epochs 400\n",
            "Cost on training data: 0.005445133135604925\n",
            "MAPE on training data: 11.826866205320805\n",
            "RMSE on training data: 0.0006612862510422266\n",
            "MAE on training data: 0.0005048827912337437\n",
            "Cost on evaluation data: 0.00137431762390152\n",
            "MAPE on evaluation data: 12.016616417068422\n",
            "RMSE on evaluation data: 0.0006589436660256572\n",
            "MAE on evaluation data: 0.0005063960145558193\n",
            "Epochs 500\n",
            "Cost on training data: 0.004297001841460855\n",
            "MAPE on training data: 10.809440509767493\n",
            "RMSE on training data: 0.0005911911270469447\n",
            "MAE on training data: 0.00046499809580494595\n",
            "Cost on evaluation data: 0.00105370814177345\n",
            "MAPE on evaluation data: 10.969415450377596\n",
            "RMSE on evaluation data: 0.0005868039426505876\n",
            "MAE on evaluation data: 0.0004651901302426573\n",
            "Epochs 600\n",
            "Cost on training data: 0.00429699572055123\n",
            "MAPE on training data: 10.809453552634842\n",
            "RMSE on training data: 0.00059119104554339\n",
            "MAE on training data: 0.00046499834925221623\n",
            "Cost on evaluation data: 0.001053706938812523\n",
            "MAPE on evaluation data: 10.969436400774047\n",
            "RMSE on evaluation data: 0.0005868038598474599\n",
            "MAE on evaluation data: 0.0004651907062566093\n",
            "Epochs 700\n",
            "Cost on training data: 0.004296995718819039\n",
            "MAPE on training data: 10.809453557273175\n",
            "RMSE on training data: 0.0005911910454311014\n",
            "MAE on training data: 0.00046499834931450164\n",
            "Cost on evaluation data: 0.0010537069385368042\n",
            "MAPE on evaluation data: 10.969436407324098\n",
            "RMSE on evaluation data: 0.0005868038597988958\n",
            "MAE on evaluation data: 0.0004651907063956179\n",
            "Epochs 800\n",
            "Cost on training data: 0.004296995717086875\n",
            "MAPE on training data: 10.809453561911504\n",
            "RMSE on training data: 0.0005911910453188121\n",
            "MAE on training data: 0.0004649983493767866\n",
            "Cost on evaluation data: 0.0010537069382611148\n",
            "MAPE on evaluation data: 10.96943641387423\n",
            "RMSE on evaluation data: 0.0005868038597503331\n",
            "MAE on evaluation data: 0.0004651907065346299\n",
            "Epochs 900\n",
            "Cost on training data: 0.004296995715354741\n",
            "MAPE on training data: 10.809453566549792\n",
            "RMSE on training data: 0.000591191045206522\n",
            "MAE on training data: 0.00046499834943907007\n",
            "Cost on evaluation data: 0.0010537069379854401\n",
            "MAPE on evaluation data: 10.969436420424321\n",
            "RMSE on evaluation data: 0.0005868038597017688\n",
            "MAE on evaluation data: 0.00046519070667364027\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004296995713622613\n",
            "MAPE on training data: 10.809453571188135\n",
            "RMSE on training data: 0.0005911910450942326\n",
            "MAE on training data: 0.00046499834950135564\n",
            "Cost on evaluation data: 0.0010537069377097932\n",
            "MAPE on evaluation data: 10.969436426974449\n",
            "RMSE on evaluation data: 0.0005868038596532068\n",
            "MAE on evaluation data: 0.000465190706812652\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004296995711890521\n",
            "MAPE on training data: 10.809453575826474\n",
            "RMSE on training data: 0.0005911910449819445\n",
            "MAE on training data: 0.00046499834956364127\n",
            "Cost on evaluation data: 0.0010537069374341626\n",
            "MAPE on evaluation data: 10.969436433524553\n",
            "RMSE on evaluation data: 0.0005868038596046431\n",
            "MAE on evaluation data: 0.000465190706951663\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004296995710158447\n",
            "MAPE on training data: 10.809453580464782\n",
            "RMSE on training data: 0.0005911910448696544\n",
            "MAE on training data: 0.0004649983496259252\n",
            "Cost on evaluation data: 0.00105370693715856\n",
            "MAPE on evaluation data: 10.969436440074642\n",
            "RMSE on evaluation data: 0.0005868038595560805\n",
            "MAE on evaluation data: 0.0004651907070906727\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004296995708426399\n",
            "MAPE on training data: 10.809453585103128\n",
            "RMSE on training data: 0.000591191044757366\n",
            "MAE on training data: 0.0004649983496882108\n",
            "Cost on evaluation data: 0.001053706936882977\n",
            "MAPE on evaluation data: 10.969436446624728\n",
            "RMSE on evaluation data: 0.0005868038595075171\n",
            "MAE on evaluation data: 0.00046519070722968246\n",
            "Epochs 1400\n",
            "Cost on training data: 0.00429699570669436\n",
            "MAPE on training data: 10.809453589741445\n",
            "RMSE on training data: 0.000591191044645076\n",
            "MAE on training data: 0.00046499834975049516\n",
            "Cost on evaluation data: 0.0010537069366074125\n",
            "MAPE on evaluation data: 10.969436453174866\n",
            "RMSE on evaluation data: 0.0005868038594589547\n",
            "MAE on evaluation data: 0.00046519070736869436\n",
            "Train and validation from state  TAS  fold  2\n",
            "Epochs 0\n",
            "Cost on training data: 207.09387653265694\n",
            "MAPE on training data: 1876.236851945502\n",
            "RMSE on training data: 0.1307312871549577\n",
            "MAE on training data: 0.0794951818957015\n",
            "Cost on evaluation data: 53.69620946205877\n",
            "MAPE on evaluation data: 1883.9631663331627\n",
            "RMSE on evaluation data: 0.13074381828968143\n",
            "MAE on evaluation data: 0.07951628781995909\n",
            "Epochs 100\n",
            "Cost on training data: 0.8955433933256536\n",
            "MAPE on training data: 50.99095908892994\n",
            "RMSE on training data: 0.0024408748670998607\n",
            "MAE on training data: 0.0021476404686829762\n",
            "Cost on evaluation data: 0.8416971202363417\n",
            "MAPE on evaluation data: 51.08043591803245\n",
            "RMSE on evaluation data: 0.002441036504523738\n",
            "MAE on evaluation data: 0.002144000852026214\n",
            "Epochs 200\n",
            "Cost on training data: 0.20425982666144468\n",
            "MAPE on training data: 35.5005806725866\n",
            "RMSE on training data: 0.001785950406151228\n",
            "MAE on training data: 0.0014927543820513279\n",
            "Cost on evaluation data: 0.17534896703833006\n",
            "MAPE on evaluation data: 35.65612603155544\n",
            "RMSE on evaluation data: 0.0017867946028947365\n",
            "MAE on evaluation data: 0.0014936388055995903\n",
            "Epochs 300\n",
            "Cost on training data: 0.030990491523028227\n",
            "MAPE on training data: 26.59319349369011\n",
            "RMSE on training data: 0.0014081281442226339\n",
            "MAE on training data: 0.0011154472908705385\n",
            "Cost on evaluation data: 0.012926436583152304\n",
            "MAPE on evaluation data: 26.765300812345327\n",
            "RMSE on evaluation data: 0.0014106833618052778\n",
            "MAE on evaluation data: 0.0011183903630273533\n",
            "Epochs 400\n",
            "Cost on training data: 0.005546390128194347\n",
            "MAPE on training data: 11.96841096999472\n",
            "RMSE on training data: 0.0006659102300132889\n",
            "MAE on training data: 0.000509204730952727\n",
            "Cost on evaluation data: 0.0014338638865525953\n",
            "MAPE on evaluation data: 12.013506575335771\n",
            "RMSE on evaluation data: 0.0006653464125481382\n",
            "MAE on evaluation data: 0.0005069716978872186\n",
            "Epochs 500\n",
            "Cost on training data: 0.004286115370333019\n",
            "MAPE on training data: 10.904910080316721\n",
            "RMSE on training data: 0.0005913024025200061\n",
            "MAE on training data: 0.00046730891123827114\n",
            "Cost on evaluation data: 0.0010579324229423898\n",
            "MAPE on evaluation data: 10.915910798229536\n",
            "RMSE on evaluation data: 0.0005872414998084234\n",
            "MAE on evaluation data: 0.00046357472803589596\n",
            "Epochs 600\n",
            "Cost on training data: 0.004286115370404091\n",
            "MAPE on training data: 10.90491007913065\n",
            "RMSE on training data: 0.0005913024025421149\n",
            "MAE on training data: 0.00046730891122578384\n",
            "Cost on evaluation data: 0.0010579324229312377\n",
            "MAPE on evaluation data: 10.915910796441235\n",
            "RMSE on evaluation data: 0.0005872414998220608\n",
            "MAE on evaluation data: 0.00046357472800050083\n",
            "Epochs 700\n",
            "Cost on training data: 0.004286115370475165\n",
            "MAPE on training data: 10.904910077944576\n",
            "RMSE on training data: 0.0005913024025642231\n",
            "MAE on training data: 0.00046730891121329616\n",
            "Cost on evaluation data: 0.0010579324229201023\n",
            "MAPE on evaluation data: 10.915910794652959\n",
            "RMSE on evaluation data: 0.0005872414998356989\n",
            "MAE on evaluation data: 0.0004635747279651071\n",
            "Epochs 800\n",
            "Cost on training data: 0.004286115370546258\n",
            "MAPE on training data: 10.904910076758515\n",
            "RMSE on training data: 0.0005913024025863326\n",
            "MAE on training data: 0.0004673089112008092\n",
            "Cost on evaluation data: 0.0010579324229089604\n",
            "MAPE on evaluation data: 10.915910792864636\n",
            "RMSE on evaluation data: 0.0005872414998493364\n",
            "MAE on evaluation data: 0.00046357472792971186\n",
            "Epochs 900\n",
            "Cost on training data: 0.004286115370617351\n",
            "MAPE on training data: 10.904910075572419\n",
            "RMSE on training data: 0.0005913024026084402\n",
            "MAE on training data: 0.00046730891118832075\n",
            "Cost on evaluation data: 0.0010579324228978393\n",
            "MAPE on evaluation data: 10.915910791076309\n",
            "RMSE on evaluation data: 0.0005872414998629725\n",
            "MAE on evaluation data: 0.000463574727894316\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004286107955305056\n",
            "MAPE on training data: 10.904891301016116\n",
            "RMSE on training data: 0.0005913023363836315\n",
            "MAE on training data: 0.0004673085242481258\n",
            "Cost on evaluation data: 0.001057930181463401\n",
            "MAPE on evaluation data: 10.915891211491024\n",
            "RMSE on evaluation data: 0.0005872413519634776\n",
            "MAE on evaluation data: 0.00046357428513670626\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004286107955363447\n",
            "MAPE on training data: 10.904891299789773\n",
            "RMSE on training data: 0.0005913023364054716\n",
            "MAE on training data: 0.00046730852423460407\n",
            "Cost on evaluation data: 0.0010579301814484265\n",
            "MAPE on evaluation data: 10.915891209665526\n",
            "RMSE on evaluation data: 0.0005872413519767167\n",
            "MAE on evaluation data: 0.0004635742851003738\n",
            "Epochs 1200\n",
            "Cost on training data: 0.0042861079554218475\n",
            "MAPE on training data: 10.904891298563435\n",
            "RMSE on training data: 0.0005913023364273126\n",
            "MAE on training data: 0.0004673085242210827\n",
            "Cost on evaluation data: 0.001057930181433449\n",
            "MAPE on evaluation data: 10.915891207840001\n",
            "RMSE on evaluation data: 0.0005872413519899534\n",
            "MAE on evaluation data: 0.00046357428506404\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004286107955480262\n",
            "MAPE on training data: 10.904891297337116\n",
            "RMSE on training data: 0.0005913023364491545\n",
            "MAE on training data: 0.00046730852420756233\n",
            "Cost on evaluation data: 0.0010579301814184875\n",
            "MAPE on evaluation data: 10.915891206014436\n",
            "RMSE on evaluation data: 0.0005872413520031905\n",
            "MAE on evaluation data: 0.0004635742850277046\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004286107955538694\n",
            "MAPE on training data: 10.904891296110776\n",
            "RMSE on training data: 0.0005913023364709952\n",
            "MAE on training data: 0.00046730852419404054\n",
            "Cost on evaluation data: 0.001057930181403533\n",
            "MAPE on evaluation data: 10.915891204188881\n",
            "RMSE on evaluation data: 0.0005872413520164267\n",
            "MAE on evaluation data: 0.000463574284991369\n",
            "Train and validation from state  TAS  fold  3\n",
            "Epochs 0\n",
            "Cost on training data: 206.69134750297758\n",
            "MAPE on training data: 1879.9916221222763\n",
            "RMSE on training data: 0.13073391546308583\n",
            "MAE on training data: 0.07950322244237076\n",
            "Cost on evaluation data: 53.68286140424046\n",
            "MAPE on evaluation data: 1866.725411531253\n",
            "RMSE on evaluation data: 0.1307258887928398\n",
            "MAE on evaluation data: 0.0794822257820854\n",
            "Epochs 100\n",
            "Cost on training data: 0.8934167251532664\n",
            "MAPE on training data: 51.07719738336633\n",
            "RMSE on training data: 0.0024427458092990476\n",
            "MAE on training data: 0.00214814583754855\n",
            "Cost on evaluation data: 0.8396142250228069\n",
            "MAPE on evaluation data: 50.738596229814625\n",
            "RMSE on evaluation data: 0.002441036209112716\n",
            "MAE on evaluation data: 0.0021463773355476484\n",
            "Epochs 200\n",
            "Cost on training data: 0.20289709961933186\n",
            "MAPE on training data: 35.63034440100968\n",
            "RMSE on training data: 0.001788606848085667\n",
            "MAE on training data: 0.001495811043615206\n",
            "Cost on evaluation data: 0.17397167385517276\n",
            "MAPE on evaluation data: 35.40736882105983\n",
            "RMSE on evaluation data: 0.0017904097631556524\n",
            "MAE on evaluation data: 0.0014944747207655679\n",
            "Epochs 300\n",
            "Cost on training data: 0.030793212722016006\n",
            "MAPE on training data: 26.613270467660506\n",
            "RMSE on training data: 0.001408452575899835\n",
            "MAE on training data: 0.0011151714203213898\n",
            "Cost on evaluation data: 0.012756152661088496\n",
            "MAPE on evaluation data: 26.360462974352995\n",
            "RMSE on evaluation data: 0.0014085189733439997\n",
            "MAE on evaluation data: 0.0011110083662507104\n",
            "Epochs 400\n",
            "Cost on training data: 0.005422839036324339\n",
            "MAPE on training data: 11.84886176368048\n",
            "RMSE on training data: 0.0006590053310063273\n",
            "MAE on training data: 0.0005034030459700564\n",
            "Cost on evaluation data: 0.001491560632838089\n",
            "MAPE on evaluation data: 12.002185508220661\n",
            "RMSE on evaluation data: 0.0006796959920017774\n",
            "MAE on evaluation data: 0.0005162439105143353\n",
            "Epochs 500\n",
            "Cost on training data: 0.004190061207082107\n",
            "MAPE on training data: 10.787410527315004\n",
            "RMSE on training data: 0.0005850245016492153\n",
            "MAE on training data: 0.0004615881479151444\n",
            "Cost on evaluation data: 0.001144808999720178\n",
            "MAPE on evaluation data: 10.985059122355388\n",
            "RMSE on evaluation data: 0.000610567910498244\n",
            "MAE on evaluation data: 0.0004768041198572915\n",
            "Epochs 600\n",
            "Cost on training data: 0.0041900541793230385\n",
            "MAPE on training data: 10.787433341111035\n",
            "RMSE on training data: 0.0005850244182407094\n",
            "MAE on training data: 0.0004615885846841719\n",
            "Cost on evaluation data: 0.001144806166483013\n",
            "MAPE on evaluation data: 10.98508457052629\n",
            "RMSE on evaluation data: 0.0006105676628940548\n",
            "MAE on evaluation data: 0.00047680465842685074\n",
            "Epochs 700\n",
            "Cost on training data: 0.004190054178566932\n",
            "MAPE on training data: 10.787433343761824\n",
            "RMSE on training data: 0.0005850244182230648\n",
            "MAE on training data: 0.00046158858474165616\n",
            "Cost on evaluation data: 0.001144806166199549\n",
            "MAPE on evaluation data: 10.985084572809544\n",
            "RMSE on evaluation data: 0.0006105676628584698\n",
            "MAE on evaluation data: 0.00047680465846829513\n",
            "Epochs 800\n",
            "Cost on training data: 0.004190054177810866\n",
            "MAPE on training data: 10.787433346412657\n",
            "RMSE on training data: 0.000585024418205423\n",
            "MAE on training data: 0.0004615885847991421\n",
            "Cost on evaluation data: 0.0011448061659161109\n",
            "MAPE on evaluation data: 10.98508457509283\n",
            "RMSE on evaluation data: 0.000610567662822886\n",
            "MAE on evaluation data: 0.0004768046585097404\n",
            "Epochs 900\n",
            "Cost on training data: 0.0041900541770548035\n",
            "MAPE on training data: 10.787433349063505\n",
            "RMSE on training data: 0.0005850244181877803\n",
            "MAE on training data: 0.0004615885848566289\n",
            "Cost on evaluation data: 0.0011448061656326803\n",
            "MAPE on evaluation data: 10.98508457737608\n",
            "RMSE on evaluation data: 0.0006105676627873003\n",
            "MAE on evaluation data: 0.000476804658551184\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004190054176298736\n",
            "MAPE on training data: 10.787433351714313\n",
            "RMSE on training data: 0.0005850244181701356\n",
            "MAE on training data: 0.0004615885849141138\n",
            "Cost on evaluation data: 0.0011448061653492672\n",
            "MAPE on evaluation data: 10.985084579659365\n",
            "RMSE on evaluation data: 0.000610567662751715\n",
            "MAE on evaluation data: 0.00047680465859262916\n",
            "Epochs 1100\n",
            "Cost on training data: 0.004190054175542701\n",
            "MAPE on training data: 10.787433354365138\n",
            "RMSE on training data: 0.0005850244181524921\n",
            "MAE on training data: 0.0004615885849715995\n",
            "Cost on evaluation data: 0.0011448061650658758\n",
            "MAPE on evaluation data: 10.985084581942655\n",
            "RMSE on evaluation data: 0.0006105676627161317\n",
            "MAE on evaluation data: 0.0004768046586340747\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004190054174786692\n",
            "MAPE on training data: 10.787433357015948\n",
            "RMSE on training data: 0.0005850244181348488\n",
            "MAE on training data: 0.0004615885850290845\n",
            "Cost on evaluation data: 0.0011448061647825049\n",
            "MAPE on evaluation data: 10.985084584225943\n",
            "RMSE on evaluation data: 0.0006105676626805485\n",
            "MAE on evaluation data: 0.0004768046586755202\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004190054174030694\n",
            "MAPE on training data: 10.787433359666807\n",
            "RMSE on training data: 0.0005850244181172062\n",
            "MAE on training data: 0.00046158858508657145\n",
            "Cost on evaluation data: 0.0011448061644991421\n",
            "MAPE on evaluation data: 10.9850845865092\n",
            "RMSE on evaluation data: 0.0006105676626449626\n",
            "MAE on evaluation data: 0.0004768046587169643\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004190054173274686\n",
            "MAPE on training data: 10.787433362317588\n",
            "RMSE on training data: 0.000585024418099561\n",
            "MAE on training data: 0.00046158858514405525\n",
            "Cost on evaluation data: 0.0011448061642158\n",
            "MAPE on evaluation data: 10.985084588792489\n",
            "RMSE on evaluation data: 0.0006105676626093782\n",
            "MAE on evaluation data: 0.00047680465875840985\n",
            "Train and validation from state  TAS  fold  4\n",
            "Epochs 0\n",
            "Cost on training data: 206.2703175175937\n",
            "MAPE on training data: 1877.110018368399\n",
            "RMSE on training data: 0.13073137162823553\n",
            "MAE on training data: 0.07949882696011236\n",
            "Cost on evaluation data: 53.688365862586735\n",
            "MAPE on evaluation data: 1877.249843956477\n",
            "RMSE on evaluation data: 0.13072912855846847\n",
            "MAE on evaluation data: 0.07948857280493914\n",
            "Epochs 100\n",
            "Cost on training data: 0.8917006106677622\n",
            "MAPE on training data: 51.18411369672795\n",
            "RMSE on training data: 0.0024509662167792705\n",
            "MAE on training data: 0.0021547940273562156\n",
            "Cost on evaluation data: 0.837630799782621\n",
            "MAPE on evaluation data: 51.21464936590484\n",
            "RMSE on evaluation data: 0.0024511154481106994\n",
            "MAE on evaluation data: 0.002157280717641586\n",
            "Epochs 200\n",
            "Cost on training data: 0.20166844082071955\n",
            "MAPE on training data: 35.66862473730517\n",
            "RMSE on training data: 0.001794519894066132\n",
            "MAE on training data: 0.0014988343544122386\n",
            "Cost on evaluation data: 0.1725997363842374\n",
            "MAPE on evaluation data: 35.67075645041326\n",
            "RMSE on evaluation data: 0.0017934591546270632\n",
            "MAE on evaluation data: 0.0015003799115292035\n",
            "Epochs 300\n",
            "Cost on training data: 0.03069241228366061\n",
            "MAPE on training data: 26.56564758543564\n",
            "RMSE on training data: 0.0014110595965673605\n",
            "MAE on training data: 0.0011140141258433988\n",
            "Cost on evaluation data: 0.012585014375244976\n",
            "MAPE on evaluation data: 26.490341121601034\n",
            "RMSE on evaluation data: 0.0014083628919181967\n",
            "MAE on evaluation data: 0.0011130944471696175\n",
            "Epochs 400\n",
            "Cost on training data: 0.005496760328532633\n",
            "MAPE on training data: 11.960249172822397\n",
            "RMSE on training data: 0.0006652069024817925\n",
            "MAE on training data: 0.0005086947410255344\n",
            "Cost on evaluation data: 0.0013961484231648843\n",
            "MAPE on evaluation data: 11.706466721708454\n",
            "RMSE on evaluation data: 0.000655107216215737\n",
            "MAE on evaluation data: 0.0004989652283775251\n",
            "Epochs 500\n",
            "Cost on training data: 0.004288121331111878\n",
            "MAPE on training data: 10.911840604448177\n",
            "RMSE on training data: 0.0005927239448390759\n",
            "MAE on training data: 0.0004676184384134855\n",
            "Cost on evaluation data: 0.0010443085049260514\n",
            "MAPE on evaluation data: 10.657925935823588\n",
            "RMSE on evaluation data: 0.0005823001678422769\n",
            "MAE on evaluation data: 0.000457536276765389\n",
            "Epochs 600\n",
            "Cost on training data: 0.004288123564043108\n",
            "MAPE on training data: 10.911825561615617\n",
            "RMSE on training data: 0.0005927238895611954\n",
            "MAE on training data: 0.0004676180068749997\n",
            "Cost on evaluation data: 0.001044309029928453\n",
            "MAPE on evaluation data: 10.657909163466197\n",
            "RMSE on evaluation data: 0.0005823000588782877\n",
            "MAE on evaluation data: 0.00045753576666542235\n",
            "Epochs 700\n",
            "Cost on training data: 0.004288123565663751\n",
            "MAPE on training data: 10.911825557089376\n",
            "RMSE on training data: 0.0005927238895367292\n",
            "MAE on training data: 0.00046761800675410107\n",
            "Cost on evaluation data: 0.0010443090303246991\n",
            "MAPE on evaluation data: 10.657909158446085\n",
            "RMSE on evaluation data: 0.0005823000588380216\n",
            "MAE on evaluation data: 0.00045753576652436966\n",
            "Epochs 800\n",
            "Cost on training data: 0.004288123567284381\n",
            "MAPE on training data: 10.911825552563096\n",
            "RMSE on training data: 0.000592723889512262\n",
            "MAE on training data: 0.00046761800663320055\n",
            "Cost on evaluation data: 0.001044309030720958\n",
            "MAPE on evaluation data: 10.657909153425935\n",
            "RMSE on evaluation data: 0.0005823000587977551\n",
            "MAE on evaluation data: 0.0004575357663833151\n",
            "Epochs 900\n",
            "Cost on training data: 0.004288123568905043\n",
            "MAPE on training data: 10.911825548036868\n",
            "RMSE on training data: 0.0005927238894877963\n",
            "MAE on training data: 0.0004676180065123021\n",
            "Cost on evaluation data: 0.0010443090311172251\n",
            "MAPE on evaluation data: 10.657909148405773\n",
            "RMSE on evaluation data: 0.0005823000587574875\n",
            "MAE on evaluation data: 0.00045753576624226025\n",
            "Epochs 1000\n",
            "Cost on training data: 0.00428812357052571\n",
            "MAPE on training data: 10.911825543510643\n",
            "RMSE on training data: 0.0005927238894633298\n",
            "MAE on training data: 0.0004676180063914035\n",
            "Cost on evaluation data: 0.0010443090315134997\n",
            "MAPE on evaluation data: 10.657909143385677\n",
            "RMSE on evaluation data: 0.0005823000587172203\n",
            "MAE on evaluation data: 0.00045753576610120755\n",
            "Epochs 1100\n",
            "Cost on training data: 0.0042881235721463655\n",
            "MAPE on training data: 10.911825538984402\n",
            "RMSE on training data: 0.0005927238894388617\n",
            "MAE on training data: 0.00046761800627050386\n",
            "Cost on evaluation data: 0.0010443090319097845\n",
            "MAPE on evaluation data: 10.657909138365582\n",
            "RMSE on evaluation data: 0.0005823000586769534\n",
            "MAE on evaluation data: 0.0004575357659601544\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004288123573767042\n",
            "MAPE on training data: 10.911825534458167\n",
            "RMSE on training data: 0.000592723889414395\n",
            "MAE on training data: 0.00046761800614960475\n",
            "Cost on evaluation data: 0.0010443090323060801\n",
            "MAPE on evaluation data: 10.657909133345452\n",
            "RMSE on evaluation data: 0.0005823000586366852\n",
            "MAE on evaluation data: 0.0004575357658191003\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004288123575387738\n",
            "MAPE on training data: 10.911825529931955\n",
            "RMSE on training data: 0.0005927238893899289\n",
            "MAE on training data: 0.0004676180060287064\n",
            "Cost on evaluation data: 0.0010443090327023786\n",
            "MAPE on evaluation data: 10.657909128325333\n",
            "RMSE on evaluation data: 0.0005823000585964177\n",
            "MAE on evaluation data: 0.00045753576567804616\n",
            "Epochs 1400\n",
            "Cost on training data: 0.00428812357700842\n",
            "MAPE on training data: 10.911825525405728\n",
            "RMSE on training data: 0.0005927238893654613\n",
            "MAE on training data: 0.0004676180059078068\n",
            "Cost on evaluation data: 0.001044309033098693\n",
            "MAPE on evaluation data: 10.657909123305231\n",
            "RMSE on evaluation data: 0.0005823000585561501\n",
            "MAE on evaluation data: 0.0004575357655369931\n",
            "Train and validation from state  TAS  fold  5\n",
            "Epochs 0\n",
            "Cost on training data: 205.86366337810261\n",
            "MAPE on training data: 1876.8912019565178\n",
            "RMSE on training data: 0.13073200863531736\n",
            "MAE on training data: 0.07950074851142816\n",
            "Cost on evaluation data: 53.679913359489724\n",
            "MAPE on evaluation data: 1876.478269821327\n",
            "RMSE on evaluation data: 0.13072084549999868\n",
            "MAE on evaluation data: 0.0794765033476847\n",
            "Epochs 100\n",
            "Cost on training data: 0.8894739333926465\n",
            "MAPE on training data: 51.152579132020634\n",
            "RMSE on training data: 0.002451543009837577\n",
            "MAE on training data: 0.0021546418608141666\n",
            "Cost on evaluation data: 0.8356240749189394\n",
            "MAPE on evaluation data: 51.32299279927906\n",
            "RMSE on evaluation data: 0.0024545787634645986\n",
            "MAE on evaluation data: 0.0021607152947759837\n",
            "Epochs 200\n",
            "Cost on training data: 0.20019031115537195\n",
            "MAPE on training data: 35.66574165532218\n",
            "RMSE on training data: 0.0017950652307186273\n",
            "MAE on training data: 0.0014992580321988138\n",
            "Cost on evaluation data: 0.17122079984425928\n",
            "MAPE on evaluation data: 35.626554273976865\n",
            "RMSE on evaluation data: 0.001793524208503995\n",
            "MAE on evaluation data: 0.0014979581534902595\n",
            "Epochs 300\n",
            "Cost on training data: 0.03025392411650177\n",
            "MAPE on training data: 26.409768331751877\n",
            "RMSE on training data: 0.0014042829848872568\n",
            "MAE on training data: 0.0011079831399363961\n",
            "Cost on evaluation data: 0.01238692645099609\n",
            "MAPE on evaluation data: 26.312099946603656\n",
            "RMSE on evaluation data: 0.0014009557410589648\n",
            "MAE on evaluation data: 0.0011042133744041368\n",
            "Epochs 400\n",
            "Cost on training data: 0.00551423585806534\n",
            "MAPE on training data: 11.966184799464322\n",
            "RMSE on training data: 0.0006671627410451463\n",
            "MAE on training data: 0.0005086092659773446\n",
            "Cost on evaluation data: 0.001412219097701799\n",
            "MAPE on evaluation data: 11.910183752587155\n",
            "RMSE on evaluation data: 0.0006607528042752049\n",
            "MAE on evaluation data: 0.0005077573348892207\n",
            "Epochs 500\n",
            "Cost on training data: 0.004270137489312646\n",
            "MAPE on training data: 10.891676718599598\n",
            "RMSE on training data: 0.0005919917133657622\n",
            "MAE on training data: 0.0004662898736720639\n",
            "Cost on evaluation data: 0.0010537495769733657\n",
            "MAPE on evaluation data: 10.843145779676732\n",
            "RMSE on evaluation data: 0.0005854316265523652\n",
            "MAE on evaluation data: 0.00046582759828262075\n",
            "Epochs 600\n",
            "Cost on training data: 0.0042701379109553374\n",
            "MAPE on training data: 10.891680868314621\n",
            "RMSE on training data: 0.0005919917176056951\n",
            "MAE on training data: 0.00046628998036194174\n",
            "Cost on evaluation data: 0.0010537496978004178\n",
            "MAPE on evaluation data: 10.843149651240982\n",
            "RMSE on evaluation data: 0.0005854316234518313\n",
            "MAE on evaluation data: 0.00046582769187003087\n",
            "Epochs 700\n",
            "Cost on training data: 0.004270137909374291\n",
            "MAPE on training data: 10.891680856680638\n",
            "RMSE on training data: 0.000591991717530105\n",
            "MAE on training data: 0.000466289980066999\n",
            "Cost on evaluation data: 0.0010537496973349796\n",
            "MAPE on evaluation data: 10.843149641766377\n",
            "RMSE on evaluation data: 0.0005854316233778634\n",
            "MAE on evaluation data: 0.00046582769166907763\n",
            "Epochs 800\n",
            "Cost on training data: 0.0042701379077932575\n",
            "MAPE on training data: 10.891680845046647\n",
            "RMSE on training data: 0.0005919917174545149\n",
            "MAE on training data: 0.0004662899797720557\n",
            "Cost on evaluation data: 0.001053749696869567\n",
            "MAPE on evaluation data: 10.843149632291855\n",
            "RMSE on evaluation data: 0.0005854316233038992\n",
            "MAE on evaluation data: 0.0004658276914681278\n",
            "Epochs 900\n",
            "Cost on training data: 0.004270137906212237\n",
            "MAPE on training data: 10.891680833412668\n",
            "RMSE on training data: 0.000591991717378925\n",
            "MAE on training data: 0.000466289979477113\n",
            "Cost on evaluation data: 0.001053749696404155\n",
            "MAPE on evaluation data: 10.843149622817219\n",
            "RMSE on evaluation data: 0.0005854316232299298\n",
            "MAE on evaluation data: 0.0004658276912671731\n",
            "Epochs 1000\n",
            "Cost on training data: 0.004270137904631243\n",
            "MAPE on training data: 10.891680821778694\n",
            "RMSE on training data: 0.0005919917173033367\n",
            "MAE on training data: 0.0004662899791821708\n",
            "Cost on evaluation data: 0.0010537496959387583\n",
            "MAPE on evaluation data: 10.843149613342579\n",
            "RMSE on evaluation data: 0.0005854316231559613\n",
            "MAE on evaluation data: 0.0004658276910662188\n",
            "Epochs 1100\n",
            "Cost on training data: 0.00427013790305024\n",
            "MAPE on training data: 10.89168081014469\n",
            "RMSE on training data: 0.0005919917172277462\n",
            "MAE on training data: 0.0004662899788872269\n",
            "Cost on evaluation data: 0.0010537496954733808\n",
            "MAPE on evaluation data: 10.843149603868044\n",
            "RMSE on evaluation data: 0.0005854316230819963\n",
            "MAE on evaluation data: 0.0004658276908652687\n",
            "Epochs 1200\n",
            "Cost on training data: 0.004270137901469263\n",
            "MAPE on training data: 10.891680798510686\n",
            "RMSE on training data: 0.0005919917171521563\n",
            "MAE on training data: 0.0004662899785922835\n",
            "Cost on evaluation data: 0.0010537496950080122\n",
            "MAPE on evaluation data: 10.8431495943934\n",
            "RMSE on evaluation data: 0.0005854316230080272\n",
            "MAE on evaluation data: 0.00046582769066431386\n",
            "Epochs 1300\n",
            "Cost on training data: 0.004270137899888282\n",
            "MAPE on training data: 10.89168078687668\n",
            "RMSE on training data: 0.0005919917170765661\n",
            "MAE on training data: 0.0004662899782973396\n",
            "Cost on evaluation data: 0.0010537496945426496\n",
            "MAPE on evaluation data: 10.843149584918804\n",
            "RMSE on evaluation data: 0.0005854316229340585\n",
            "MAE on evaluation data: 0.00046582769046336057\n",
            "Epochs 1400\n",
            "Cost on training data: 0.004270137898307315\n",
            "MAPE on training data: 10.891680775242664\n",
            "RMSE on training data: 0.0005919917170009766\n",
            "MAE on training data: 0.0004662899780023955\n",
            "Cost on evaluation data: 0.001053749694077313\n",
            "MAPE on evaluation data: 10.843149575444219\n",
            "RMSE on evaluation data: 0.0005854316228600917\n",
            "MAE on evaluation data: 0.0004658276902624087\n",
            "Train and validation from state  VIC  fold  1\n",
            "Weights and biases initialization for state  VIC  in progress...\n",
            "Epochs 0\n",
            "Cost on training data: 735.9354865781078\n",
            "MAPE on training data: 3968.323608005969\n",
            "RMSE on training data: 0.24731145983222383\n",
            "MAE on training data: 0.16737911147932166\n",
            "Cost on evaluation data: 185.62717570514607\n",
            "MAPE on evaluation data: 3974.520295528344\n",
            "RMSE on evaluation data: 0.2473171789663167\n",
            "MAE on evaluation data: 0.16737476318323952\n",
            "Epochs 100\n",
            "Cost on training data: 0.7579533776927645\n",
            "MAPE on training data: 47.448534398775436\n",
            "RMSE on training data: 0.002407122301717259\n",
            "MAE on training data: 0.0019973182852399277\n",
            "Cost on evaluation data: 0.7048666659001084\n",
            "MAPE on evaluation data: 47.81465411941981\n",
            "RMSE on evaluation data: 0.00242422911162517\n",
            "MAE on evaluation data: 0.002013322694460299\n",
            "Epochs 200\n",
            "Cost on training data: 0.17583896500627033\n",
            "MAPE on training data: 39.63875934190046\n",
            "RMSE on training data: 0.0020434695079412334\n",
            "MAE on training data: 0.001687563059362409\n",
            "Cost on evaluation data: 0.13772686986701685\n",
            "MAPE on evaluation data: 40.01918871565194\n",
            "RMSE on evaluation data: 0.00206635211663083\n",
            "MAE on evaluation data: 0.0017064283078296772\n",
            "Epochs 300\n",
            "Cost on training data: 0.03482711257406424\n",
            "MAPE on training data: 28.539218176572284\n",
            "RMSE on training data: 0.001520137428240454\n",
            "MAE on training data: 0.001206067879320777\n",
            "Cost on evaluation data: 0.013776157723753334\n",
            "MAPE on evaluation data: 28.81649697525291\n",
            "RMSE on evaluation data: 0.001542487294879785\n",
            "MAE on evaluation data: 0.001219716324323111\n",
            "Epochs 400\n",
            "Cost on training data: 0.010707874201695002\n",
            "MAPE on training data: 17.25133309220734\n",
            "RMSE on training data: 0.000934728741274715\n",
            "MAE on training data: 0.0007224012614617907\n",
            "Cost on evaluation data: 0.002875637650658971\n",
            "MAPE on evaluation data: 17.38372085008181\n",
            "RMSE on evaluation data: 0.000953083157966078\n",
            "MAE on evaluation data: 0.0007304757528090062\n",
            "Epochs 500\n",
            "Cost on training data: 0.00674903933863501\n",
            "MAPE on training data: 14.171056702197454\n",
            "RMSE on training data: 0.000729721589479255\n",
            "MAE on training data: 0.0005938380505122284\n",
            "Cost on evaluation data: 0.00179138903855673\n",
            "MAPE on evaluation data: 14.254110986754096\n",
            "RMSE on evaluation data: 0.0007554645635867778\n",
            "MAE on evaluation data: 0.0006006490754654544\n",
            "Epochs 600\n",
            "Cost on training data: 0.006749039338908195\n",
            "MAPE on training data: 14.171056703503012\n",
            "RMSE on training data: 0.0007297215894887049\n",
            "MAE on training data: 0.0005938380505833525\n",
            "Cost on evaluation data: 0.001791389038655587\n",
            "MAPE on evaluation data: 14.2541109880121\n",
            "RMSE on evaluation data: 0.0007554645636013086\n",
            "MAE on evaluation data: 0.0006006490755340665\n",
            "Epochs 700\n",
            "Cost on training data: 0.0067490393391814035\n",
            "MAPE on training data: 14.17105670480859\n",
            "RMSE on training data: 0.0007297215894981551\n",
            "MAE on training data: 0.0005938380506544773\n",
            "Cost on evaluation data: 0.0017913890387544497\n",
            "MAPE on evaluation data: 14.25411098927007\n",
            "RMSE on evaluation data: 0.000755464563615839\n",
            "MAE on evaluation data: 0.0006006490756026772\n",
            "Epochs 800\n",
            "Cost on training data: 0.006749039339454642\n",
            "MAPE on training data: 14.171056706114157\n",
            "RMSE on training data: 0.0007297215895076059\n",
            "MAE on training data: 0.0005938380507256022\n",
            "Cost on evaluation data: 0.0017913890388533392\n",
            "MAPE on evaluation data: 14.25411099052808\n",
            "RMSE on evaluation data: 0.0007554645636303707\n",
            "MAE on evaluation data: 0.00060064907567129\n",
            "Epochs 900\n",
            "Cost on training data: 0.006749039339727896\n",
            "MAPE on training data: 14.171056707419725\n",
            "RMSE on training data: 0.0007297215895170566\n",
            "MAE on training data: 0.000593838050796727\n",
            "Cost on evaluation data: 0.0017913890389522399\n",
            "MAPE on evaluation data: 14.254110991785982\n",
            "RMSE on evaluation data: 0.0007554645636448998\n",
            "MAE on evaluation data: 0.0006006490757398985\n",
            "Epochs 1000\n",
            "Cost on training data: 0.0067490393400011445\n",
            "MAPE on training data: 14.171056708725288\n",
            "RMSE on training data: 0.0007297215895265074\n",
            "MAE on training data: 0.0005938380508678523\n",
            "Cost on evaluation data: 0.0017913890390511527\n",
            "MAPE on evaluation data: 14.25411099304397\n",
            "RMSE on evaluation data: 0.0007554645636594306\n",
            "MAE on evaluation data: 0.0006006490758085106\n",
            "Epochs 1100\n",
            "Cost on training data: 0.006749039340274434\n",
            "MAPE on training data: 14.171056710030813\n",
            "RMSE on training data: 0.0007297215895359576\n",
            "MAE on training data: 0.0005938380509389765\n",
            "Cost on evaluation data: 0.0017913890391500912\n",
            "MAPE on evaluation data: 14.254110994301977\n",
            "RMSE on evaluation data: 0.0007554645636739637\n",
            "MAE on evaluation data: 0.0006006490758771242\n",
            "Epochs 1200\n",
            "Cost on training data: 0.006749039340547747\n",
            "MAPE on training data: 14.171056711336375\n",
            "RMSE on training data: 0.0007297215895454086\n",
            "MAE on training data: 0.0005938380510101019\n",
            "Cost on evaluation data: 0.0017913890392490478\n",
            "MAPE on evaluation data: 14.254110995559907\n",
            "RMSE on evaluation data: 0.0007554645636884941\n",
            "MAE on evaluation data: 0.0006006490759457348\n",
            "Epochs 1300\n",
            "Cost on training data: 0.006749039340821069\n",
            "MAPE on training data: 14.171056712641922\n",
            "RMSE on training data: 0.0007297215895548605\n",
            "MAE on training data: 0.0005938380510812272\n",
            "Cost on evaluation data: 0.0017913890393480225\n",
            "MAPE on evaluation data: 14.254110996817904\n",
            "RMSE on evaluation data: 0.0007554645637030257\n",
            "MAE on evaluation data: 0.0006006490760143483\n",
            "Epochs 1400\n",
            "Cost on training data: 0.006749039341094405\n",
            "MAPE on training data: 14.171056713947458\n",
            "RMSE on training data: 0.0007297215895643122\n",
            "MAE on training data: 0.0005938380511523524\n",
            "Cost on evaluation data: 0.0017913890394470053\n",
            "MAPE on evaluation data: 14.254110998075802\n",
            "RMSE on evaluation data: 0.0007554645637175561\n",
            "MAE on evaluation data: 0.0006006490760829579\n",
            "Train and validation from state  VIC  fold  2\n",
            "Epochs 0\n",
            "Cost on training data: 744.8430566670447\n",
            "MAPE on training data: 3998.288534790375\n",
            "RMSE on training data: 0.2490581431952182\n",
            "MAE on training data: 0.16859118700424314\n",
            "Cost on evaluation data: 188.21450217033666\n",
            "MAPE on evaluation data: 3995.96764359598\n",
            "RMSE on evaluation data: 0.2490499429193013\n",
            "MAE on evaluation data: 0.1685926535488896\n",
            "Epochs 100\n",
            "Cost on training data: 0.7761311502460637\n",
            "MAPE on training data: 47.935065445510446\n",
            "RMSE on training data: 0.0024336789403963817\n",
            "MAE on training data: 0.0020174358084831517\n",
            "Cost on evaluation data: 0.7217958189510968\n",
            "MAPE on evaluation data: 47.81120060976256\n",
            "RMSE on evaluation data: 0.0024163681287477303\n",
            "MAE on evaluation data: 0.002011007041238583\n",
            "Epochs 200\n",
            "Cost on training data: 0.19002796766999372\n",
            "MAPE on training data: 41.53187813173393\n",
            "RMSE on training data: 0.002127814733966136\n",
            "MAE on training data: 0.0017685355434690273\n",
            "Cost on evaluation data: 0.14872038463917375\n",
            "MAPE on evaluation data: 41.28337927700702\n",
            "RMSE on evaluation data: 0.0021092342331077876\n",
            "MAE on evaluation data: 0.0017547369738987442\n",
            "Epochs 300\n",
            "Cost on training data: 0.03844964997293823\n",
            "MAPE on training data: 29.842726514183443\n",
            "RMSE on training data: 0.0015900036247203386\n",
            "MAE on training data: 0.0012606117809664235\n",
            "Cost on evaluation data: 0.015270082216589868\n",
            "MAPE on evaluation data: 29.420681824221372\n",
            "RMSE on evaluation data: 0.001571160048349748\n",
            "MAE on evaluation data: 0.001242009605563343\n",
            "Epochs 400\n",
            "Cost on training data: 0.012523812563551708\n",
            "MAPE on training data: 18.598896591794897\n",
            "RMSE on training data: 0.0010089190713220893\n",
            "MAE on training data: 0.0007802466226534894\n",
            "Cost on evaluation data: 0.003140627710527514\n",
            "MAPE on evaluation data: 18.08470436084389\n",
            "RMSE on evaluation data: 0.0009870151361763002\n",
            "MAE on evaluation data: 0.0007583437127040824\n",
            "Epochs 500\n",
            "Cost on training data: 0.0069363752401786485\n",
            "MAPE on training data: 14.33650619321962\n",
            "RMSE on training data: 0.0007400884751390583\n",
            "MAE on training data: 0.000600296096804585\n",
            "Cost on evaluation data: 0.001598879433665513\n",
            "MAPE on evaluation data: 13.736892344134812\n",
            "RMSE on evaluation data: 0.0007097556663760844\n",
            "MAE on evaluation data: 0.0005745521538052527\n",
            "Epochs 600\n",
            "Cost on training data: 0.006936375243575366\n",
            "MAPE on training data: 14.336506192655172\n",
            "RMSE on training data: 0.0007400884752279196\n",
            "MAE on training data: 0.0006002960968329943\n",
            "Cost on evaluation data: 0.0015988794344987272\n",
            "MAPE on evaluation data: 13.736892341319596\n",
            "RMSE on evaluation data: 0.0007097556664410553\n",
            "MAE on evaluation data: 0.0005745521537312856\n",
            "Epochs 700\n",
            "Cost on training data: 0.006936375246972139\n",
            "MAPE on training data: 14.33650619209076\n",
            "RMSE on training data: 0.0007400884753167833\n",
            "MAE on training data: 0.000600296096861406\n",
            "Cost on evaluation data: 0.0015988794353319778\n",
            "MAPE on evaluation data: 13.736892338504456\n",
            "RMSE on evaluation data: 0.0007097556665060312\n",
            "MAE on evaluation data: 0.0005745521536573227\n",
            "Epochs 800\n",
            "Cost on training data: 0.006936386176624535\n",
            "MAPE on training data: 14.336492435117313\n",
            "RMSE on training data: 0.0007400884183548348\n",
            "MAE on training data: 0.0006002958492093194\n",
            "Cost on evaluation data: 0.001598882086416971\n",
            "MAPE on evaluation data: 13.736880372225869\n",
            "RMSE on evaluation data: 0.0007097555290533591\n",
            "MAE on evaluation data: 0.0005745519627737077\n",
            "Epochs 900\n",
            "Cost on training data: 0.006936386180014449\n",
            "MAPE on training data: 14.33649243457214\n",
            "RMSE on training data: 0.000740088418443705\n",
            "MAE on training data: 0.0006002958492381888\n",
            "Cost on evaluation data: 0.0015988820872486714\n",
            "MAPE on evaluation data: 13.736880369424945\n",
            "RMSE on evaluation data: 0.0007097555291181223\n",
            "MAE on evaluation data: 0.000574551962699995\n",
            "Epochs 1000\n",
            "Cost on training data: 0.006936386183404407\n",
            "MAPE on training data: 14.336492434026946\n",
            "RMSE on training data: 0.0007400884185325768\n",
            "MAE on training data: 0.0006002958492670585\n",
            "Cost on evaluation data: 0.001598882088080405\n",
            "MAPE on evaluation data: 13.736880366624026\n",
            "RMSE on evaluation data: 0.0007097555291828876\n",
            "MAE on evaluation data: 0.0005745519626262831\n",
            "Epochs 1100\n",
            "Cost on training data: 0.006936386186794391\n",
            "MAPE on training data: 14.336492433481721\n",
            "RMSE on training data: 0.0007400884186214485\n",
            "MAE on training data: 0.0006002958492959279\n",
            "Cost on evaluation data: 0.0015988820889121617\n",
            "MAPE on evaluation data: 13.736880363823031\n",
            "RMSE on evaluation data: 0.0007097555292476498\n",
            "MAE on evaluation data: 0.0005745519625525692\n",
            "Epochs 1200\n",
            "Cost on training data: 0.006936386190184419\n",
            "MAPE on training data: 14.33649243293651\n",
            "RMSE on training data: 0.0007400884187103207\n",
            "MAE on training data: 0.0006002958493247985\n",
            "Cost on evaluation data: 0.0015988820897439465\n",
            "MAPE on evaluation data: 13.736880361022022\n",
            "RMSE on evaluation data: 0.0007097555293124137\n",
            "MAE on evaluation data: 0.0005745519624788552\n",
            "Epochs 1300\n",
            "Cost on training data: 0.006936386193574473\n",
            "MAPE on training data: 14.336492432391227\n",
            "RMSE on training data: 0.0007400884187991921\n",
            "MAE on training data: 0.0006002958493536672\n",
            "Cost on evaluation data: 0.0015988820905757741\n",
            "MAPE on evaluation data: 13.736880358220995\n",
            "RMSE on evaluation data: 0.0007097555293771781\n",
            "MAE on evaluation data: 0.0005745519624051418\n",
            "Epochs 1400\n",
            "Cost on training data: 0.006936386196964584\n",
            "MAPE on training data: 14.336492431845944\n",
            "RMSE on training data: 0.0007400884188880656\n",
            "MAE on training data: 0.0006002958493825368\n",
            "Cost on evaluation data: 0.001598882091407624\n",
            "MAPE on evaluation data: 13.736880355419935\n",
            "RMSE on evaluation data: 0.0007097555294419424\n",
            "MAE on evaluation data: 0.0005745519623314276\n",
            "Train and validation from state  VIC  fold  3\n",
            "Epochs 0\n",
            "Cost on training data: 743.3415921045171\n",
            "MAPE on training data: 3994.4122377588014\n",
            "RMSE on training data: 0.24905501197705304\n",
            "MAE on training data: 0.16858884906349342\n",
            "Cost on evaluation data: 188.21140176929097\n",
            "MAPE on evaluation data: 4011.918386641666\n",
            "RMSE on evaluation data: 0.24905236494010405\n",
            "MAE on evaluation data: 0.16859181697266915\n",
            "Epochs 100\n",
            "Cost on training data: 0.7740660672392166\n",
            "MAPE on training data: 47.91957225656506\n",
            "RMSE on training data: 0.0024330317259831065\n",
            "MAE on training data: 0.0020187199451611195\n",
            "Cost on evaluation data: 0.7200938008007023\n",
            "MAPE on evaluation data: 48.09858743340373\n",
            "RMSE on evaluation data: 0.0024259337277385065\n",
            "MAE on evaluation data: 0.0020154084124813024\n",
            "Epochs 200\n",
            "Cost on training data: 0.18848740774382403\n",
            "MAPE on training data: 41.41141615683506\n",
            "RMSE on training data: 0.002122554005632484\n",
            "MAE on training data: 0.0017643247471725162\n",
            "Cost on evaluation data: 0.14754759988661506\n",
            "MAPE on evaluation data: 41.291976705470205\n",
            "RMSE on evaluation data: 0.0021085546822487214\n",
            "MAE on evaluation data: 0.001749789870918702\n",
            "Epochs 300\n",
            "Cost on training data: 0.03777445807643083\n",
            "MAPE on training data: 29.618670988907613\n",
            "RMSE on training data: 0.0015778147083152561\n",
            "MAE on training data: 0.0012529742611072012\n",
            "Cost on evaluation data: 0.015061046416459216\n",
            "MAPE on evaluation data: 29.513169615113316\n",
            "RMSE on evaluation data: 0.0015648075105887333\n",
            "MAE on evaluation data: 0.0012410192203491021\n",
            "Epochs 400\n",
            "Cost on training data: 0.012405376829450905\n",
            "MAPE on training data: 18.417216658229368\n",
            "RMSE on training data: 0.001005863003201595\n",
            "MAE on training data: 0.0007746972343935405\n",
            "Cost on evaluation data: 0.003157868060308107\n",
            "MAPE on evaluation data: 18.355640025109984\n",
            "RMSE on evaluation data: 0.000990929650584808\n",
            "MAE on evaluation data: 0.0007655721021863516\n",
            "Epochs 500\n",
            "Cost on training data: 0.006854000615104996\n",
            "MAPE on training data: 14.191438696994506\n",
            "RMSE on training data: 0.000737205574575751\n",
            "MAE on training data: 0.0005962826165471167\n",
            "Cost on evaluation data: 0.0016334027642510075\n",
            "MAPE on evaluation data: 14.131026182984893\n",
            "RMSE on evaluation data: 0.0007167545543986054\n",
            "MAE on evaluation data: 0.0005869455842063565\n",
            "Epochs 600\n",
            "Cost on training data: 0.006854000617965702\n",
            "MAPE on training data: 14.191438690660297\n",
            "RMSE on training data: 0.000737205574661603\n",
            "MAE on training data: 0.000596282616523065\n",
            "Cost on evaluation data: 0.001633402764736456\n",
            "MAPE on evaluation data: 14.131026176526406\n",
            "RMSE on evaluation data: 0.0007167545544729718\n",
            "MAE on evaluation data: 0.0005869455841704572\n",
            "Epochs 700\n",
            "Cost on training data: 0.006854000620826363\n",
            "MAPE on training data: 14.191438684326007\n",
            "RMSE on training data: 0.0007372055747474556\n",
            "MAE on training data: 0.0005962826164990127\n",
            "Cost on evaluation data: 0.001633402765221907\n",
            "MAPE on evaluation data: 14.131026170067932\n",
            "RMSE on evaluation data: 0.0007167545545473398\n",
            "MAE on evaluation data: 0.0005869455841345613\n",
            "Epochs 800\n",
            "Cost on training data: 0.006854000623687051\n",
            "MAPE on training data: 14.191438677991686\n",
            "RMSE on training data: 0.0007372055748333079\n",
            "MAE on training data: 0.0005962826164749596\n",
            "Cost on evaluation data: 0.0016334027657073733\n",
            "MAPE on evaluation data: 14.13102616360941\n",
            "RMSE on evaluation data: 0.0007167545546217064\n",
            "MAE on evaluation data: 0.0005869455840986636\n",
            "Epochs 900\n",
            "Cost on training data: 0.006854001394072622\n",
            "MAPE on training data: 14.191436470071503\n",
            "RMSE on training data: 0.0007372055913166234\n",
            "MAE on training data: 0.0005962826243314534\n",
            "Cost on evaluation data: 0.0016334028647258512\n",
            "MAPE on evaluation data: 14.131023899273092\n",
            "RMSE on evaluation data: 0.000716754566486115\n",
            "MAE on evaluation data: 0.0005869455892954963\n",
            "Epochs 1000\n",
            "Cost on training data: 0.006853999579423716\n",
            "MAPE on training data: 14.19142033026538\n",
            "RMSE on training data: 0.0007372055698457098\n",
            "MAE on training data: 0.0005962823719445918\n",
            "Cost on evaluation data: 0.0016334019330723664\n",
            "MAPE on evaluation data: 14.131006103413302\n",
            "RMSE on evaluation data: 0.0007167545166194747\n",
            "MAE on evaluation data: 0.0005869452453026019\n",
            "Epochs 1100\n",
            "Cost on training data: 0.006853999582270866\n",
            "MAPE on training data: 14.19142032393959\n",
            "RMSE on training data: 0.0007372055699313203\n",
            "MAE on training data: 0.0005962823719201675\n",
            "Cost on evaluation data: 0.0016334019335551369\n",
            "MAPE on evaluation data: 14.13100609696765\n",
            "RMSE on evaluation data: 0.0007167545166938616\n",
            "MAE on evaluation data: 0.0005869452452665012\n",
            "Epochs 1200\n",
            "Cost on training data: 0.006853999585118036\n",
            "MAPE on training data: 14.191420317613762\n",
            "RMSE on training data: 0.0007372055700169285\n",
            "MAE on training data: 0.000596282371895742\n",
            "Cost on evaluation data: 0.0016334019340379289\n",
            "MAPE on evaluation data: 14.131006090521984\n",
            "RMSE on evaluation data: 0.0007167545167682487\n",
            "MAE on evaluation data: 0.0005869452452304005\n",
            "Epochs 1300\n",
            "Cost on training data: 0.006853999587965225\n",
            "MAPE on training data: 14.191420311287956\n",
            "RMSE on training data: 0.0007372055701025395\n",
            "MAE on training data: 0.0005962823718713184\n",
            "Cost on evaluation data: 0.0016334019345207308\n",
            "MAPE on evaluation data: 14.131006084076308\n",
            "RMSE on evaluation data: 0.0007167545168426368\n",
            "MAE on evaluation data: 0.0005869452451943\n",
            "Epochs 1400\n",
            "Cost on training data: 0.00685399959081242\n",
            "MAPE on training data: 14.191420304962108\n",
            "RMSE on training data: 0.0007372055701881496\n",
            "MAE on training data: 0.0005962823718468933\n",
            "Cost on evaluation data: 0.0016334019350035403\n",
            "MAPE on evaluation data: 14.131006077630555\n",
            "RMSE on evaluation data: 0.0007167545169170211\n",
            "MAE on evaluation data: 0.0005869452451581967\n",
            "Train and validation from state  VIC  fold  4\n",
            "Epochs 0\n",
            "Cost on training data: 741.8334141184343\n",
            "MAPE on training data: 4003.3868430503426\n",
            "RMSE on training data: 0.2490508327584364\n",
            "MAE on training data: 0.16858664625154465\n",
            "Cost on evaluation data: 188.21861005164618\n",
            "MAPE on evaluation data: 3976.0209081257954\n",
            "RMSE on evaluation data: 0.24906069083427612\n",
            "MAE on evaluation data: 0.1685894634436274\n",
            "Epochs 100\n",
            "Cost on training data: 0.7720551552172887\n",
            "MAPE on training data: 48.030192835417004\n",
            "RMSE on training data: 0.002432497030128193\n",
            "MAE on training data: 0.0020189037470126365\n",
            "Cost on evaluation data: 0.718271659259907\n",
            "MAPE on evaluation data: 47.55862356955154\n",
            "RMSE on evaluation data: 0.0024320339761447385\n",
            "MAE on evaluation data: 0.0020129693501106773\n",
            "Epochs 200\n",
            "Cost on training data: 0.18735754231712354\n",
            "MAPE on training data: 41.48604865224425\n",
            "RMSE on training data: 0.0021238699720453687\n",
            "MAE on training data: 0.0017635344025136034\n",
            "Cost on evaluation data: 0.14658585032525792\n",
            "MAPE on evaluation data: 41.29660021539436\n",
            "RMSE on evaluation data: 0.0021268905629188736\n",
            "MAE on evaluation data: 0.0017670055272591796\n",
            "Epochs 300\n",
            "Cost on training data: 0.03720639229559462\n",
            "MAPE on training data: 29.54966188081395\n",
            "RMSE on training data: 0.001568226415716574\n",
            "MAE on training data: 0.001245488626886027\n",
            "Cost on evaluation data: 0.01496805361085584\n",
            "MAPE on evaluation data: 29.459201980394255\n",
            "RMSE on evaluation data: 0.0015709997786940916\n",
            "MAE on evaluation data: 0.001250846092739193\n",
            "Epochs 400\n",
            "Cost on training data: 0.011973786292255347\n",
            "MAPE on training data: 18.251312707597446\n",
            "RMSE on training data: 0.000989663696319281\n",
            "MAE on training data: 0.0007635726350015183\n",
            "Cost on evaluation data: 0.0031765922469726426\n",
            "MAPE on evaluation data: 18.189614638359163\n",
            "RMSE on evaluation data: 0.0009920464611108469\n",
            "MAE on evaluation data: 0.0007688180144373107\n",
            "Epochs 500\n",
            "Cost on training data: 0.006763206909877336\n",
            "MAPE on training data: 14.22070646017569\n",
            "RMSE on training data: 0.0007325505237386543\n",
            "MAE on training data: 0.0005933013293523052\n",
            "Cost on evaluation data: 0.0017290571202835158\n",
            "MAPE on evaluation data: 14.171616419982897\n",
            "RMSE on evaluation data: 0.0007367843627259868\n",
            "MAE on evaluation data: 0.0005992391612748504\n",
            "Epochs 600\n",
            "Cost on training data: 0.006763206915265272\n",
            "MAPE on training data: 14.220706452503308\n",
            "RMSE on training data: 0.0007325505239129675\n",
            "MAE on training data: 0.0005933013293184767\n",
            "Cost on evaluation data: 0.0017290571219816598\n",
            "MAPE on evaluation data: 14.171616415175613\n",
            "RMSE on evaluation data: 0.0007367843629369599\n",
            "MAE on evaluation data: 0.0005992391613657321\n",
            "Epochs 700\n",
            "Cost on training data: 0.006763206920653276\n",
            "MAPE on training data: 14.220706444830963\n",
            "RMSE on training data: 0.0007325505240872834\n",
            "MAE on training data: 0.0005933013292846502\n",
            "Cost on evaluation data: 0.0017290571236798155\n",
            "MAPE on evaluation data: 14.171616410368145\n",
            "RMSE on evaluation data: 0.0007367843631479302\n",
            "MAE on evaluation data: 0.0005992391614566073\n",
            "Epochs 800\n",
            "Cost on training data: 0.006763206926041291\n",
            "MAPE on training data: 14.220706437158587\n",
            "RMSE on training data: 0.0007325505242615986\n",
            "MAE on training data: 0.0005933013292508226\n",
            "Cost on evaluation data: 0.0017290571253779944\n",
            "MAPE on evaluation data: 14.17161640556074\n",
            "RMSE on evaluation data: 0.0007367843633589015\n",
            "MAE on evaluation data: 0.0005992391615474853\n",
            "Epochs 900\n",
            "Cost on training data: 0.0067632091470552335\n",
            "MAPE on training data: 14.22071199839503\n",
            "RMSE on training data: 0.0007325505492846548\n",
            "MAE on training data: 0.000593301300734017\n",
            "Cost on evaluation data: 0.001729057411171901\n",
            "MAPE on evaluation data: 14.17162012381634\n",
            "RMSE on evaluation data: 0.0007367842674043649\n",
            "MAE on evaluation data: 0.0005992390483899171\n",
            "Epochs 1000\n",
            "Cost on training data: 0.006763209152447727\n",
            "MAPE on training data: 14.220711990708537\n",
            "RMSE on training data: 0.0007325505494590062\n",
            "MAE on training data: 0.0005933013007001426\n",
            "Cost on evaluation data: 0.0017290574128718907\n",
            "MAPE on evaluation data: 14.17162011899467\n",
            "RMSE on evaluation data: 0.0007367842676155276\n",
            "MAE on evaluation data: 0.0005992390484807392\n",
            "Epochs 1100\n",
            "Cost on training data: 0.006763217640568157\n",
            "MAPE on training data: 14.22072355753006\n",
            "RMSE on training data: 0.0007325505671363093\n",
            "MAE on training data: 0.0005933014536803293\n",
            "Cost on evaluation data: 0.0017290590197704928\n",
            "MAPE on evaluation data: 14.171628601179536\n",
            "RMSE on evaluation data: 0.0007367842823981743\n",
            "MAE on evaluation data: 0.0005992390729070109\n",
            "Epochs 1200\n",
            "Cost on training data: 0.0067632176459666606\n",
            "MAPE on training data: 14.220723549803319\n",
            "RMSE on training data: 0.0007325505673112697\n",
            "MAE on training data: 0.0005933014536460762\n",
            "Cost on evaluation data: 0.0017290590214737494\n",
            "MAPE on evaluation data: 14.17162859633164\n",
            "RMSE on evaluation data: 0.0007367842826100495\n",
            "MAE on evaluation data: 0.0005992390729980478\n",
            "Epochs 1300\n",
            "Cost on training data: 0.006763217651365195\n",
            "MAPE on training data: 14.220723542076556\n",
            "RMSE on training data: 0.0007325505674862311\n",
            "MAE on training data: 0.0005933014536118231\n",
            "Cost on evaluation data: 0.0017290590231770308\n",
            "MAPE on evaluation data: 14.171628591483776\n",
            "RMSE on evaluation data: 0.0007367842828219248\n",
            "MAE on evaluation data: 0.0005992390730890865\n",
            "Epochs 1400\n",
            "Cost on training data: 0.0067632176567637425\n",
            "MAPE on training data: 14.220723534349744\n",
            "RMSE on training data: 0.0007325505676611916\n",
            "MAE on training data: 0.0005933014535775684\n",
            "Cost on evaluation data: 0.0017290590248803322\n",
            "MAPE on evaluation data: 14.171628586635826\n",
            "RMSE on evaluation data: 0.0007367842830337983\n",
            "MAE on evaluation data: 0.0005992390731801216\n",
            "Train and validation from state  VIC  fold  5\n",
            "Epochs 0\n",
            "Cost on training data: 740.341885874264\n",
            "MAPE on training data: 3997.7347335962\n",
            "RMSE on training data: 0.2490509429552578\n",
            "MAE on training data: 0.16858614023987756\n",
            "Cost on evaluation data: 188.20039095467126\n",
            "MAPE on evaluation data: 4004.2145053199065\n",
            "RMSE on evaluation data: 0.24904500640696456\n",
            "MAE on evaluation data: 0.16858205263184436\n",
            "Epochs 100\n",
            "Cost on training data: 0.7703204754110503\n",
            "MAPE on training data: 48.09066547517269\n",
            "RMSE on training data: 0.0024370151267046327\n",
            "MAE on training data: 0.0020238845369456\n",
            "Cost on evaluation data: 0.71662773456206\n",
            "MAPE on evaluation data: 48.23766840745614\n",
            "RMSE on evaluation data: 0.0024492127733794023\n",
            "MAE on evaluation data: 0.0020277269878747474\n",
            "Epochs 200\n",
            "Cost on training data: 0.18597256053218106\n",
            "MAPE on training data: 41.42642939753139\n",
            "RMSE on training data: 0.0021209467665681842\n",
            "MAE on training data: 0.0017624200116619344\n",
            "Cost on evaluation data: 0.14549734947014398\n",
            "MAPE on evaluation data: 41.6675988180615\n",
            "RMSE on evaluation data: 0.0021315972166664854\n",
            "MAE on evaluation data: 0.0017718189572339745\n",
            "Epochs 300\n",
            "Cost on training data: 0.03690069441365432\n",
            "MAPE on training data: 29.416160060025582\n",
            "RMSE on training data: 0.0015657311941131553\n",
            "MAE on training data: 0.0012419060858287947\n",
            "Cost on evaluation data: 0.014901106773070437\n",
            "MAPE on evaluation data: 29.787472867546246\n",
            "RMSE on evaluation data: 0.0015776273587992788\n",
            "MAE on evaluation data: 0.0012558637476609417\n",
            "Epochs 400\n",
            "Cost on training data: 0.011366831359653037\n",
            "MAPE on training data: 17.784787682048293\n",
            "RMSE on training data: 0.000966357482762945\n",
            "MAE on training data: 0.0007462124108008912\n",
            "Cost on evaluation data: 0.0031172813395785952\n",
            "MAPE on evaluation data: 18.39055254890061\n",
            "RMSE on evaluation data: 0.0009860880984890344\n",
            "MAE on evaluation data: 0.0007692399939036377\n",
            "Epochs 500\n",
            "Cost on training data: 0.006619630798982352\n",
            "MAPE on training data: 14.028404632203827\n",
            "RMSE on training data: 0.0007255571738223864\n",
            "MAE on training data: 0.0005875757046321747\n",
            "Cost on evaluation data: 0.0017956079451737395\n",
            "MAPE on evaluation data: 14.76293557235802\n",
            "RMSE on evaluation data: 0.0007540042341252637\n",
            "MAE on evaluation data: 0.0006158532257561174\n",
            "Epochs 600\n",
            "Cost on training data: 0.006619630804194104\n",
            "MAPE on training data: 14.028404619623863\n",
            "RMSE on training data: 0.0007255571740320661\n",
            "MAE on training data: 0.0005875757046083455\n",
            "Cost on evaluation data: 0.001795607946572043\n",
            "MAPE on evaluation data: 14.762935558586454\n",
            "RMSE on evaluation data: 0.00075400423432769\n",
            "MAE on evaluation data: 0.0006158532257061465\n",
            "Epochs 700\n",
            "Cost on training data: 0.006619630809405906\n",
            "MAPE on training data: 14.028404607043862\n",
            "RMSE on training data: 0.0007255571742417469\n",
            "MAE on training data: 0.0005875757045845153\n",
            "Cost on evaluation data: 0.0017956079479703752\n",
            "MAPE on evaluation data: 14.762935544814903\n",
            "RMSE on evaluation data: 0.0007540042345301169\n",
            "MAE on evaluation data: 0.0006158532256561762\n",
            "Epochs 800\n",
            "Cost on training data: 0.006619626603336216\n",
            "MAPE on training data: 14.028409050022411\n",
            "RMSE on training data: 0.0007255571498317422\n",
            "MAE on training data: 0.0005875757944136127\n",
            "Cost on evaluation data: 0.0017956068724097587\n",
            "MAPE on evaluation data: 14.762940055587388\n",
            "RMSE on evaluation data: 0.0007540042233471365\n",
            "MAE on evaluation data: 0.0006158533118649642\n",
            "Epochs 900\n",
            "Cost on training data: 0.0066196266085564205\n",
            "MAPE on training data: 14.02840903744664\n",
            "RMSE on training data: 0.0007255571500413327\n",
            "MAE on training data: 0.0005875757943895404\n",
            "Cost on evaluation data: 0.0017956068738101988\n",
            "MAPE on evaluation data: 14.76294004181884\n",
            "RMSE on evaluation data: 0.0007540042235494439\n",
            "MAE on evaluation data: 0.000615853311814699\n",
            "Epochs 1000\n",
            "Cost on training data: 0.006619626001469255\n",
            "MAPE on training data: 14.0284139032446\n",
            "RMSE on training data: 0.0007255571509200402\n",
            "MAE on training data: 0.0005875758549111302\n",
            "Cost on evaluation data: 0.001795606699118172\n",
            "MAPE on evaluation data: 14.762945054207597\n",
            "RMSE on evaluation data: 0.00075400420736976\n",
            "MAE on evaluation data: 0.000615853367821622\n",
            "Epochs 1100\n",
            "Cost on training data: 0.006619626006698559\n",
            "MAPE on training data: 14.028413890676713\n",
            "RMSE on training data: 0.0007255571511295076\n",
            "MAE on training data: 0.0005875758548867457\n",
            "Cost on evaluation data: 0.0017956067005208652\n",
            "MAPE on evaluation data: 14.762945040445267\n",
            "RMSE on evaluation data: 0.0007540042075719045\n",
            "MAE on evaluation data: 0.0006158533677709713\n",
            "Epochs 1200\n",
            "Cost on training data: 0.006619626011927897\n",
            "MAPE on training data: 14.028413878108804\n",
            "RMSE on training data: 0.0007255571513389743\n",
            "MAE on training data: 0.0005875758548623607\n",
            "Cost on evaluation data: 0.0017956067019235815\n",
            "MAPE on evaluation data: 14.762945026682988\n",
            "RMSE on evaluation data: 0.0007540042077740498\n",
            "MAE on evaluation data: 0.0006158533677203232\n",
            "Epochs 1300\n",
            "Cost on training data: 0.006619626017157285\n",
            "MAPE on training data: 14.028413865540873\n",
            "RMSE on training data: 0.0007255571515484416\n",
            "MAE on training data: 0.0005875758548379756\n",
            "Cost on evaluation data: 0.001795606703326331\n",
            "MAPE on evaluation data: 14.762945012920584\n",
            "RMSE on evaluation data: 0.0007540042079761923\n",
            "MAE on evaluation data: 0.0006158533676696705\n",
            "Epochs 1400\n",
            "Cost on training data: 0.006619610900086397\n",
            "MAPE on training data: 14.028427729236615\n",
            "RMSE on training data: 0.0007255570481732388\n",
            "MAE on training data: 0.0005875762104437132\n",
            "Cost on evaluation data: 0.0017956028516335825\n",
            "MAPE on evaluation data: 14.762959787994362\n",
            "RMSE on evaluation data: 0.0007540041717995122\n",
            "MAE on evaluation data: 0.0006158537425537355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uR8_q6Idzo5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import rc\n",
        "def plot():\n",
        "    state = {0: 'NSW', 1: 'QLD', 2: 'SA', 3: 'TAS', 4: 'VIC'}\n",
        "    for st in state.values():\n",
        "        fig = plt.figure()\n",
        "        ax = fig.add_subplot(111)\n",
        "        rc('font',**{'family':'serif','serif':['Times New Roman']})\n",
        "        ax.set_title(\"MAPE for state \"+ st)\n",
        "        \n",
        "        for fold in np.arange(1,6):\n",
        "                fname1 = \"results_\" + st + \"_5Fold_\" + str(fold) + \"CSO\"\n",
        "                _, e_mape1, e_rmse1, e_mae1, _, _, _, _ = json.load(open(fname1))\n",
        "                label = \"CSO Split \"+str(fold)\n",
        "                ax.plot(np.arange(0, 1500), [e for e in e_mape1], label=label )\n",
        "                ax.set_ylim([10,20])\n",
        "                ax.set_xlim([200,1500])\n",
        "                ax.set_xlabel('Epoch')\n",
        "                ax.set_ylabel('MAPE')\n",
        "                ax.grid(True)\n",
        "        plt.legend(loc=\"center\", bbox_to_anchor=(0.5, -0.4), ncol=3)\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N2kM92Pkz0bE",
        "colab_type": "code",
        "outputId": "2d9c7c20-85d9-4ca7-a92d-98672db9387c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2342
        }
      },
      "cell_type": "code",
      "source": [
        "plot()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAHRCAYAAACsO1ouAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQAwyC+Ot0K3fNywiwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAHRCAYAAACsO1ouAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAHRCAYAAACsO1ouAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4VOX9///XmZlMdtlMQATBjVUF\nLBQpfFjCXhKCQS22CsVW1EtARUGBD/3+RAG3QotVCkWKSzcRCIu4AbKoLFJRXNAPVRAokMQQQvZt\nzu+PgYFxkgCayeSePB/XxUXmnDPnvO/7HHjlPmfmHMu2bVsAAMAIjlAXAAAAzh/BDQCAQQhuAAAM\nQnADAGAQghsAAIMQ3AAAGITgBsLYN998o9TUVHXp0kUvvfRSqMsBUAMIbqCGJCUl6ZprrtHx48f9\npo8YMUJt27bV4cOH/aY/++yzatu2rT755BO/6StWrFD79u3VpUsXXX/99UpNTdW7774rSdqxY4fa\ntWunLl26+P3ZvXt3pTUtXrxY3bt31+7duzV69OgabK2/w4cPq23btiovLz/v9yQlJemDDz74wdvc\ntWuXRo0apZ/85Cf66U9/qlGjRmnPnj1+y+zYsUNt27bVokWLfvB2gLqG4AZq0KWXXqrXX3/d9/qr\nr75SUVFRwHK2bSs9PV0NGzZUenp6wPzOnTtr9+7d2rVrl2666Sbdf//9ys3NlSQlJiZq9+7dfn+6\ndOlSaT1HjhzR1Vdf/YPaciEhXNvy8/N1991367bbbtPOnTu1ZcsWjR8/Xm6322+50328atWqEFUK\n1DyCG6hBqampfkGcnp6uESNGBCy3a9cuZWVlafr06Vq3bp1KS0srXZ/D4dDIkSNVXFysgwcPXlAt\no0eP1o4dOzRz5kx16dJF+/fvV15enqZMmaIbbrhB/fr10/PPPy+PxyPJO9IfNWqUZs+ere7du+vZ\nZ58NWOeePXuUlpam66+/Xj/72c80Z84cSdJtt90mSerWrZvvDMDBgwc1evRode/eXd27d9eDDz6o\nkydPSpImT56sI0eO6O6771aXLl30l7/8RZL08ccfa9SoUeratauGDx+uHTt2VNq2/fv3S5KSk5Pl\ndDoVFRWlXr16qV27dr5lCgsL9eabb+p3v/udvv32W3366acX1H9AXUVwAzWoc+fOys/P19dff62K\nigq9/vrrGj58eMByK1euVL9+/TR06FBJ8p0K/77y8nItW7ZMMTExat269QXV8tJLL6lr16763e9+\np927d+vyyy/XY489pry8PK1fv14vv/yyVq1apeXLl/ves2fPHrVs2VLvv/++7rnnnoB1zpo1S6NH\nj9ZHH32kd955x1f/K6+8Ikn68MMPfWcAbNvWXXfdpa1bt+qNN97QsWPHfL8MPP3002revLn+/Oc/\na/fu3brzzjuVkZGhu+66S/fcc4927typhx9+WBMnTgy49CBJl19+uZxOpx5++GFt3rzZdzbibG+/\n/bZiY2M1ZMgQ9erVq9IzG4CJCG6ghp0edb///vu68sor1bRpU7/5RUVFevPNN5WSkqKIiAgNHjw4\nIFQ++eQTde3aVT179tTrr7+u5557TvHx8ZKkzMxMde3a1e9PYWHhOeuqqKjQunXr9OCDDyouLk4t\nWrTQ2LFjtXr1at8yiYmJuv322+VyuRQVFRWwDpfLpYMHD+r48eOKjY1V586dq9xeq1at1LNnT7nd\nbjVu3Fhjx47Vhx9+WOXyq1atUu/evdWnTx85HA717NlT11xzjTZv3hywbFxcnP7+97/LsizNmDFD\nPXr00N13363vvvvOt0x6erqGDh0qp9Op5ORkvf766yorKztnPwF1nSvUBQDhJjU1VbfddpsOHz6s\n1NTUgPnvvPOOXC6XevfuLUlKSUnR2LFjdfz4cTVu3FiS1KlTJ/3jH/+odP2JiYnasmXLBdeVk5Oj\nsrIyNW/e3DetefPmysjI8L1u1qxZteuYNWuW5s+fr6FDh6pFixYaP368+vXrV+my3333nWbNmqVd\nu3apoKBAtm3roosuqnLdR44c0Ztvvul39qG8vFzdu3evdPkrr7xSTzzxhCTp66+/1uTJkzV79mzN\nnTtXR48e1Y4dOzRp0iRJUv/+/TVjxgxt3rxZAwYMqLaNQF1HcAM17NJLL1WLFi20efNmzZo1K2B+\nenq6CgsLfYFn27bKysq0Zs0ajRkzJmh1NWrUSBERETpy5IiuuuoqSdLRo0f9zghYllXtOlq3bq25\nc+fK4/Ho7bff1sSJE7Vjx45K3zd37lxZlqU1a9aoYcOGWr9+vWbOnFnlui+55BKlpqbq8ccfv+C2\nXXnllUpLS9O//vUvSd7Ru8fj8TvdX1paqpUrVxLcMB6nyoEgmDVrll588UXFxMT4Tc/IyNC2bdv0\n5z//Wenp6UpPT9eqVat05513Bv2Tz06nU0OGDNG8efOUn5+v//73v/rrX/9a6TX4qqxatUrHjx+X\nw+HwjZ4dDocaN24sh8OhQ4cO+ZYtKChQTEyM4uPjlZGRocWLF/ut6+KLL/Zbfvjw4Xr33Xe1detW\nVVRUqKSkRDt27NCxY8cC6vj666+1ZMkS37yjR49q7dq16tSpkyTvZwjGjx/v6+P09HTNnz9fmzdv\nVk5Ozvl3GlAHEdxAEFx22WW69tprA6avWrVK7du3V69evZSQkOD7c/vtt+urr77S//3f/51z3ZmZ\nmQHf437rrbfOq64ZM2YoOjpaAwYM0C9/+UslJydr5MiR592urVu3atiwYerSpYtmzZqlefPmKSoq\nStHR0br77rt16623qmvXrvr44481fvx4ffHFF+ratavGjRunQYMG+a1r3LhxWrBggbp27aoXXnhB\nl1xyiZ5//nktXLhQPXr0UJ8+ffTCCy/4PvV+tri4OH3yySe6+eab1blzZ91yyy1q06aNHnnkEX38\n8cc6cuSIfvWrX/n1cf/+/dWqVSu/r+sBJrJs27ZDXQQAADg/jLgBADBI0D6cdvToUU2ZMkXZ2dmy\nLEu33HKLxowZoxMnTuiBBx7Qf//7X1166aX6wx/+oAYNGgSrDAAAwkrQTpVnZmYqKytLHTt2VH5+\nvkaOHKnnnntOK1asUMOGDTVu3DgtWrRIubm5mjx5cjBKAAAg7ATtVHliYqI6duwoyftBkiuuuEIZ\nGRnasGGD7xaQI0aM0Pr164NVAgAAYadWrnEfPnxYe/fuVadOnZSdna3ExERJUkJCgrKzs2ujBAAA\nwkLQb8BSUFCgiRMnatq0aYqLi/ObZ1nWOW/4IHlvUHE+y9VHb9xxm6Jyi9X3tWWyLEu2bevmaa+r\n+cWxmv9g5Xe0Kik6rs+2zvG97thziqJiE2qrZADAjxDU4C4rK9PEiROVkpLi+w5nkyZNlJmZqcTE\nRGVmZvpu8Vgdy7KUlZUXzFKNk5AQr6ysPOU3jtVF2UU6/Nn/KaqZ91aWiQ2j9d+sfGVmnqz0Fx7b\ndimm0XUqzPE+u/jIwc8Vf/FParX+mna6P3AGfRKIPvFHfwSqK32SkBBf5bygnSq3bVvTp0/XFVdc\nobFjx/qmJyUl+R6okJ6erv79+werhHqh6GLvzi04+l/ftOYXx6q0zKODGfmVvseyLF3ceoQuvvxm\n7wRP3X3uMgDAX9CC+9///rdWrVql7du3KzU1Vampqdq8ebPGjRun999/X4MGDdIHH3ygcePGBauE\n+iEqUpJUVlzgm/STNt7T3rv3ZWn/0ZMqrwi885QkWZZTkmTbFUEuEgBQU4J2qrxr16766quvKp33\n4osvBmuz9Y7DfTq4zzzWse1lDSVJq98/oNXvH/BNb9ooWg+N6qImDbyPa7Qc3t1v24y4AcAU3DnN\ncI5Ib3CXFxf5psXHuHVDx6YBy2bkFGnttgNnJlingptT5QBgDB7rabjTI+6zg1uSfpvcQSk/a63G\n8VH658Z92vzxEUlSTl6JbxlG3ABgHkbchouIipYUGNwOy9IlTWIV6XZqzJB2WvhQH0lSxVnXuy3f\niJtr3ABgCoLbcNEx3mcil5z14bTKRLicinA5VFB8ZnTNiBsAzENwGy421vtBtLKiwnMsKcVGuVR4\ndnCf/lQ517gBwBgEt+HiG3lvH2tl55xz2ZioCBWWnB3cjLgBwDQEt+HimzRVVkOX4g59J09xcbXL\nRkY4VVJ25nq271Q5I24AMAbBbbhIp1u58U45PLb+M/5uFXy2R1U9qTUywqGyco88p+afCe6yWqsX\nAPDjENyGczvcanLizIj5v3+Yq313jlVpRoaOLPiTSo8eObNshPeadlmZ95PlluWU5YyUp/zc18cB\nAHUDwW04p8OpD37SIGD6gekPK//fu3R08SLfNLfLu7vPPl3udMWporz6T6QDAOoOgjsMHGsVGNyn\nWc4zuzjy1Ii71C+4Y+UpL5RtV34/cwBA3UJwh4FIp7vKec6LzoT66VPlJeVnQtoRESvJ5nQ5ABiC\n4A4Dkc5IHW3qvfWp6+KL1ST1RjUff58kKaLJxb7l3BHe3V36vVPlklRRVvkjQAEAdQv3Kg8D0a5o\nLUtqoLm9H5M7whvgpz+UZped+cS423VqxF16VnBHxEoS17kBwBCMuMPAJXFNZVvS24c2KbMwS5Jk\nRURI8g/umCjv72ln34SFETcAmIXgDgMt4i6RJL1xYIMe3f60JMl2eUPac1ZwXxTjvRZ+srDUN80V\n5T2Vnpf5gQqOf1or9QIAfjhOlYeBS2Kb+b1O/886fXNsr5IllZac+dBZfKx3FJ5XcCa4I2NbSpLK\nirOU/e1KRUQnyh0d+CxvAEDdwIg7DLSKb+H3+p2Dm3Sg6Jgk6URBtm/66RH3mg++1VN//0jHTxbL\nsiy/91aUngxytQCAH4PgDgMRzgg90et3vtcdGrfVwMuTJEmFRXm+6U0bxSgm0qXyCo++PHhCe7/1\nPpikWbu7fcuUl+bWUtUAgB+CU+VhIt4dp3l9Zqm0olRxbu8nxfc6XpVVduaDaJFup+4e0VGL1+7V\nyYJSlVV4v8/tjk5U4lW3K/M/L6uinA+pAUBdxog7jLidEb7QlqSiWJfiTpbKrjjz9a9rLm+iMYPb\nSvL/Wpjl8J5Gtz1nrn8DAOoegjuMZV8Sr8hSj8oyM/ymR7oDv8/tOHX3NbuCJ4UBQF1GcIexsljv\nzVjKCvxPf58O7uKywBG3hxE3ANRpBHcYs6NO3UUtP89velREJSNuTpUDgBEI7nAWHSVJKsn3/4qX\nb8R99jXuU6fKPRUENwDUZXyqPIw5oqMlSSeXvqiTL76k2M5dVH78uCLadVRiiaXi0jMPILEsp2Q5\nGXEDQB1HcIexiFMPHJEk2bYKdn8kSSr59oDukLS67X1+yzscboIbAOo4TpWHMU+Hq6udH5d12O+1\n5XRzqhwA6jiCO4zFRsXpcGJElfObZ3zl95oRNwDUfQR3GIuNiNWaPg18ry/6WS+/+SedMX6vLYeb\nr4MBQB1HcIexi9zxKo1w6OCIG3TJPePV7I7fqs3ipbJOPfKzwPYfjTucbsmukO2pqGx1AIA6gOAO\nYwnRTSRJX18WrfifdPVNb/bbuyRJdnm53/Lc9hQA6j4+VR7G4iJiFRsRoz3ffa6Z25/WwMv6asex\nf6tLdpQukaSKMpWVexTh8v7+Zjm8I/CivK/lcESqvPSEZFmyK0pkOaNkVxSf+dsRKdsu836NTJJt\ne2RZLtmeUlnOSNkVxXI4o+SpKD71ukyWwynZtmzZsiynbE9ZFcuWynJEyLY9kt+ybtkVJWctG+Wt\nzREhT2GE8vNLZFmWbE+FLGdElcvadoUsWd622RWyrAjZnrrfRtuukGSddxvtwmjlF5T4tdF/2cra\neHrZYLbx+8tW1kaHbE/5+e/HavvD7WujXRSpvLzCGmxjmSyH60e08dz7/PzbWC7LcnxvP545rn3v\nOWuf24WRyssvOo82OmXbtpFtPP/96G2jpzBSBQVl53FcB6+NkpSQMLDK/9sJ7jBmWZb6XPozrTuw\nXhmFWXrly2WSpJLvSnSjJFdknnLyS5TYMPrU8t7DIfvAilCV/IPlhLqAOuhEqAuogzhO/NEfgerM\nv5uOVQc3p8rD3MBWfdX70h6KdkX5plU4LEmSy1ms47nFvukNmvWu9foAABeG4A5zbqdbv2h7o576\nn/9PvS69QZdf1Eo3tbtRkuRylCort8i3rCuyoSxnVFWrAgDUAZwqrycclkO3tk2TJB3/z159J8mp\ncn17LE//c92Z5Vpc+6Ak+a55miIhIV5ZWXnnXrAeoU8C0Sf+6I9AJvQJI+56yB3pvabtkkfvf3ZM\n+UVnnsFtWU7jQhsA6hOCux5yub33MI91WSoprdCsl3YpJ68kxFUBAM4HwV0POV3e72tHOqTYKJcy\ncoq066vMEFcFADgfBHc9ZEV4v69tlVfozpQOkqSikvLq3gIAqCMI7nrIGRMjjyW5C8sUG+UN8eJS\nbnMKACYguOshy+VScbRL0QVlior0frGA4AYAMxDc9VRRbIRiCssU5fLejKW4lFPlAGACgrueKolx\ny+mRIk89UKS4hBE3AJiA4K6nyqO917ZdJd47pzHiBgAzENz1VYT32vbBGVN1RWmmirjGDQBGILjr\nqdj8MyPsvlm7VMzXwQDACAR3PZVzXWvfzy55+FQ5ABiC4K6nStpfrtxY7+5vUHxCpSWlIa4IAHA+\nCO56KsYVrVeGNZGndQs5bY8cxUXyeOxQlwUAOIegBffUqVPVo0cPJScn+6bt3btXt9xyi1JTU5WW\nlqY9e/YEa/M4h2hXtMpdlsobxkmSnHYFp8sBwABBC+60tDQtXrzYb9rTTz+te++9V6tWrdJ9992n\np59+Olibxzk0i02QJGWV5UqSXHaFCorLqnsLAKAOCFpwd+vWTQ0aNPCbZlmWCgoKJEl5eXlKTEwM\n1uZxDi3jL5XDciir7IQkyWmXKzu3OMRVAQDOxVWbG5s2bZp+85vf6Mknn5TH49E///nP2tw8zhLt\nitav2t2k/R8tkSRFuIqVdaJI7Vo1CnFlAIDq1Gpw/+Mf/9DUqVM1ePBgrVu3TtOnT9fSpUvP670J\nCfHBLc5AP7ZPUhL6ac3bGyV9IaejRKveP6BtX2QoM6dIiY2i5XQGnpCxbT7ABgDB9uT4/6lyXq0G\n98qVKzV9+nRJ0tChQ/W///u/5/3erKy8YJVlpISE+BrpE8vhliRd3ixCWzKKlZtfouhIl778Nsd/\nuSpf1A2WJH6l8EefBKJP/NEfgUzok1oN7sTERO3cuVPdu3fX9u3b1bp169rcPCrhjoyWJF3TOkY3\njfofRbmdclUy0q7rauoXmXBCnwSiT/zRH4FM6JOgBfekSZO0c+dO5eTkqHfv3powYYIee+wxzZ49\nW+Xl5YqMjNTMmTODtXmcpwh3lCSprLRIcacePAIAqLuCFtxz586tdPqKFSuCtUn8AA53pCSpopQ7\npwGACcw7J4oa5YrwXuP2lPMdbgAwAcFdzzlPXeO2i/kONwCYgOCu59zNmkqSIr7LDXElAIDzQXDX\ncxHNLpHHkiK/OxnqUgAA54Hgruci3dEqibDkKC4JdSkAgPNAcNdzEY4IlbgdcvGAEQAwAsFdz0U4\nI1TithRZUCq7vDzU5QAAzoHgruciHC41Pe4N7OzX14S4GgDAuRDc9ZzDOnMIHF+zSrnvbQlhNQCA\ncyG4obeGXeb7OWPpkhBWAgA4F4IbKr40IdQlAADOE8ENxUXGKj+aQwEATMD/1lBcRJxeHdTI99pT\nxlfDAKCuIrihOHes8mKdsq7rKEnyFBWFuCIAQFUIbiguIlaSVO72Hg6eosJQlgMAqAbBDV9wF0V4\nX3sKCW4AqKsIbigxxvup8kPl2ZKkCk6VA0CdRXBDVzZsrRZxzZXh8T4hjBE3ANRdBDckSQMu66OS\nCEuSdCI3M8TVAACqQnBDktStWRe1btpGkpSX+12IqwEAVIXghk/zi1tJkorzc0NcCQCgKgQ3fOJj\nvTdhKS0uCHElAICqENzwcUd7vxZml5aGuBIAQFUIbvi4o7zBLYIbAOosghs+p0fcKi0PbSEAgCoR\n3PCJjI6TJFmlPGQEAOoqghs+7sgYeSzJKmPEDQB1lSvUBaDucDsj5LClRkdPqiw7W/m7P5I8FSo+\ncECWy6WK/Dw54+JUkZ8vR0yMPCUlcrhcsm1JFRWy3G55iovkjIlVRUH+mWVjY+UpKpLD7Zbt8Uge\nj6yICHlKSuSMjqli2UjZFd5fICynS57SEjmio+UpKPAt64yNU0VRoRyRkcp22CoprZDldMpTWlr5\nsoUFckRFez9853TIsix5ysvliIyUp7DwzLLfa6PlPPXP5Ie0sbi4mmUD2/j9/ji7jXb56WXPo41l\npcqOdqu0tKLqNhYUyBEdLbukVHI6z7Qx0i1PUSVtPL3PIyLOauO5+uOsNrpcle7zyttYzT4/q41y\nOGQ5HPKUlQW2MTZOFQXeuk+3MTvSpZLCkjNtjI2tdJ/L41FFXp5sj0cOt3dZR0yMKk7V4inIlyM6\nRp7iYllut+SpkOwzbXRER/uW9dZyqj9Ot9GS5HDKLi2VIypKnqJCOWIDl/WUlclyOCTLkl1WFrhs\nXJw8p/ajp7RU1qn9aJ/e5wHLnqq7pESWy6WjLqdKS0rlOHWsOs7qj8raaHts77Lfa6OnIF+OmGra\n+P3+OF13VFTQ2yjb9t+P52jjEadDFXJ4++OsfV7pfpT/PvcUFlSzH62q9/n32ijbVsL831f5fzXB\nDR/Lsnw/73/4wRBWgpqQH+oC6iD6xF9xqAvAD8KpcvjZ2yY+1CUAAKpBcMNPXpOYUJcAAKgGwQ0/\neZc2CnUJAIBqcI0bfsqbNtGS4U00o/N4xV52eajLOW8JCfHKysoLdRl1Cn0SiD7xR38EMqFPGHHD\nT0xEtPLinCpv2iTUpQAAKkFww0+MK1qSVFheFOJKAACVIbjhp1FUQ0lSZiHP5AaAuohr3PDTMr6F\nJGnRpy+qe7OfyOVwKiH6YlmWJUuWbNkBf0uqcl5lf0uq8WXjj0cpL7/4vGs5W03WG8w2Xmh/xx2P\nVF5+cY2v90LfE6z1/pC+i8uOUkFBSY0eH3Xl38AP6bvY7Mjz6o/T6z3NpGUvpA8l+f4vCeW+iXS6\ndWPCQFWF4IafqxpermhXlIrKi7Xj2L9DXQ4A1Es3dq46uDlVDj+RTrd+e83tio3g+9wAUBdZtm3b\n514s9Or6x/NrmwlfWahN9Ecg+iQQfeKP/ghUV/okIaHqu1gy4gYAwCAENwAABiG4AQAwCMENAIBB\nCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAgBDcAAAYhuAEAMEjQgnvq1Knq0aOHkpOT/aa//PLL\nGjJkiIYNG6annnoqWJsHACAsBe2xnmlpabrtttv08MMP+6Zt375dGzZs0OrVq+V2u5WdnR2szQMA\nEJaCNuLu1q2bGjRo4DftH//4h8aNGye32y1JatKkSbA2DwBAWAraiLsyBw4c0K5duzRv3jxFRkZq\nypQpuu66687rvdU94qy+ok/80R+B6JNA9Ik/+iNQXe+TWg3uiooK5ebm6tVXX9Wnn36q+++/Xxs2\nbJBlWed8b114PmpdUleeGVtX0B+B6JNA9Ik/+iNQXemTOvM87qZNm2rgwIGyLEvXXXedHA6HcnJy\narMEAACMVqvBPWDAAO3YsUOStH//fpWVlalRo0a1WQIAAEYL2qnySZMmaefOncrJyVHv3r01YcIE\njRw5UtOmTVNycrIiIiL0xBNPnNdpcgAA4BW04J47d26l05955plgbRIAgLDHndMAADAIwQ0AgEEI\nbgAADEJwAwBgEIIbAACDENwAABiE4AYAwCAENwAABiG4AQAwCMENAIBBCG4AAAxCcAMAYBCCGwAA\ng1Qb3I888ojv5+eff95v3l133RWcigAAQJWqDe6vvvrK9/M777zjNy8jIyM4FQEAgCpVG9y2bVf6\nsyRZlhWcigAAQJWqDe6zw5mgBgAg9FzVzdy/f79uuummgJ9t29aBAweCXhwAAPBXbXAvWrSotuoA\nAADnodrg/ulPf6oTJ07o8OHDat26teLi4mqrLgAAUIlqr3GvW7dOffr00bhx49S3b19t27attuoC\nAACVqHbEvWDBAv3zn/9U+/bttX37dj333HPq0aNHbdUGAAC+p9oRt8PhUPv27SVJN9xwg/Lz82ul\nKAAAULlqR9xlZWX6+uuvfd/hLikp8Xt91VVXBb9CAADgU21wFxcX68477/Sbdvq1ZVnasGFD8CoD\nAAABqg3ujRs31lYdAADgPFzw08FKS0u1evVqjRkzJhj1AACAalQ74j7bnj179Nprr+mtt97Stdde\nqxtvvDGYdQEAgEpUG9zHjx/X6tWrtXz5cpWVlWnEiBGKjo7W4sWLa6s+AABwlmqDu3fv3uratase\nffRRXX/99ZKkZcuW1UphAAAgULXXuMeMGaOvv/5ac+fO1cqVK1VYWFhbdQEAgEpUG9yTJ0/W5s2b\ndccdd2jDhg3q27evcnJytH379tqqDwAAnOWcH05zOBxKSkpSUlKSjh8/rlWrVmnWrFnKzc3Vli1b\naqNGAABwSrXB/be//S1gmtvt1qhRo3TixImgFQUAACpXbXA/9thj6tixo9q0aVNb9QAAgGpUG9yz\nZ8/WypUrtW/fPt14441KTk5WgwYNaqs2AADwPdUGd1pamtLS0nTo0CGlp6dr1KhRatOmje655x61\na9eutmoEAACnnNctT1u2bKlf//rXGj16tHbu3KlPP/002HUBAIBKVDvitm1bW7du1YoVK7Rv3z4N\nHTpUr776qlq2bFlb9QEAgLOc885piYmJSktL07333ivLslRSUqL//Oc/kngeNwAAta3a4I6IiFBO\nTo5eeOEFLVmyRLZt++bxPG4AAGofz+MGAMAgF/w8bgAAEDoENwAABiG4AQAwCMENAIBBCG4AAAxC\ncAMAYBCCGwAAgxDcAAAYhOAGAMAgQQvuqVOnqkePHkpOTg6Yt2TJErVt21bHjx8P1uYBAAhLQQvu\ntLQ0LV68OGD60aNH9f7776t58+bB2jQAAGEraMHdrVs3NWjQIGD6nDlzNHnyZFmWFaxNAwAQtqp9\nyEhNW79+vRITE9WuXbsLfm9giNf2AAAY+klEQVRCQnwQKjIbfeKP/ghEnwSiT/zRH4Hqep/UWnAX\nFRVp4cKFWrJkyQ96f1ZWXg1XZLaEhHj65Cz0RyD6JBB94o/+CFRX+qS6Xx5q7VPlBw8e1OHDh5Wa\nmqqkpCQdO3ZMaWlpysrKqq0SAAAwXq2NuNu2batt27b5XiclJem1115T48aNa6sEAACMF7QR96RJ\nkzRq1Cjt379fvXv31rJly4K1KQAA6o2gjbjnzp1b7fyNGzcGa9MAAIQt7pwGAIBBCG4AAAxCcAMA\nYBCCGwAAgxDcAAAYhOAGAMAgBDcAAAYhuAEAMAjBDQCAQQhuAAAMQnADAGAQghsAAIMQ3AAAGITg\nBgDAIAQ3AAAGIbgBADAIwQ0AgEEIbgAADEJwAwBgEIIbAACDENwAABiE4AYAwCAENwAABiG4AQAw\nCMENAIBBCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAgBDcAAAYhuAEAMAjBDQCAQQhuAAAMQnAD\nAGAQghsAAIMQ3AAAGITgBgDAIAQ3AAAGIbgBADAIwQ0AgEEIbgAADEJwAwBgEIIbAACDENwAABiE\n4AYAwCAENwAABiG4AQAwCMENAIBBCG4AAAziCtaKp06dqk2bNqlJkyZau3atJOnJJ5/Uu+++q4iI\nCF122WWaM2eOLrroomCVAABA2AnaiDstLU2LFy/2m9azZ0+tXbtWa9asUevWrbVw4cJgbR4AgLAU\ntODu1q2bGjRo4DetV69ecrm8g/zOnTvr2LFjwdo8AABhKWTXuJcvX67evXuHavMAABgpaNe4q7Ng\nwQI5nU4NHz78vN+TkBAfxIrMRJ/4oz8C0SeB6BN/9Eegut4ntR7cK1as0KZNm7R06VJZlnXe78vK\nygtiVeZJSIinT85CfwSiTwLRJ/7oj0B1pU+q++WhVoN7y5YtWrx4sV555RVFR0fX5qYBAAgLQQvu\nSZMmaefOncrJyVHv3r01YcIELVq0SKWlpRo7dqwkqVOnTpo5c2awSgAAIOwELbjnzp0bMO3mm28O\n1uYAAKgXuHMaAAAGIbgBADAIwQ0AgEEIbgAADEJwAwBgEIIbAACDENwAABiE4AYAwCAENwAABiG4\nAQAwCMENAIBBCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAgBDcAAAYhuAEAMAjBDQCAQQhuAAAM\nQnADAGAQghsAAIMQ3AAAGITgBgDAIAQ3AAAGIbgBADAIwQ0AgEEIbgAADEJwAwBgEIIbAACDENwA\nABiE4AYAwCAENwAABiG4AQAwCMENAIBBCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAgBDcAAAYh\nuAEAMAjBDQCAQQhuAAAMQnADAGAQghsAAIMQ3AAAGITgBgDAIAQ3AAAGIbgBADAIwQ0AgEGCFtxT\np05Vjx49lJyc7Jt24sQJjR07VoMGDdLYsWOVm5sbrM0DABCWghbcaWlpWrx4sd+0RYsWqUePHnr7\n7bfVo0cPLVq0KFibBwAgLAUtuLt166YGDRr4TduwYYNGjBghSRoxYoTWr18frM0DABCWavUad3Z2\nthITEyVJCQkJys7Ors3NAwBgPFeoNmxZlizLOu/lExLig1iNmegTf/RHIPokEH3ij/4IVNf7pFZH\n3E2aNFFmZqYkKTMzU40bN67NzQMAYLxaDe6kpCSlp6dLktLT09W/f//a3DwAAMazbNu2g7HiSZMm\naefOncrJyVGTJk00YcIEDRgwQPfff7+OHj2q5s2b6w9/+IMaNmwYjM0DABCWghbcAACg5nHnNAAA\nDEJwAwBgkJAH99GjR3X77bfr5z//uYYNG6YXX3xRUtW3R7VtW48//rgGDhyolJQUff7556EsP6gq\nKio0YsQI3XXXXZKkQ4cO6eabb9bAgQN1//33q7S0VJJUWlqq+++/XwMHDtTNN9+sw4cPh7LsoDl5\n8qQmTpyoIUOGaOjQodq9e3e9Pk6WLl2qYcOGKTk5WZMmTVJJSUm9O0Yu5NbK1R0TK1eu1KBBgzRo\n0CCtXLmy1ttRkyrrkyeffFJDhgxRSkqK7r33Xp08edI3b+HChRo4cKAGDx6srVu3+qZv2bJFgwcP\n1sCBA42/y2VlfXLakiVL1LZtWx0/flySIceJHWIZGRn2Z599Ztu2befl5dmDBg2y9+3bZz/55JP2\nwoULbdu27YULF9pPPfWUbdu2vWnTJvs3v/mN7fF47N27d9s33XRTyGoPtiVLltiTJk2yx40bZ9u2\nbU+cONFeu3atbdu2PWPGDPtvf/ubbdu2/corr9gzZsywbdu2165da993332hKTjIpkyZYr/66qu2\nbdt2SUmJnZubW2+Pk2PHjtn9+vWzi4qKbNv2HhvLly+vd8fIzp077c8++8weNmyYb9qFHhM5OTl2\nUlKSnZOTY584ccJOSkqyT5w4UfuNqSGV9cnWrVvtsrIy27Zt+6mnnvL1yb59++yUlBS7pKTEPnjw\noN2/f3+7vLzcLi8vt/v3728fPHjQLikpsVNSUux9+/aFpD01obI+sW3bPnLkiH3HHXfYffv2tbOz\ns23bNuM4CfmIOzExUR07dpQkxcXF6YorrlBGRkaVt0c9Pd2yLHXu3FknT570fTc8nBw7dkybNm3S\nTTfdJMn7W+D27ds1ePBgSdKNN96oDRs2SJI2btyoG2+8UZI0ePBgbdu2TXaYfeYwLy9PH374oa8/\n3G63Lrroonp9nFRUVKi4uFjl5eUqLi5WQkJCvTtGLuTWylUdE++995569uyphg0bqkGDBurZs6ff\nyNM0lfVJr1695HJ577fVuXNnHTt2TJK3T4YNGya3262WLVuqVatW2rNnj/bs2aNWrVqpZcuWcrvd\nGjZsmO9YMlFlfSJJc+bM0eTJk/1uBmbCcRLy4D7b4cOHtXfvXnXq1KnK26NmZGSoWbNmvvc0a9ZM\nGRkZIak3mGbPnq3JkyfL4fDuopycHF100UW+f3xntzsjI0OXXHKJJMnlcik+Pl45OTmhKTxIDh8+\nrMaNG2vq1KkaMWKEpk+frsLCwnp7nDRt2lR33HGH+vXrp169eikuLk4dO3as18fIaRd6THx/etOm\nTcPqWPm+5cuXq3fv3pIC++R02+tDn6xfv16JiYlq166d33QTjpM6E9wFBQWaOHGipk2bpri4OL95\nF3p7VNO9++67aty4sa655ppQl1JnlJeX64svvtCtt96q9PR0RUdHB1x3q0/HSW5urjZs2KANGzZo\n69atKioqMnqUGCz16Zg4HwsWLJDT6dTw4cNDXUpIFRUVaeHChbrvvvtCXcoPUieCu6ysTBMnTlRK\nSooGDRokqerbozZt2tR3mkfynlJu2rRp7RcdRB999JE2btyopKQkTZo0Sdu3b9esWbN08uRJlZeX\nS/Jvd9OmTXX06FFJ3oDLy8tTo0aNQlZ/MDRr1kzNmjVTp06dJElDhgzRF198UW+Pkw8++EAtWrRQ\n48aNFRERoUGDBumjjz6q18fIaRd6THx/ekZGRlgdK6etWLFCmzZt0jPPPOP7Zaaqtod7nxw8eFCH\nDx9WamqqkpKSdOzYMaWlpSkrK8uI4yTkwW3btqZPn64rrrhCY8eO9U2v6vaop6fbtq2PP/5Y8fHx\nvtNi4eLBBx/Uli1btHHjRs2dO1c33HCDfv/736t79+566623JHk/3ZiUlCTJ2yenP+H41ltv6YYb\nbgi7UUZCQoKaNWumb775RpK0bds2XXnllfX2OGnevLk++eQTFRUVybZtbdu2TVdddVW9PkZOu9Bj\nolevXnrvvfeUm5ur3Nxcvffee+rVq1com1DjtmzZosWLF2vBggWKjo72TU9KStLrr7+u0tJSHTp0\nSAcOHNB1112na6+9VgcOHNChQ4dUWlqq119/3XcshYO2bdtq27Zt2rhxozZu3KhmzZppxYoVSkhI\nMOI4Cfmd03bt2qVf/epXatOmje967qRJk3TddddVentU27Y1c+ZMbd26VdHR0Zo9e7auvfbaUDYh\nqHbs2KElS5Zo4cKFOnTokB544AHl5uaqffv2euaZZ+R2u1VSUqLJkydr7969atCggebNm6eWLVuG\nuvQat3fvXk2fPl1lZWVq2bKl5syZI4/HU2+Pk/nz52vdunVyuVxq3769Zs2apYyMjHp1jFzIrZWr\nOyZee+01LVy4UJJ09913a+TIkaFs1o9SWZ8sWrRIpaWlvltMd+rUSTNnzpTkPX2+fPlyOZ1OTZs2\nTX369JEkbd68WbNnz1ZFRYVGjhype+65J2Rt+rEq65Obb77ZNz8pKUmvvfaaGjdubMRxEvLgBgAA\n5y/kp8oBAMD5I7gBADAIwQ0AgEEIbgAADEJwAwBgEFeoCwAQPElJSXK73YqMjPRNe+6559SiRYsa\n28bhw4c1cuRI7dixo8bWCaBqBDcQ5ubPn682bdqEugwANYRT5UA91LZtW82fP1+pqakaPHiw725r\nkvcuWyNGjFBKSorGjBmjb7/91jfvtdde0/DhwzV8+HCNHDlS3333nW/evHnzNGLECA0ePFi7du2q\n1fYA9QkjbiDMTZw40Xeq3Ol0asWKFZIkh8OhVatW6ZtvvtGtt96qrl27SpKmTJmiV155RVdddZWW\nLVumhx56SMuWLdOOHTu0cOFC/f3vf1dCQoIKCgrkcrlUXFysEydOqHPnznrggQe0evVqPfPMM/rn\nP/8ZsjYD4YzgBsJcVafKT9/y8YorrlCHDh308ccfy7IstWvXTldddZUkaeTIkXr00UeVn5+vTZs2\nKTU1VQkJCZKk2NhY37piYmLUr18/Sd7nPT/55JPBbhZQb3GqHMCP5na7fT87HA7fE8oA1DyCG6in\nli9fLkk6cOCAvvjiC3Xu3FmdO3fWl19+qa+//lqS9wljHTp0UFxcnPr27atVq1b5rmsXFBSopKQk\nZPUD9RWnyoEwd/Y1bkl6/PHHJUkVFRUaMWKEioqKNHPmTDVp0kSS9NRTT+mhhx5SeXm5GjdurKef\nflqS1L17d40bN05jx46VZVlyu93685//XPsNAuo5ng4G1ENt27bVRx995HedGoAZOFUOAIBBGHED\nAGAQRtwAABiE4AYAwCAENwAABiG4AQAwCMENAIBBCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAg\nBDcAAAYhuAEAMAjBDQCAQQhuAAAMQnADAGAQghsAAIMQ3AAAGITgBgDAIAQ3AAAGIbgBADAIwQ0A\ngEEIbgAADEJwAwBgEIIbAACDENwAABiE4AYAwCAENwAABiG4AQAwCMENAIBBCG4AAAxCcAMAYBCC\nGwAAgxDcAAAYhOAGAMAgBDcAAAYhuAEAMAjBDQCAQQhuAAAMQnADAGAQghsAAIMQ3AAAGITgBgDA\nIAQ3AAAGIbgBADAIwQ0AgEEIbgAADEJwAwBgEIIbAACDENwAABiE4AYAwCAENwAABiG4AQAwCMEN\nAIBBCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAgBDcAAAYhuAEAMAjBDQCAQQhuAAAMQnADAGAQ\nghsAAIMQ3AAAGITgBgDAIAQ3AAAGIbgBADAIwQ0AgEEIbgAADEJwAwBgEIIbAACDENwAABiE4AYA\nwCAENwAABnGFugCEl6ysLM2ePVuffvqpLrroIjVp0kTTpk1Tq1atNHv2bG3fvl2WZcntdusPf/iD\nWrZsqby8PD322GPavXu3bNvW9ddfrxkzZig+Pj5g/QsWLNDatWvlcDjkcDg0c+ZMderUqcp6nn32\nWcXExOg3v/mN/vjHP6pbt2762c9+pqVLl+oXv/iFoqOjA97zyiuv6MUXX9TBgwe1bds2NW7cuEb7\nKFTCYd9MmzZNn332mWzb1uWXX645c+YoNja2RvspVMJh/zzyyCPauXOnb/tPPPGE2rdvX3OdBC8b\nqCEej8e+5ZZb7L///e++aXv37rU//PBDe82aNfaECRPsiooK27Zt++jRo/aJEyds27btCRMm2PPn\nz/e9549//KM9YcKEgPV/9NFH9i233GKXlJTYtm3b2dnZ9rFjx6qtaf78+fbixYsDpvfr18/Ozs6u\n9D2ff/65fejQoWqXMU247Ju8vDzfz7Nnz7YXLlxY7TZMES775+GHH7bfeOONc7QWPxYjbtSY7du3\ny+Vy6dZbb/VNa9eunSTpr3/9qxISEuRweK/ONGvWTJL07bff6rPPPtO8efN877n33ns1cOBAHTx4\nUJdddplvelZWlho1aiS32y1JfiPhpKQkDRkyRFu3blVkZKR+//vfq1WrVn71PfLII+rbt68yMzOV\nmZmpMWPGqGHDhnr55Zf9luvQoUNNdEedEi77Ji4uTpJk27aKi4t/dL/UFeGyf1A7CO4wtWTN53r/\nk//W6Dp7drpUd6R0rHL+vn371LFj5fOHDh2qX/7yl9q1a5d69Oih4cOHq0OHDvrPf/6j9u3by+l0\n+pZ1Op1q37699u3b5/efT8+ePfXcc89p8ODB6tGjh37+85/rpz/9qW9+fHy81qxZo/T0dM2ePVsL\nFy6stJbRo0dr6dKlevHFF0NyGnz/X19U9gfbanSdTX7WQ5ePHVPl/HDaN1OnTtXmzZt15ZVX6pFH\nHqm2X36Iw1+tVU7GnhpdZ6Om16lF2+Qq54fT/pk3b56ee+459ejRQw899JDvlwXUHD6chlrRrFkz\nvfnmm5o0aZIsy9Kvf/1rbdt2YeEVGxurFStWaObMmWrcuLEeeOABrVixwjc/Odn7H+OwYcP08ccf\n12j94cy0fTNnzhxt3bpVV155pdatW/ej1mUCk/bPpEmT9Oabb2r58uXKzc3VokWLfvC6UDVG3GHq\njpSO1Y6Og+Hqq6/WW2+9VeV8t9utPn36qE+fPrr44ou1fv16jR49Wnv37pXH4/GdCvR4PNq7d6+u\nuuqqgHU4nU51795d3bt3V5s2bZSenq60tLSgtSkYLh87ptrRcTCE275xOp0aNmyYFi9erJEjR9bo\nulu0Ta52dBwM4bJ/EhMTffWmpaVpyZIlNbp+eDHiRo254YYbVFpaqn/961++aV9++aV27dqlzz//\nXBkZGZK8/7l89dVXat68uVq1aqUOHTro+eef973n+eefV8eOHQOus33zzTc6cOCA7/XevXvVvHlz\n3+s33nhDkrRu3Tp16dKl2lpjY2NVUFDwg9tqmnDYN7Zt69tvv/X9vHHjRl1xxRXn2QN1WzjsH0nK\nzMyU5N0/69ev19VXX30erceFYsSNGmNZlv70pz9p9uzZ+stf/qLIyEhdeumlmjZtmg4ePKgZM2ao\ntLRUknTttdfqtttukyTNmjVLjz32mAYMGCBJ6ty5s2bNmhWw/sLCQj3++OM6efKknE6nWrVqpZkz\nZ/rm5+bmKiUlRW63W3Pnzq221ltuuUW//e1vlZiYGPABm5deekmLFy/Wd999p+HDh6tPnz6V1mOS\ncNg3tm3r4YcfVkFBgWzbVtu2bfXoo4/+6L6pC8Jh/0jSQw89pJycHNm2rXbt2oXN/qlrLNu27VAX\nAfxYSUlJeu2118LmO9fhhH1Tt7F/zMOpcgAADMKIGwAAgzDiBgDAIAQ3AAAGIbgBADAIwQ0AgEEI\nbtSorKwsPfDAAxowYIDS0tJ05513av/+/fJ4PHr88ceVnJyslJQUjRw5UocOHZIk5eXlacqUKRo4\ncKAGDBigKVOmKC8vr9L1L1iwQMOGDVNKSopSU1P1ySefVFvPs88+qxdeeEGS9Mc//lEffPCBJGnp\n0qUqKiqq9D0PPvigBg8erOTkZE2dOlVlZWU/tDvqlHDYN6c9/vjj57xRCBCuuAELaoxt2xo/frxG\njBjhe2LRl19+qezsbH3++efKzMzU6tWr5XA4dOzYMd/zfKdPn66rr75aTz31lCRp/vz5mj59uubP\nn++3/t27d2vTpk1auXKl3G63jh8/fkGhet999/l+fumllzR8+PBKnyk8fPhwPfPMM5K8Ib5s2TL9\n8pe/vLDOqGPCZd9I0qeffqrc3NwLaj8QTghu1JhweTRhnz59fD9fd911vttNmixc9k1FRYWeeuop\n/f73v9f69etromsA4xDcYerlj5dr+6GPanSdN7S8Xrd3rvqBDuH0aEJJKisr06pVqzR9+vQql/kh\n3lnzhb745EiNrrNDp+YamFL1c8TDZd+88sor6t+/v+9hFkB9xDVu1AqTHk142qOPPqquXbuqa9eu\nP3pddZkp+yYjI0Nvvvmm7z7dQH3FiDtM3d55ZLWj42AIl0cTStKf/vQnHT9+XH/6059qfN0DUzpU\nOzoOhnDYN3v37tXBgwc1aNAgSVJRUZEGDhyod955p8a2AZiAETdqTLg8mnDZsmV67733NHfuXF9g\nmS4c9k3fvn31/vvva+PGjdq4caOio6MJbdRLjLhRY8Ll0YT/7//9PzVv3ly/+MUvJEkDBw7U+PHj\nf3jH1AHhsm8A8JARhAkeTVh3sW+AmhUe5wEBAKgnGHEDAGAQRtwAABiE4AYAwCAENwAABiG4AQAw\nCMENAIBBCG4AAAxCcAMAYBCCGwAAgxDcAAAYhOAGAMAg/z8KywfZqkfagwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAHRCAYAAACsO1ouAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIbgBADAIwQ0AgEF+AtxgFMOA0dnbAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe4AAAHRCAYAAACsO1ouAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhkTFEMyJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}